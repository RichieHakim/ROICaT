{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import math\n",
    "import argparse\n",
    "import pickle\n",
    "import roicat\n",
    "import scipy.sparse\n",
    "from roicat.model_training import simclr_training_helpers as sth\n",
    "\n",
    "path_script = sys.argv[0]\n",
    "directory_data = '/Users/josh/analysis/data/ROICaT/simclr_training'\n",
    "filepath_params = '/Users/josh/analysis/github_repos/ROICaT/roicat/model_training/simclr_params_base.json'\n",
    "directory_save = '/Users/josh/analysis/outputs/ROICaT/simclr_training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Global preferences\n",
    "# device_train = torch_helpers.set_device(use_GPU=params['useGPU_dataloader'])\n",
    "\n",
    "# # Load parameters from JSON\n",
    "# with open(filepath_params) as f:\n",
    "#     dict_params = json.load(f)\n",
    "\n",
    "dict_params = {\n",
    "    'data': {\n",
    "        'um_per_pixel': 1.0,\n",
    "    'nan_to_num': True,\n",
    "    'nan_to_num_val': 0.0,\n",
    "    'verbose': True},\n",
    "    'dataloader': {\n",
    "        'batchSize_dataloader': 1024,\n",
    "    'pinMemory_dataloader': False,\n",
    "    'numWorkers_dataloader': 0,\n",
    "    'persistentWorkers_dataloader': False,\n",
    "    'prefetchFactor_dataloader': 0,\n",
    "    'img_size_out': [224, 224],\n",
    "    'jit_script_transforms': False,\n",
    "    'shuffle_dataloader': True,\n",
    "    'drop_last_dataloader': True,\n",
    "    'verbose': True,\n",
    "    'transforms_invariant': {'Random_occlusion': {'prob': 0.5,\n",
    "        'size': [0.4, 0.45]},\n",
    "    'Scale_image_sum': {'sum_val': 1, 'epsilon': 1e-09, 'min_sub': True},\n",
    "    'AddPoissonNoise': {'scaler_bounds': [1778.27941004, 5623.4132519],\n",
    "        'prob': 0.4,\n",
    "        'base': 1000,\n",
    "        'scaling': 'log'},\n",
    "    'Horizontal_stripe_scale': {'alpha_min_max': [0.5, 1],\n",
    "        'im_size': [36, 36],\n",
    "        'prob': 0.3},\n",
    "    'Horizontal_stripe_shift': {'alpha_min_max': [1, 2],\n",
    "        'im_size': [36, 36],\n",
    "        'prob': 0.3},\n",
    "    'RandomHorizontalFlip': {'p': 0.0},\n",
    "    'RandomAffine': {'degrees': [-15, 15],\n",
    "        'translate': [0.02, 0.02],\n",
    "        'scale': [0.9, 1.1],\n",
    "        'shear': [-2, 2, -2, 2],\n",
    "        'interpolation': 'bilinear',\n",
    "        'fill': 0,\n",
    "        # 'fillcolor': None,\n",
    "        # 'resample': None\n",
    "        },\n",
    "    'AddGaussianNoise': {'mean': 0, 'std': 0.0003, 'prob': 0.4},\n",
    "    'ScaleDynamicRange': {'scaler_bounds': [0, 1], 'epsilon': 1e-09},\n",
    "    'WarpPoints': {'r': [0.1, 0.2],\n",
    "        'cx': [-0.3, 0.3],\n",
    "        'cy': [-0.3, 0.3],\n",
    "        'dx': [-0.1, 0.1],\n",
    "        'dy': [-0.1, 0.1],\n",
    "        'n_warps': 2,\n",
    "        'prob': 0.5,\n",
    "        'img_size_in': [36, 36],\n",
    "        'img_size_out': [224, 224]},\n",
    "    'TileChannels': {'dim': 0, 'n_channels': 3}}},\n",
    "    'model': {'torchvision_model': 'convnext_tiny',\n",
    "    'filepath_model': '/Users/josh/analysis/outputs/ROICaT/simclr_training/models/ConvNext_tiny__1_0_best__simCLR',\n",
    "    'head_pool_method': 'AdaptiveAvgPool2d',\n",
    "    'head_pool_method_kwargs': {'output_size': 1},\n",
    "    'pre_head_fc_sizes': [256],\n",
    "    'post_head_fc_sizes': [128],\n",
    "    'block_to_unfreeze': '5.6',\n",
    "    'n_block_toInclude': 7,\n",
    "    'head_nonlinearity': 'GELU',\n",
    "    'head_nonlinearity_kwargs': {}},\n",
    "    'trainer': {'n_epochs': 9999999,\n",
    "    'device_train': 'cpu',\n",
    "    'inner_batch_size': 256,\n",
    "    'learning_rate': 0.01,\n",
    "    'penalty_orthogonality': 1.0,\n",
    "    'weight_decay': 0.1,\n",
    "    'gamma': 1.0,\n",
    "    'temperature': 0.03,\n",
    "    'l2_alpha': 0.0\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josh/analysis/github_repos/ROICaT/roicat/util.py:369: UserWarning: RH WARNING: unable to get cpu info. Got error: No module named 'cpuinfo'\n",
      "  warnings.warn(f'RH WARNING: unable to get cpu info. Got error: {e}')\n",
      "/Users/josh/analysis/github_repos/ROICaT/roicat/util.py:388: UserWarning: RH WARNING: unable to get gpu info. Got error: No module named 'GPUtil'\n",
      "  warnings.warn(f'RH WARNING: unable to get gpu info. Got error: {e}')\n",
      "/Users/josh/analysis/github_repos/ROICaT/roicat/ROInet.py:84: UserWarning: ROICaT WARNING: Image(s) with all zeros detected. These can pass through the network, but may give weird results.\n",
      "  warnings.warn('ROICaT WARNING: Image(s) with all zeros detected. These can pass through the network, but may give weird results.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: Importing ROI images\n",
      "Completed: Imported 1 sessions. Each session has [3000] ROIs. Total number of ROIs is 3000. The um_per_pixel is 1.0 um per pixel.\n",
      "Starting: resizing ROIs\n",
      "Completed: resizing ROIs\n",
      "Defined image transformations: Sequential(\n",
      "  (0): Random_occlusion(\n",
      "    (rotator): RandomRotation(degrees=[-180.0, 180.0], interpolation=nearest, expand=False, fill=0)\n",
      "  )\n",
      "  (1): Scale_image_sum()\n",
      "  (2): AddPoissonNoise(level_bounds=[1778.27941004, 5623.4132519], prob=0.4)\n",
      "  (3): Horizontal_stripe_scale()\n",
      "  (4): Horizontal_stripe_shift()\n",
      "  (5): RandomHorizontalFlip(p=0.0)\n",
      "  (6): RandomAffine(degrees=[-15.0, 15.0], translate=[0.02, 0.02], scale=[0.9, 1.1], shear=[-2.0, 2.0, -2.0, 2.0], interpolation=bilinear)\n",
      "  (7): AddGaussianNoise(mean=0, std=0.0003, level_bounds=(0.0, 1.0), prob=0.4)\n",
      "  (8): ScaleDynamicRange(scaler_bounds=[0, 1])\n",
      "  (9): WarpPoints(r=[0.1, 0.2], cx=[-0.3, 0.3], cy=[-0.3, 0.3], dx=[-0.1, 0.1], dy=[-0.1, 0.1], n_warps=2, prob=0.5, img_size_in=[36, 36], img_size_out=[224, 224])\n",
      "  (10): TileChannels(dim=0)\n",
      ")\n",
      "Defined dataset\n",
      "Defined dataloader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josh/analysis/github_repos/ROICaT/roicat/ROInet.py:247: UserWarning: prefetchFactor_dataloader is ignored when numWorkers_dataloader == 0. Setting numWorkers_dataloader > 0 will allow prefetchFactor_dataloader to be used.\n",
      "  warnings.warn(f'prefetchFactor_dataloader is ignored when numWorkers_dataloader == 0. Setting numWorkers_dataloader > 0 will allow prefetchFactor_dataloader to be used.')\n",
      "/Users/josh/opt/anaconda3/envs/ROICaT/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/josh/opt/anaconda3/envs/ROICaT/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ConvNeXt_Tiny_Weights.IMAGENET1K_V1`. You can also use `weights=ConvNeXt_Tiny_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "list_filepaths_data = [os.path.join(directory_data, filename) for filename in os.listdir(directory_data)]\n",
    "\n",
    "# Load data from dir_data into Data object... or load from saved Data object\n",
    "ROI_sparse_all = [scipy.sparse.load_npz(filepath_ROI_images) for filepath_ROI_images in list_filepaths_data]\n",
    "ROI_images = [sf_sparse.toarray().reshape(sf_sparse.shape[0], 36,36).astype(np.float32) for sf_sparse in ROI_sparse_all]\n",
    "\n",
    "data = roicat.data_importing.Data_roicat();\n",
    "data.set_ROI_images(\n",
    "    ROI_images=[ROI_images[0][:3000]],\n",
    "    um_per_pixel=dict_params['data']['um_per_pixel'],\n",
    ")\n",
    "### Data import preferences\n",
    "# params['paths']['path_data_training']\n",
    "\n",
    "\n",
    "# Create dataset / dataloader\n",
    "ROI_images_rs = roicat.ROInet.Resizer_ROI_images(\n",
    "    np.concatenate(data.ROI_images, axis=0),\n",
    "    dict_params['data']['um_per_pixel'],\n",
    "    dict_params['data']['nan_to_num'],\n",
    "    dict_params['data']['nan_to_num_val'],\n",
    "    dict_params['data']['verbose']\n",
    ").ROI_images_rs\n",
    "### Resizing preferences\n",
    "\n",
    "dataloader_generator = roicat.ROInet.Dataloader_ROInet(\n",
    "    ROI_images_rs,\n",
    "    dict_params['dataloader']['batchSize_dataloader'],\n",
    "    dict_params['dataloader']['pinMemory_dataloader'],\n",
    "    dict_params['dataloader']['numWorkers_dataloader'],\n",
    "    dict_params['dataloader']['persistentWorkers_dataloader'],\n",
    "    dict_params['dataloader']['prefetchFactor_dataloader'],\n",
    "    torch.nn.Sequential(\n",
    "        *[roicat.model_training.augmentation.__dict__[key](**params) for key,params in dict_params['dataloader']['transforms_invariant'].items()]\n",
    "    ), # Converting dictionary of transforms to torch.nn.Sequential object\n",
    "    tuple(dict_params['dataloader']['img_size_out']),\n",
    "    dict_params['dataloader']['jit_script_transforms'],\n",
    "    dict_params['dataloader']['shuffle_dataloader'],\n",
    "    dict_params['dataloader']['drop_last_dataloader'],\n",
    "    dict_params['dataloader']['verbose'],\n",
    ")\n",
    "\n",
    "dataloader = dataloader_generator.dataloader\n",
    "image_out_size = list(dataloader_generator.dataset[0][0][0].shape)\n",
    "\n",
    "# Create Model\n",
    "model_container = sth.Simclr_Model(\n",
    "    dict_params['model']['filepath_model'], # Set filepath to/from which to save/load model\n",
    "    base_model=torchvision.models.__dict__[dict_params['model']['torchvision_model']](pretrained=True),\n",
    "    # Freeze base_model\n",
    "    # slice_point=dict_params['model']['slice_point'],\n",
    "    # Slice off the model at the slice_point and only keep the prior blocks\n",
    "    \n",
    "    \n",
    "    # attachment_block=sth.Attachment_Blocks(\n",
    "    head_pool_method=dict_params['model']['head_pool_method'],\n",
    "    head_pool_method_kwargs=dict_params['model']['head_pool_method_kwargs'],\n",
    "    pre_head_fc_sizes=dict_params['model']['pre_head_fc_sizes'],\n",
    "    post_head_fc_sizes=dict_params['model']['post_head_fc_sizes'],\n",
    "    head_nonlinearity=dict_params['model']['head_nonlinearity'],\n",
    "    head_nonlinearity_kwargs=dict_params['model']['head_nonlinearity_kwargs'],\n",
    "    # ),\n",
    "\n",
    "\n",
    "    # Add the attachment blocks to the end of the base_model\n",
    "    block_to_unfreeze=dict_params['model']['block_to_unfreeze'],\n",
    "    n_block_toInclude=dict_params['model']['n_block_toInclude'],\n",
    "    # Unfreeze the model at and beyond the unfreeze_point\n",
    "    image_out_size=image_out_size,\n",
    "    # Set version of the forward pass to use\n",
    "    load_model=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9999999 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9999999 [02:21<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "weight tensor should be defined either for all 1025 classes or no classes but got weight tensor of shape: [2049]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/josh/analysis/github_repos/ROICaT/roicat/model_training/simclr_training.ipynb Cell 4\u001b[0m in \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josh/analysis/github_repos/ROICaT/roicat/model_training/simclr_training.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m trainer \u001b[39m=\u001b[39m sth\u001b[39m.\u001b[39mSimclr_Trainer(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josh/analysis/github_repos/ROICaT/roicat/model_training/simclr_training.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     dataloader,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josh/analysis/github_repos/ROICaT/roicat/model_training/simclr_training.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     model_container,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josh/analysis/github_repos/ROICaT/roicat/model_training/simclr_training.ipynb#W3sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     l2_alpha\u001b[39m=\u001b[39mdict_params[\u001b[39m'\u001b[39m\u001b[39mtrainer\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39ml2_alpha\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josh/analysis/github_repos/ROICaT/roicat/model_training/simclr_training.ipynb#W3sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josh/analysis/github_repos/ROICaT/roicat/model_training/simclr_training.ipynb#W3sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Loop through epochs, batches, etc. if loss becomes NaNs, don't save the network and stop training. Otherwise, save the network as an onnx file.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josh/analysis/github_repos/ROICaT/roicat/model_training/simclr_training.ipynb#W3sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m##### TODO\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/josh/analysis/github_repos/ROICaT/roicat/model_training/simclr_training.ipynb#W3sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/analysis/github_repos/ROICaT/roicat/model_training/simclr_training_helpers.py:417\u001b[0m, in \u001b[0;36mSimclr_Trainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mepoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    415\u001b[0m log_function \u001b[39m=\u001b[39m partial(log_fn, path_log\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath_saveLog) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath_saveLog \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mlambda\u001b[39;00m x: \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 417\u001b[0m losses_train \u001b[39m=\u001b[39m training\u001b[39m.\u001b[39;49mepoch_step(\n\u001b[1;32m    418\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataloader, \n\u001b[1;32m    419\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_container\u001b[39m.\u001b[39;49mmodel, \n\u001b[1;32m    420\u001b[0m     optimizer, \n\u001b[1;32m    421\u001b[0m     criterion,\n\u001b[1;32m    422\u001b[0m     scheduler\u001b[39m=\u001b[39;49mscheduler,\n\u001b[1;32m    423\u001b[0m     temperature\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtemperature,\n\u001b[1;32m    424\u001b[0m     \u001b[39m# l2_alpha,\u001b[39;49;00m\n\u001b[1;32m    425\u001b[0m     penalty_orthogonality\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpenalty_orthogonality,\n\u001b[1;32m    426\u001b[0m     mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msemi-supervised\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    427\u001b[0m     loss_rolling_train\u001b[39m=\u001b[39;49mlosses_train, \n\u001b[1;32m    428\u001b[0m     loss_rolling_val\u001b[39m=\u001b[39;49mlosses_val,\n\u001b[1;32m    429\u001b[0m     device\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice_train, \n\u001b[1;32m    430\u001b[0m     inner_batch_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minner_batch_size,\n\u001b[1;32m    431\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[1;32m    432\u001b[0m     verbose_update_period\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m    433\u001b[0m     log_function\u001b[39m=\u001b[39;49mpartial(log_fn, path_log\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath_saveLog),\n\u001b[1;32m    434\u001b[0m )\n\u001b[1;32m    436\u001b[0m \u001b[39m## save loss stuff\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath_saveLog \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/analysis/github_repos/ROICaT/roicat/model_training/training.py:232\u001b[0m, in \u001b[0;36mepoch_step\u001b[0;34m(dataloader, model, optimizer, criterion, scheduler, temperature, L2_alpha, penalty_orthogonality, mode, loss_rolling_train, loss_rolling_val, device, inner_batch_size, do_validation, validation_Object, verbose, verbose_update_period, log_function, X_val, y_val)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39m# Get batch weights\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msemi-supervised\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 232\u001b[0m     loss, pos_over_neg \u001b[39m=\u001b[39m train_step_simCLR(\n\u001b[1;32m    233\u001b[0m         X_batch, \n\u001b[1;32m    234\u001b[0m         y_batch, \n\u001b[1;32m    235\u001b[0m         model, \n\u001b[1;32m    236\u001b[0m         optimizer, \n\u001b[1;32m    237\u001b[0m         criterion, \n\u001b[1;32m    238\u001b[0m         scheduler, \n\u001b[1;32m    239\u001b[0m         temperature, \n\u001b[1;32m    240\u001b[0m         sample_weights\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mas_tensor(sample_weights, device\u001b[39m=\u001b[39;49mdevice),\n\u001b[1;32m    241\u001b[0m         penalty_orthogonality\u001b[39m=\u001b[39;49mpenalty_orthogonality,\n\u001b[1;32m    242\u001b[0m         inner_batch_size\u001b[39m=\u001b[39;49minner_batch_size,\n\u001b[1;32m    243\u001b[0m         ) \u001b[39m# Needs to take in weights\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msupervised\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    245\u001b[0m     loss \u001b[39m=\u001b[39m train_step_classifier(X_batch, y_batch, model, optimizer, criterion, scheduler, L2_alpha\u001b[39m=\u001b[39mL2_alpha)\n",
      "File \u001b[0;32m~/analysis/github_repos/ROICaT/roicat/model_training/training.py:83\u001b[0m, in \u001b[0;36mtrain_step_simCLR\u001b[0;34m(X_train_batch, y_train_batch, model, optimizer, criterion, scheduler, temperature, sample_weights, penalty_orthogonality, inner_batch_size)\u001b[0m\n\u001b[1;32m     78\u001b[0m pos_over_neg \u001b[39m=\u001b[39m (torch\u001b[39m.\u001b[39mmean(logits[:,\u001b[39m0\u001b[39m]) \u001b[39m/\u001b[39m torch\u001b[39m.\u001b[39mmean(logits[:,\u001b[39m1\u001b[39m:]))\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     79\u001b[0m \u001b[39m# loss_unreduced_train = criterion(logits, labels)\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \n\u001b[1;32m     81\u001b[0m \u001b[39m# print('contrastive_matrix_sample_weights', contrastive_matrix_sample_weights)\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m loss_unreduced_train \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mfunctional\u001b[39m.\u001b[39;49mcross_entropy(logits, labels, weight\u001b[39m=\u001b[39;49mcontrastive_matrix_sample_weights, reduction\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mnone\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     84\u001b[0m \u001b[39m# loss_unreduced_train = torch.nn.functional.cross_entropy(logits, labels, reduction='none')\u001b[39;00m\n\u001b[1;32m     85\u001b[0m loss_train \u001b[39m=\u001b[39m (loss_unreduced_train\u001b[39m.\u001b[39mfloat() \u001b[39m@\u001b[39m double_sample_weights\u001b[39m.\u001b[39mfloat()) \u001b[39m/\u001b[39m double_sample_weights\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39msum()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ROICaT/lib/python3.9/site-packages/torch/nn/functional.py:3014\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3012\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3013\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3014\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: weight tensor should be defined either for all 1025 classes or no classes but got weight tensor of shape: [2049]"
     ]
    }
   ],
   "source": [
    "# Specify criterion, optimizer, scheduler, learning rate, etc.\n",
    "trainer = sth.Simclr_Trainer(\n",
    "    dataloader,\n",
    "    model_container,\n",
    "    \n",
    "    n_epochs=dict_params['trainer']['n_epochs'],\n",
    "    device_train=dict_params['trainer']['device_train'],\n",
    "    inner_batch_size=dict_params['trainer']['inner_batch_size'],\n",
    "    learning_rate=dict_params['trainer']['learning_rate'],\n",
    "    penalty_orthogonality=dict_params['trainer']['penalty_orthogonality'],\n",
    "    weight_decay=dict_params['trainer']['weight_decay'],\n",
    "    gamma=dict_params['trainer']['gamma'],\n",
    "    temperature=dict_params['trainer']['temperature'],\n",
    "    l2_alpha=dict_params['trainer']['l2_alpha'],\n",
    ")\n",
    "\n",
    "# Loop through epochs, batches, etc. if loss becomes NaNs, don't save the network and stop training. Otherwise, save the network as an onnx file.\n",
    "##### TODO\n",
    "trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ROICaT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

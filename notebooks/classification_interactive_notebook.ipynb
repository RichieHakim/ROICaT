{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d180220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Move into Files...\n",
    "class Data():\n",
    "    def __init__(\n",
    "        self,\n",
    "        paths_statFiles,\n",
    "        paths_labelFiles=None,\n",
    "        um_per_pixel=1.0,\n",
    "        new_or_old_suite2p='new',\n",
    "        verbose=True \n",
    "                ):\n",
    "        \"\"\"\n",
    "        Initializes the class for importing spatial footprints.\n",
    "        Args:\n",
    "            paths_statFiles (list of str or pathlib.Path):\n",
    "                List of paths to the stat.npy files.\n",
    "                Elements should be one of: str, pathlib.Path,\n",
    "                 list of str or list of pathlib.Path\n",
    "            paths_labelFiles (list of str or pathlib.Path):\n",
    "                Optional. Only used to train a classifier.\n",
    "                List of paths to the label .npy files.\n",
    "                Elements should be one of: str, pathlib.Path,\n",
    "                 list of str or list of pathlib.Path\n",
    "            um_per_pixel (float):\n",
    "                'micrometers per pixel' of the imaging field\n",
    "                  of view.\n",
    "            verbose (bool):\n",
    "                If True, prints results from each function.\n",
    "        \"\"\"\n",
    "\n",
    "        self.paths_stat = fix_paths(paths_statFiles)\n",
    "        if paths_labelFiles is not None:\n",
    "            self.paths_lbl = fix_paths(paths_labelFiles)\n",
    "        else:\n",
    "            self.paths_lbl = None\n",
    "\n",
    "        self.n_sessions = len(self.paths_stat)\n",
    "        self.statFiles = None\n",
    "        self.labelFiles = None\n",
    "        self.um_per_pixel = um_per_pixel\n",
    "        self._new_or_old_suite2p = new_or_old_suite2p\n",
    "        self._verbose = verbose\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def import_statFiles(self):\n",
    "        \"\"\"\n",
    "        Imports the stats.npy contents into the class.\n",
    "        This method can be called before any other function.\n",
    "\n",
    "        Returns:\n",
    "            self.statFiles (list):\n",
    "                List of imported files. Type depends on sf_type.\n",
    "        \"\"\"\n",
    "\n",
    "        print(f\"Starting: Importing spatial footprints from stat files\") if self._verbose else None\n",
    "\n",
    "#         self.statFiles = [np.load(path, allow_pickle=True) for path in self.paths_stat]\n",
    "        \n",
    "        statFiles_lst = []\n",
    "        for path_stat in self.paths_stat:\n",
    "            if Path(path_stat).suffix == '.npz':\n",
    "                dat = np.load(path_stat)\n",
    "                images_labeled = scipy.sparse.csr_matrix((dat['data'], dat['indices'], dat['indptr']), shape=dat['shape']).toarray()\n",
    "                images_labeled = [images_labeled.reshape([-1, 36,36])]\n",
    "\n",
    "            elif Path(path_stat).suffix == '.npy':\n",
    "                images_labeled = \\\n",
    "                    helpers.import_multiple_stat_files(   \n",
    "                        paths_statFiles=[path_stat],\n",
    "                        out_height_width=[36,36],\n",
    "                        max_footprint_width=241\n",
    "                    )\n",
    "            else:\n",
    "                raise ValueError(f'path_stat: {path_stat} is not an npy or npz file.')\n",
    "            \n",
    "            statFiles_lst.extend(images_labeled)\n",
    "        \n",
    "        \n",
    "        self.n_roi = [len(stat) for stat in statFiles_lst]\n",
    "        self.n_roi_total = sum(self.n_roi)\n",
    "        \n",
    "        self.statFiles = np.concatenate(statFiles_lst,axis=0)\n",
    "        \n",
    "        if type(self.labelFiles) is np.ndarray:\n",
    "            assert self.statFiles.shape[0] == self.labelFiles.shape[0] , 'num images in stat files does not correspond to num labels'\n",
    "\n",
    "        print(f\"Completed: Imported {len(self.statFiles)} stat files into class as self.statFiles. Total number of ROIs: {self.n_roi_total}. Number of ROI from each file: {self.n_roi}\") if self._verbose else None\n",
    "        \n",
    "        \n",
    "#         return self.statFiles\n",
    "        return self.statFiles\n",
    "        \n",
    "    def import_labelFiles(self):\n",
    "        \"\"\"\n",
    "        Imports the FOV images from ops files or user defined\n",
    "         image arrays.\n",
    "\n",
    "        Args:\n",
    "            type_meanImg (str):\n",
    "                Type of the mean image.\n",
    "                References the key in the ops.npy file.\n",
    "                Options are:\n",
    "                    'meanImgE':\n",
    "                        Enhanced mean image.\n",
    "                    'meanImg':\n",
    "                        Mean image.\n",
    "            images (list of np.ndarray):\n",
    "                Optional. If provided, the FOV images are \n",
    "                 defined by these images.\n",
    "                If not provided, the FOV images are defined by\n",
    "                 the ops.npy files from self.paths_ops.\n",
    "                len(images) must be equal to len(self.paths_stat)\n",
    "                Images must be of the same shape.\n",
    "        \n",
    "        Returns:\n",
    "            self.FOV_images (list):\n",
    "                List of FOV images.\n",
    "                Length of the list is the same self.paths_files.\n",
    "                Each element is a numpy.ndarray of shape:\n",
    "                 (n_files, height, width)\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f\"Starting: Importing labels footprints from npy files\") if self._verbose else None\n",
    "        \n",
    "        raw_labels = [np.load(path) for path in self.paths_lbl]\n",
    "        self.n_lbl = [len(stat) for stat in raw_labels]\n",
    "        self.n_lbl_total = sum(self.n_roi)\n",
    "        self.labelFiles = helpers.squeeze_integers(np.concatenate(raw_labels))\n",
    "        if type(self.statFiles) is np.ndarray:\n",
    "            assert self.statFiles.shape[0] == self.labelFiles.shape[0] , 'num images in stat files does not correspond to num labels'\n",
    "                \n",
    "        print(f\"Completed: Imported {len(self.labelFiles)} labels into class as self.labelFiles. Total number of ROIs: {self.n_lbl_total}. Number of ROI from each file: {self.n_lbl}\") if self._verbose else None\n",
    "        \n",
    "        return self.labelFiles\n",
    "\n",
    "\n",
    "    def drop_nan_rois(self):\n",
    "        idx_nne = helpers.get_keep_nonnan_entries(self.statFiles)\n",
    "        self.statFiles = self.statFiles[idx_nne]\n",
    "#         latents_clean = latents_clean[idx_nne]\n",
    "        self.labelFiles = self.labelFiles[idx_nne]\n",
    "        return self.statFiles, self.labelFiles\n",
    "\n",
    "\n",
    "\n",
    "    def cleaning(self):\n",
    "\n",
    "#         raw_images = roinet.ROI_images_rs\n",
    "#         raw_images_dup = np.concatenate([raw_images for _ in range(len(raw_labels_match))], axis=0)\n",
    "\n",
    "#         latents = roinet.latents\n",
    "#         latents_dup = np.concatenate([latents for _ in range(len(raw_labels_match))], axis=0)\n",
    "\n",
    "#         labels = helpers.squeeze_integers(np.concatenate(raw_labels_match))\n",
    "#         assert raw_images_dup.shape[0] == labels.shape[0] , 'num images in stat files does not correspond to num labels'\n",
    "        \n",
    "        return\n",
    "\n",
    "        \n",
    "    def relabeling(self):\n",
    "#         https://github.com/seung-lab/fastremap\n",
    "\n",
    "#         # Relabel values based on relabels definition\n",
    "#         # Used for combining e.g. 4 into 3 via {4: 3}\n",
    "#         new_labels = fg.relabel(labels, relabels)\n",
    "\n",
    "#         # Identify the examples to keep by with labels not in the list \"lbls_to_drop\"\n",
    "#         # E.g. If all label 6s are bad data to not be classified, pass a list of [6]\n",
    "#         keep_tf = fg.get_keep_labels(new_labels, lbls_to_drop)\n",
    "\n",
    "\n",
    "#         # Create a final list of indices that should be kept (for use in filtering both labels and ROI images)\n",
    "#         idx_toKeep = fg.get_keep_entries(keep_tf)\n",
    "\n",
    "#         # \n",
    "#         idx_nne = fg.get_keep_nonnan_entries(images_labeled_clean)\n",
    "#         images_labeled_clean = images_labeled_clean[idx_nne]\n",
    "#         latents_clean = latents_clean[idx_nne]\n",
    "#         labels_clean = labels_clean[idx_nne]\n",
    "            \n",
    "#         # Keep only ROI values that are labelled by not dropped classes\n",
    "#         images_labeled_clean = raw_images_dup[idx_toKeep]\n",
    "#         latents_clean = latents_dup[idx_toKeep]\n",
    "#         labels_clean = labels[idx_toKeep]\n",
    "\n",
    "#         # Set lowest label value to 0 and sweeze all other label numbers to be sequential integers\n",
    "#         labels_clean -= labels_clean.min()\n",
    "#         labels_clean = helpers.squeeze_integers(labels_clean)\n",
    "\n",
    "#         # \n",
    "#         idx_nne = fg.get_keep_nonnan_entries(images_labeled_clean)\n",
    "#         images_labeled_clean = images_labeled_clean[idx_nne]\n",
    "#         latents_clean = latents_clean[idx_nne]\n",
    "#         labels_clean = labels_clean[idx_nne]\n",
    "            \n",
    "            return\n",
    "\n",
    "    \n",
    "def fix_paths(paths):\n",
    "    \"\"\"\n",
    "    Make sure path_files is a list of pathlib.Path\n",
    "    \n",
    "    Args:\n",
    "        paths (list of str or pathlib.Path or str or pathlib.Path):\n",
    "            Potentially dirty input.\n",
    "            \n",
    "    Returns:\n",
    "        paths (list of pathlib.Path):\n",
    "            List of pathlib.Path\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    if (type(paths) is str) or (type(paths) is pathlib.PosixPath):\n",
    "        paths = [Path(paths)]\n",
    "    if type(paths[0]) is str:\n",
    "        paths = [Path(path) for path in paths]\n",
    "    if type(paths[0]) is pathlib.PosixPath:\n",
    "        paths = paths\n",
    "    else:\n",
    "        raise TypeError(\"path_files must be a list of str or list of pathlib.Path or a str or pathlib.Path\")\n",
    "\n",
    "    return paths\n",
    "    \n",
    "    \n",
    "# # class ROINet():\n",
    "# #     def __init__(self):\n",
    "# #         return\n",
    "# #         device_dataloader = torch_helpers.set_device(use_GPU=simclr_params_json['useGPU_dataloader'])\n",
    "# #         DEVICE = torch_helpers.set_device(use_GPU=simclr_params_json['useGPU_training'])\n",
    "\n",
    "# #         # hash_dict_true={\n",
    "# #         #             'params': ('params.json', hash_file('/n/data1/hms/neurobio/sabatini/josh/analysis/roinet-paper/debugging/params.json')),\n",
    "# #         #             'model': ('model.py', hash_file('/n/data1/hms/neurobio/sabatini/josh/analysis/roinet-paper/debugging/model.py')),\n",
    "# #         #             'state_dict': ('ConvNext_tiny__1_0_unfrozen__simCLR.pth', hash_file('/n/data1/hms/neurobio/sabatini/josh/analysis/roinet-paper/debugging/ConvNext_tiny__1_0_unfrozen__simCLR.pth')),\n",
    "# #         #         }\n",
    "# #         # hash_dict_true={\n",
    "# #         #             'params': ('params.json', hash_file('/n/data1/hms/neurobio/sabatini/josh/analysis/roinet-paper/debugging/params.json')),\n",
    "# #         #             'model': ('model.py', hash_file('/n/data1/hms/neurobio/sabatini/josh/analysis/roinet-paper/debugging/model.py')),\n",
    "# #         #             'state_dict': ('ConvNext_tiny__1_0_best__simCLR.pth', hash_file('/n/data1/hms/neurobio/sabatini/josh/analysis/roinet-paper/debugging/ConvNext_tiny__1_0_best__simCLR.pth')),\n",
    "# #         #         }\n",
    "\n",
    "# #         ROIne_params = fig_gen_params['ROIne_params']\n",
    "# #         if 'hash_dict_true' in fig_gen_params:\n",
    "# #             hash_dict_true = fig_gen_params['hash_dict_true']\n",
    "# #         else:\n",
    "# #             hash_dict_true = {}\n",
    "# #         roinet = ROInet.ROInet_embedder(device=DEVICE, hash_dict_networkFiles=hash_dict_true, **ROIne_params)\n",
    "# #         # roinet = ROInet.ROInet_embedder(device=DEVICE, hash_dict_networkFiles=hash_dict_true, **ROIne_params)\n",
    "\n",
    "# #         ROIne_gen_dataloader_params = fig_gen_params['ROIne_gen_dataloader_params']\n",
    "# #         roinet.generate_dataloader(ROI_images=images_labeled, numWorkers_dataloader=mp.cpu_count(), **ROIne_gen_dataloader_params);\n",
    "\n",
    "# #         roinet.generate_latents();\n",
    "\n",
    "# class Embedder():\n",
    "    def __init__(self):\n",
    "        # Get Embeddings\n",
    "\n",
    "        umap_params = dict(\n",
    "            n_neighbors=30,\n",
    "            n_components=2,\n",
    "            metric='euclidean',\n",
    "            metric_kwds=None,\n",
    "            output_metric='euclidean',\n",
    "            output_metric_kwds=None,\n",
    "            n_epochs=None,\n",
    "            learning_rate=1.0,\n",
    "            init='spectral',\n",
    "            min_dist=0.1,\n",
    "            spread=1.0,\n",
    "            low_memory=True,\n",
    "            n_jobs=-1,\n",
    "            set_op_mix_ratio=1.0,\n",
    "            local_connectivity=1.0,\n",
    "            repulsion_strength=1.0,\n",
    "            negative_sample_rate=5,\n",
    "            transform_queue_size=4.0,\n",
    "            a=None,\n",
    "            b=None,\n",
    "            random_state=None,\n",
    "            angular_rp_forest=False,\n",
    "            target_n_neighbors=-1,\n",
    "            target_metric='categorical',\n",
    "            target_metric_kwds=None,\n",
    "            target_weight=0.5,\n",
    "            transform_seed=42,\n",
    "            transform_mode='embedding',\n",
    "            force_approximation_algorithm=False,\n",
    "            verbose=False,\n",
    "            tqdm_kwds=None,\n",
    "            unique=False,\n",
    "            densmap=False,\n",
    "            dens_lambda=2.0,\n",
    "            dens_frac=0.3,\n",
    "            dens_var_shift=0.1,\n",
    "            output_dens=False,\n",
    "            disconnection_distance=None,\n",
    "            precomputed_knn=(None, None, None),\n",
    "        )\n",
    "\n",
    "        umap = UMAP(**umap_params)\n",
    "        embeddings = umap.fit_transform(features_nn)\n",
    "        return\n",
    "    def fit(self):\n",
    "        \n",
    "        return\n",
    "    def transform(self):\n",
    "        \n",
    "        return\n",
    "    def fit_transform(self, x):\n",
    "        self.fit(x)\n",
    "        return self.transform(x)\n",
    "\n",
    "class Classifier():\n",
    "    def __init__(self):\n",
    "        return\n",
    "    def pca(self):\n",
    "#         # PCA\n",
    "#         comp_nn, scores_nn, SVs, EVR_nn = decomposition.torch_pca(features_nn, zscore=False)\n",
    "#         # scores_nn = features_nn\n",
    "\n",
    "#         # Normalize PCA'd Values\n",
    "#         features_norm = torch.cat([_ / torch.std(_, dim=0).mean() for _ in [scores_nn]], dim=1)\n",
    "#         # features_norm = scores_nn\n",
    "        return\n",
    "    \n",
    "\n",
    "class Visualization():\n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b84fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db3ae2f7",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97949d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conda Environment: ROI_env\n",
      "python version: 3.8.13\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "# check environment\n",
    "import os\n",
    "print(f'Conda Environment: ' + os.environ['CONDA_DEFAULT_ENV'])\n",
    "\n",
    "from platform import python_version\n",
    "print(f'python version: {python_version()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e36ab5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy Version: 1.21.6\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import importlib.util\n",
    "import glob\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from umap import UMAP\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit, StratifiedShuffleSplit\n",
    "import scipy.stats\n",
    "import scipy.signal\n",
    "from kymatio import Scattering2D\n",
    "import json\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import h5py\n",
    "# import figgen as fg\n",
    "import sys\n",
    "import time\n",
    "import gc\n",
    "\n",
    "print('Numpy Version:', np.__version__)\n",
    "# print('TorchVision Version:',torchvision.__version__)\n",
    "\n",
    "dir_github = Path(r'/n/data1/hms/neurobio/sabatini/josh/github_repos/').resolve()\n",
    "\n",
    "import sys\n",
    "sys.path.append(str(dir_github))\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ROICaT.tracking import data_importing, visualization, alignment, blurring, helpers, ROInet, scatteringWaveletTransformer, similarity_graph, clustering\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a45cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72274363",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "toc = {}\n",
    "toc['start'] = time.time() - tic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8673d43",
   "metadata": {},
   "source": [
    "# Import Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54c375e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spr(*directory_list):\n",
    "    for dir_num, directory in enumerate(directory_list):\n",
    "        if dir_num == 0:\n",
    "            full_directory = Path(directory)\n",
    "        else:\n",
    "            full_directory = full_directory / directory\n",
    "    return str(full_directory.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7f6d2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_list(l):\n",
    "    for item in l:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcc7d099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir_allOuterFolders = Path(r\"/media/rich/bigSSD/other lab data/Harnett_lab/ROI_Tracking/Vincent_Valerio/4th_email/AllStatFiles/rbp16\").resolve()\n",
    "# # dir_allOuterFolders = Path(r\"/media/rich/bigSSD/res2p/scanimage data/round 5 experiments/mouse 2_6/just_stat_files\").resolve()\n",
    "\n",
    "# folders_allSessions = natsort.natsorted(helpers.get_dir_contents(dir_allOuterFolders)[0])\n",
    "\n",
    "# dir_allS2pFolders = [dir_allOuterFolders / folder for folder in folders_allSessions]\n",
    "\n",
    "# pathSuffixToStat = 'plane0/stat.npy'\n",
    "# pathSuffixToOps = 'plane0/ops.npy'\n",
    "# # pathSuffixToStat = 'stat.npy'\n",
    "# # pathSuffixToOps = 'ops.npy'\n",
    "\n",
    "# paths_allStat = np.array([path / pathSuffixToStat for path in dir_allS2pFolders])[:]\n",
    "# paths_allOps  = np.array([path / pathSuffixToOps for path in dir_allS2pFolders])[:]\n",
    "# # paths_allStat = np.array([path / pathSuffixToStat for path in dir_allS2pFolders])\n",
    "# # paths_allOps  = np.array([path / pathSuffixToOps for path in dir_allS2pFolders])\n",
    "\n",
    "# print(f'folder names of all sessions: \\n{folders_allSessions}')\n",
    "# print(f'paths to all stat files: \\n{paths_allStat}')\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "# || Specify Raw Data Filename Sources ||\n",
    "# ---------------------------------------\n",
    "stat_files = spr('/n/data1/hms/neurobio/sabatini/josh/github_repos/GCaMP_ROI_classifier/data/training/mouse2_6__20210409/stat.npy')\n",
    "label_files = spr('/n/data1/hms/neurobio/sabatini/josh/github_repos/GCaMP_ROI_classifier/data/training/mouse2_6__20210409/labels_round2_sesh2.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d01ca7b",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4179f95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: Importing spatial footprints from stat files\n",
      "Completed: Imported 4898 stat files into class as self.statFiles. Total number of ROIs: 4898. Number of ROI from each file: [4898]\n",
      "Starting: Importing labels footprints from npy files\n",
      "Completed: Imported 4898 labels into class as self.labelFiles. Total number of ROIs: 4898. Number of ROI from each file: [4898]\n"
     ]
    }
   ],
   "source": [
    "data = Data(\n",
    "    paths_statFiles=stat_files,\n",
    "    paths_labelFiles=label_files,\n",
    "    um_per_pixel=1.0,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "data.import_statFiles();\n",
    "data.import_labelFiles();\n",
    "\n",
    "# data.import_ROI_spatialFootprints(workers=-1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8363c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "\n",
    "# # From ROICaT\n",
    "# visualization.display_toggle_image_stack(np.concatenate(data.ROI_images, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5a179d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "toc['import_data'] = time.time() - tic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83365f09",
   "metadata": {},
   "source": [
    "# Concatenate / Adjust / Clean Data + Drop Non-Nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff4c6f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_nan_rois();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232dd31e",
   "metadata": {},
   "source": [
    "# Neural Network Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ea0ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful hash comparison. Found matching files: {'params': '/n/data1/hms/neurobio/sabatini/josh/analysis/roinet-paper/ROICaT/params.json', 'model': '/n/data1/hms/neurobio/sabatini/josh/analysis/roinet-paper/ROICaT/model.py', 'state_dict': '/n/data1/hms/neurobio/sabatini/josh/analysis/roinet-paper/ROICaT/ConvNext_tiny__1_0_best__simCLR.pth'}\n",
      "Imported model from /n/data1/hms/neurobio/sabatini/josh/analysis/roinet-paper/ROICaT/model.py\n",
      "Loaded params_model from /n/data1/hms/neurobio/sabatini/josh/analysis/roinet-paper/ROICaT/params.json\n",
      "Generated network using params_model\n",
      "Loaded state_dict into network from /n/data1/hms/neurobio/sabatini/josh/analysis/roinet-paper/ROICaT/ConvNext_tiny__1_0_best__simCLR.pth\n",
      "Loaded network onto device cuda:0\n",
      "Starting: resizing ROIs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4898/4898 [00:11<00:00, 436.06it/s]\n",
      "/home/joz608/.conda/envs/ROI_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py:487: UserWarning: This DataLoader will create 48 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: resizing ROIs\n",
      "Defined image transformations: Sequential(\n",
      "  (0): ScaleDynamicRange(scaler_bounds=(0, 1))\n",
      "  (1): Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n",
      "  (2): TileChannels(dim=0)\n",
      ")\n",
      "Defined dataset\n",
      "Defined dataloader\n",
      "starting: running data through network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/22041 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "hash_dict_true = {\n",
    "    'params': ('params.json', '68cf1bd47130f9b6d4f9913f86f0ccaa'),\n",
    "    'model': ('model.py', '61c85529b7aa33e0dfadb31ee253a7e1'),\n",
    "    'state_dict': ('ConvNext_tiny__1_0_best__simCLR.pth', '3287e001ff28d07ada2ae70aa7d0a4da'),\n",
    "}\n",
    "\n",
    "roinet = ROInet.ROInet_embedder(\n",
    "    device='cuda:0',\n",
    "#     dir_networkFiles='/home/rich/Downloads/ROInet',\n",
    "    dir_networkFiles='/n/data1/hms/neurobio/sabatini/josh/analysis/roinet-paper/ROICaT',\n",
    "    \n",
    "#     download_from_gDrive='force_download',\n",
    "#     download_from_gDrive='force_local',\n",
    "    download_from_gDrive='check_local_first',\n",
    "    gDriveID='1D2Qa-YUNX176Q-wgboGflW0K6un7KYeN',\n",
    "    hash_dict_networkFiles=hash_dict_true,\n",
    "#     hash_dict_networkFiles=None,\n",
    "    forward_pass_version='latent',\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "roinet.generate_dataloader(\n",
    "    ROI_images=data.statFiles,\n",
    "    um_per_pixel=data.um_per_pixel,\n",
    "    pref_plot=False,\n",
    "    batchSize_dataloader=8,\n",
    "    pinMemory_dataloader=True,\n",
    "    numWorkers_dataloader=mp.cpu_count(),\n",
    "    persistentWorkers_dataloader=True,\n",
    "    prefetchFactor_dataloader=2,    \n",
    ");\n",
    "\n",
    "roinet.generate_latents();\n",
    "\n",
    "# roinet.latents\n",
    "# roinet.dataset\n",
    "# roinet.net\n",
    "# roinet.params_model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1c20ef0c",
   "metadata": {},
   "source": [
    "#         raw_images = roinet.ROI_images_rs\n",
    "#         raw_images_dup = np.concatenate([raw_images for _ in range(len(raw_labels_match))], axis=0)\n",
    "\n",
    "#         self.latents = roinet.latents\n",
    "#         latents_dup = np.concatenate([latents for _ in range(len(raw_labels_match))], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1419d5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb8a9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "toc['NN'] = time.time() - tic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6500d0",
   "metadata": {},
   "source": [
    "# UMAP Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537bf8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_params = dict(\n",
    "    n_neighbors=30,\n",
    "    n_components=2,\n",
    "    metric='euclidean',\n",
    "    metric_kwds=None,\n",
    "    output_metric='euclidean',\n",
    "    output_metric_kwds=None,\n",
    "    n_epochs=None,\n",
    "    learning_rate=1.0,\n",
    "    init='spectral',\n",
    "    min_dist=0.1,\n",
    "    spread=1.0,\n",
    "    low_memory=True,\n",
    "    n_jobs=-1,\n",
    "    set_op_mix_ratio=1.0,\n",
    "    local_connectivity=1.0,\n",
    "    repulsion_strength=1.0,\n",
    "    negative_sample_rate=5,\n",
    "    transform_queue_size=4.0,\n",
    "    a=None,\n",
    "    b=None,\n",
    "    random_state=None,\n",
    "    angular_rp_forest=False,\n",
    "    target_n_neighbors=-1,\n",
    "    target_metric='categorical',\n",
    "    target_metric_kwds=None,\n",
    "    target_weight=0.5,\n",
    "    transform_seed=42,\n",
    "    transform_mode='embedding',\n",
    "    force_approximation_algorithm=False,\n",
    "    verbose=False,\n",
    "    tqdm_kwds=None,\n",
    "    unique=False,\n",
    "    densmap=False,\n",
    "    dens_lambda=2.0,\n",
    "    dens_frac=0.3,\n",
    "    dens_var_shift=0.1,\n",
    "    output_dens=False,\n",
    "    disconnection_distance=None,\n",
    "    precomputed_knn=(None, None, None),\n",
    ")\n",
    "\n",
    "umap = UMAP(**umap_params)\n",
    "print('Fitting UMAP...')\n",
    "umap.fit(roinet.latents)\n",
    "print('Generating Embeddings...')\n",
    "embeddings = umap.transform(roinet.latents)\n",
    "print('Embeddings Generated...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2128141",
   "metadata": {},
   "source": [
    "# Visualize Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043fd0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5,5))\n",
    "ax.scatter(embeddings[:,0], embeddings[:,1], s=5, c=used_labels, cmap='gist_rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd1e05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "toc['visualize'] = time.time() - tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c45fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393f0c10",
   "metadata": {},
   "source": [
    "# Load / Setup Classifier — ZScore + PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97205953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # features_nn = torch.cat(tmp_arr, dim=0)\n",
    "\n",
    "# features_nn = latents_clean\n",
    "\n",
    "# # prv_features_nn = features_nn.numpy().copy()\n",
    "\n",
    "# features_nn_z = scipy.stats.zscore(features_nn, axis=0)\n",
    "# features_nn_z = features_nn_z[:, ~np.isnan(features_nn_z[0,:])]\n",
    "# features_nn_z = torch.as_tensor(features_nn_z, dtype=torch.float32)\n",
    "\n",
    "# # # PCA\n",
    "# comp_nn, scores_nn, SVs, EVR_nn = decomposition.torch_pca(features_nn, zscore=False)\n",
    "# # scores_nn = features_nn\n",
    "\n",
    "# # Normalize PCA'd Values\n",
    "# features_norm = torch.cat([_ / torch.std(_, dim=0).mean() for _ in [scores_nn]], dim=1)\n",
    "# # features_norm = scores_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee49aa93",
   "metadata": {},
   "source": [
    "## Train/Holdout Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af582cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train/Holdout Split\n",
    "# features_train, features_holdout, labels_train, labels_holdout = sklearn.model_selection.train_test_split(features_norm, labels_clean[:features_norm.shape[0]], test_size=0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071cd712",
   "metadata": {},
   "source": [
    "## Shuffle Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb025cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Shuffle Split\n",
    "# splitter = ShuffleSplit(n_splits=classifier_n_splits)\n",
    "# all_split_inx = list(splitter.split(features_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f17b9d",
   "metadata": {},
   "source": [
    "## Train'/Val Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd57c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Train'/Val Extract\n",
    "# trainp_X = [features_train[_[0]] for _ in all_split_inx]\n",
    "# val_X = [features_train[_[1]] for _ in all_split_inx]\n",
    "# trainp_y = [labels_train[_[0]] for _ in all_split_inx]\n",
    "# val_y = [labels_train[_[1]] for _ in all_split_inx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcc5ea7",
   "metadata": {},
   "source": [
    "## Fit Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c727450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sweep through regularizations for classifier\n",
    "# for ic, c in enumerate(C_toUse):\n",
    "#     cm_trp_lst = []\n",
    "#     cm_val_lst = []\n",
    "\n",
    "#     cm_trp_cnt_lst = []\n",
    "#     cm_val_cnt_lst = []\n",
    "\n",
    "#     acc_trp_lst = []\n",
    "#     acc_val_lst = []\n",
    "\n",
    "#     # Sweep Through Shuffle Splits\n",
    "#     # trp = Train' or train within single Shuffle Split fold\n",
    "#     # val = Validation or test set within single Shuffle Split fold\n",
    "#     for inx_split in trange(len(trainp_X)):\n",
    "#         tmp_trainp_X = trainp_X[inx_split]\n",
    "#         tmp_trainp_y = trainp_y[inx_split]\n",
    "\n",
    "#         tmp_val_X = val_X[inx_split]\n",
    "#         tmp_val_y = val_y[inx_split]\n",
    "\n",
    "#         logreg = fg.fit_classifier_logreg(tmp_trainp_X, tmp_trainp_y, max_iter=logistic_max_iter, C=c)\n",
    "\n",
    "#         cm_trp = fg.cm_classifier_logreg(logreg, tmp_trainp_X, tmp_trainp_y, github_loc=fig_gen_params['github_loc'])\n",
    "#         cm_val = fg.cm_classifier_logreg(logreg, tmp_val_X, tmp_val_y, github_loc=fig_gen_params['github_loc'])\n",
    "\n",
    "#         cm_trp_cnt = fg.cm_classifier_logreg(logreg, tmp_trainp_X, tmp_trainp_y, counts=True, github_loc=fig_gen_params['github_loc'])\n",
    "#         cm_val_cnt = fg.cm_classifier_logreg(logreg, tmp_val_X, tmp_val_y, counts=True, github_loc=fig_gen_params['github_loc'])\n",
    "\n",
    "#         acc_trp = fg.score_classifier_logreg(logreg, tmp_trainp_X, tmp_trainp_y)\n",
    "#         acc_val = fg.score_classifier_logreg(logreg, tmp_val_X, tmp_val_y)\n",
    "\n",
    "#         cm_trp_lst.append(cm_trp)\n",
    "#         cm_val_lst.append(cm_val)\n",
    "\n",
    "#         cm_trp_cnt_lst.append(cm_trp_cnt)\n",
    "#         cm_val_cnt_lst.append(cm_val_cnt)\n",
    "\n",
    "#         acc_trp_lst.append(acc_trp)\n",
    "#         acc_val_lst.append(acc_val)\n",
    "    \n",
    "    \n",
    "#     cm_trp_mn = np.mean(cm_trp_lst,axis=0)\n",
    "#     cm_val_mn = np.mean(cm_val_lst,axis=0)\n",
    "\n",
    "#     cm_trp_cnt_sm = np.sum(cm_trp_cnt_lst,axis=0)\n",
    "#     cm_val_cnt_sm = np.sum(cm_val_cnt_lst,axis=0)\n",
    "\n",
    "#     # Refitting model to all of training / CV data and evaluating on heldout data\n",
    "#     logreg_refit = fg.fit_classifier_logreg(features_train, labels_train, max_iter=logistic_max_iter, C=c)\n",
    "\n",
    "#     cm_tr = fg.cm_classifier_logreg(logreg_refit, features_train, labels_train, counts=False, github_loc=fig_gen_params['github_loc'])\n",
    "#     cm_ho = fg.cm_classifier_logreg(logreg_refit, features_holdout, labels_holdout, counts=False, github_loc=fig_gen_params['github_loc'])\n",
    "\n",
    "#     cm_tr_cnt = fg.cm_classifier_logreg(logreg_refit, features_train, labels_train, counts=True, github_loc=fig_gen_params['github_loc'])\n",
    "#     cm_ho_cnt = fg.cm_classifier_logreg(logreg_refit, features_holdout, labels_holdout, counts=True, github_loc=fig_gen_params['github_loc'])\n",
    "\n",
    "#     acc_tr = fg.score_classifier_logreg(logreg_refit, features_train, labels_train)\n",
    "#     acc_ho = fg.score_classifier_logreg(logreg_refit, features_holdout, labels_holdout)\n",
    "    \n",
    "#     restricted_n_train_results = {}\n",
    "#     for n_train in n_train_to_use:\n",
    "#         print('Saving: n_train',n_train)\n",
    "#         train_size = n_train/features_train.shape[0] if type(n_train) == type(None) and n_train < features_train else None\n",
    "#         print('Saving: train_size',train_size)\n",
    "#         if train_size is not None:\n",
    "#             # Refitting model to n_train data points from training data / and evaluating on heldout data\n",
    "#             sss = StratifiedShuffleSplit(n_splits=1, train_size=train_size)\n",
    "#             train_subset_inx, _ = sss.split(features_train, labels_train)[0]\n",
    "#             features_train_subset, labels_train_subset = features_train[train_subset_inx], labels_train[train_subset_inx]\n",
    "            \n",
    "#             logreg_refit = fg.fit_classifier_logreg(features_train_subset, labels_train_subset, max_iter=logistic_max_iter, C=c)\n",
    "            \n",
    "#             restricted_n_train_results[f'acc_tr_subset_{n_train}'] = fg.score_classifier_logreg(logreg_refit, features_train_subset, labels_train_subset)\n",
    "#             restricted_n_train_results[f'acc_tr_{n_train}'] = fg.score_classifier_logreg(logreg_refit, features_train, labels_train)\n",
    "#             restricted_n_train_results[f'acc_ho_{n_train}'] = fg.score_classifier_logreg(logreg_refit, features_holdout, labels_holdout)\n",
    "    \n",
    "#     with h5py.File(fig_gen_params['h5_out_name'], 'a') as f:\n",
    "#         g = f.create_group(f'creg_{c}')\n",
    "#         g.attrs['acc_tr'] = np.mean(acc_tr)\n",
    "#         g.attrs['acc_trp'] = np.mean(acc_trp_lst)\n",
    "#         g.attrs['acc_val'] = np.mean(acc_val_lst)\n",
    "#         g.attrs['acc_ho'] = np.mean(acc_ho)\n",
    "        \n",
    "#         for n_train in n_train_to_use:\n",
    "#             print('Saving: n_train',n_train)\n",
    "#             train_size = n_train/features_train.shape[0] if type(n_train) == type(None) and n_train < features_train else None\n",
    "#             print('Saving: train_size',train_size)\n",
    "#             if train_size is not None:\n",
    "#                 g.attrs[f'acc_tr_subset_{n_train}'] = restricted_n_train_results[f'acc_tr_subset_{n_train}']\n",
    "#                 g.attrs[f'acc_tr_{n_train}'] = restricted_n_train_results[f'acc_tr_{n_train}']\n",
    "#                 g.attrs[f'acc_ho_{n_train}'] = restricted_n_train_results[f'acc_ho_{n_train}']\n",
    "\n",
    "#         gg = g.create_group(f'cm_prc')\n",
    "\n",
    "#         gg.create_dataset(f'tr', data=cm_tr)\n",
    "#         gg.create_dataset(f'trp', data=cm_trp_mn)\n",
    "#         gg.create_dataset(f'val', data=cm_val_mn)\n",
    "#         gg.create_dataset(f'ho', data=cm_ho)\n",
    "\n",
    "#         gg = g.create_group(f'cm_count')\n",
    "\n",
    "#         gg.create_dataset(f'tr', data=cm_tr_cnt)\n",
    "#         gg.create_dataset(f'trp', data=cm_trp_cnt_sm)\n",
    "#         gg.create_dataset(f'val', data=cm_val_cnt_sm)\n",
    "#         gg.create_dataset(f'ho', data=cm_ho_cnt)\n",
    "\n",
    "#         gg = g.create_group(f'logreg_model')\n",
    "\n",
    "#         gg.create_dataset(f'coef', data=logreg_refit.coef_)\n",
    "#         gg.create_dataset(f'int', data=logreg_refit.intercept_)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019f193b",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c57700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir_save = Path('/home/rich/Desktop/').resolve()\n",
    "dir_save = Path('/n/data1/hms/neurobio/sabatini/josh/analysis/roinet-paper/ROICaT/output/').resolve()\n",
    "name_save = dir_allOuterFolders.name\n",
    "path_save = dir_save / (name_save + '.ROICaT.results' + '.pkl')\n",
    "\n",
    "ROIs = {\n",
    "    \"ROIs_aligned\": aligner.ROIs_aligned,\n",
    "    \"ROIs_raw\": data.spatialFootprints,\n",
    "    \"frame_height\": data.FOV_height,\n",
    "    \"frame_width\": data.FOV_width,\n",
    "    \"idx_roi_session\": np.where(data.sessionID_concat)[1]\n",
    "}\n",
    "\n",
    "results = {\n",
    "    \"UCIDs\": labels,\n",
    "    \"UCIDs_bySession\": labels_bySession,\n",
    "    \"ROIs\": ROIs,\n",
    "}\n",
    "\n",
    "helpers.simple_save(\n",
    "    obj=results,\n",
    "    filename=path_save,\n",
    "    mkdir=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565a7b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "toc['saving'] = time.time() - tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0407b108",
   "metadata": {},
   "outputs": [],
   "source": [
    "toc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1143fff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sweep through regularizations for classifier\n",
    "\n",
    "    # Sweep Through Shuffle Splits\n",
    "\n",
    "    # Refitting model to all of training / CV data and evaluating on heldout data\n",
    "\n",
    "            # Refitting model to n_train data points from training data / and evaluating on heldout data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

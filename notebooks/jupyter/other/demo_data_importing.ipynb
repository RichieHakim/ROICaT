{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7864836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# widen jupyter notebook window\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:95% !important; }</style>\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82e7486e",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "#### Welcome to a demo notebook on different methods for ingesting diverse data into ROICaT. There are 3 sections:\n",
    "\n",
    "- [Section 1](#Section-1): Ingesting data from **different segmentation packages** (Suite2p, CaImAn, CNMF, NWB, etc.).\n",
    "- [Section 2](#Section-2): **Understanding** the `Data_roicat` class.\n",
    "- [Section 3](#Section-3): Ingesting **custom data**.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1e739fc0",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b1f992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "from IPython.display import display\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c4421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import roicat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "57ce6ec6",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4cbfa33a",
   "metadata": {},
   "source": [
    "# Section 1\n",
    "## Ingesting different data sources"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b33df0e",
   "metadata": {},
   "source": [
    "We've made a few subclasses that make ingesting this data from various sources easy. These sources include:\n",
    "```\n",
    "- Raw data ----- via Data_roicat\n",
    "- Suite2p ------ via Data_suite2p or Data_roiextractors\n",
    "- CaImAn ------- via Data_caiman or Data_roiextractors\n",
    "- CNMF --------- via Data_roiextractors\n",
    "- NWB ---------- via Data_roiextractors\n",
    "- Sima --------- via Data_roiextractors\n",
    "- EXTRACT ------ via Data_roiextractors\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03fd5791",
   "metadata": {},
   "source": [
    "##### Download data\n",
    "\n",
    "Let's first download a single dataset that has been processed by each segmentation method above. This data was curated by the good folks at [CatalystNeuro](https://www.catalystneuro.com/), which makes [roiextractors](https://github.com/catalystneuro/roiextractors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c71a306",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_download_temp = tempfile.gettempdir()\n",
    "path_download_temp = str(Path(dir_download_temp) / 'datasets_roiextractors.zip')\n",
    "\n",
    "roicat.helpers.download_file(\n",
    "    url='https://osf.io/db5h8/download',\n",
    "    path_save=path_download_temp,\n",
    ")\n",
    "paths_extracted = roicat.helpers.extract_zip(\n",
    "    path_zip=path_download_temp,\n",
    "    path_extract=None,\n",
    "    verbose=True,\n",
    ");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd83a2be",
   "metadata": {},
   "source": [
    "### Make `Data_roiextractors` objects\n",
    "Let's make first `roiextractors` objects out of each of these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14479151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import roiextractors\n",
    "\n",
    "dir_segData = paths_extracted[0]\n",
    "\n",
    "re_caiman = roiextractors.CaimanSegmentationExtractor(file_path=str(Path(dir_segData) / 'caiman' / 'caiman_analysis.hdf5'))\n",
    "re_cnmfe = roiextractors.CnmfeSegmentationExtractor(file_path=str(Path(dir_segData) / 'cnmfe' / '2014_04_01_p203_m19_check01_cnmfeAnalysis.mat'))\n",
    "re_EXTRACT = roiextractors.ExtractSegmentationExtractor(file_path=str(Path(dir_segData) / 'extract' / 'extract_public_output.mat'), sampling_frequency=30)\n",
    "re_NWB = roiextractors.NwbSegmentationExtractor(file_path=str(Path(dir_segData) / 'nwb' / 'nwb_test.nwb'))\n",
    "re_s2p = roiextractors.Suite2pSegmentationExtractor(folder_path=str(Path(dir_segData) / 'suite2p'), plane_no=0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17f8c942",
   "metadata": {},
   "source": [
    "Next, let's convert the `roiextractors` object to `Data_roicat` objects by using the `Data_roiextractors` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2b8a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_re_caiman = roicat.data_importing.Data_roiextractors(re_caiman)\n",
    "display(data_re_caiman)\n",
    "data_re_cnmfe = roicat.data_importing.Data_roiextractors(re_cnmfe)\n",
    "display(data_re_cnmfe)\n",
    "data_re_EXTRACT = roicat.data_importing.Data_roiextractors(re_EXTRACT)\n",
    "display(data_re_EXTRACT)\n",
    "data_re_NWB = roicat.data_importing.Data_roiextractors(re_NWB)\n",
    "display(data_re_NWB)\n",
    "data_re_s2p = roicat.data_importing.Data_roiextractors(re_s2p)\n",
    "display(data_re_s2p)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "05e41ec7",
   "metadata": {},
   "source": [
    "### Make `Data_suite2p` and `Data_caiman` objects\n",
    "\n",
    "For suite2p and CaImAn, we recommend using our built in data ingestion classes. These collect a little more information and can be faster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5257f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_roicat_s2p = roicat.data_importing.Data_suite2p(\n",
    "    paths_statFiles=str(Path(dir_segData) / 'suite2p' / 'plane0' / 'stat.npy'),\n",
    "    paths_opsFiles=str(Path(dir_segData) / 'suite2p' / 'plane0' / 'ops.npy'),\n",
    ")\n",
    "display(data_roicat_s2p)\n",
    "\n",
    "data_roicat_caiman = roicat.data_importing.Data_caiman(\n",
    "    paths_resultsFiles=str(Path(dir_segData) / 'caiman' / 'caiman_analysis.hdf5')\n",
    ")\n",
    "display(data_roicat_caiman)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b89f871c",
   "metadata": {},
   "source": [
    "## Make multisession objects\n",
    "\n",
    "Normally we are using ROICaT with multiple sessions of data. To do this, just pass in a list of paths or roiextractors objects where each element is from one session."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1674d55f",
   "metadata": {},
   "source": [
    "#### Multisession `Data_roiextractors`\n",
    "\n",
    "We will simulate having multiple sessions of a dataset from the EXTRACT pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c505fe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_multi_EXTRACT = [roiextractors.ExtractSegmentationExtractor(file_path=path, sampling_frequency=30) for path in [str(Path(dir_segData) / 'extract' / 'extract_public_output.mat')]*10]\n",
    "\n",
    "print(f'Number of sessions: {len(re_multi_EXTRACT)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1001189",
   "metadata": {},
   "source": [
    "Now let's make a single `Data_roiextractors` object containing all these sessions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92e1fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_roicat_multi_EXTRACT = roicat.data_importing.Data_roiextractors(segmentation_extractor_objects=re_multi_EXTRACT)\n",
    "display(data_roicat_multi_EXTRACT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "025f0504",
   "metadata": {},
   "source": [
    "You'll see that this object now stores data from all 10 of these sessions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f76db37c",
   "metadata": {},
   "source": [
    "#### Multisession `Data_suite2p`\n",
    "\n",
    "Now let's do it with the `Data_suite2p` class (recommended for suite2p data). This data was collected and provided by Valerio Francioni while in Mark Harnett's lab at MIT:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f1575df",
   "metadata": {},
   "source": [
    "*Download*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eba1f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define temporary directory to save files to\n",
    "dir_temp = tempfile.gettempdir()\n",
    "path_test_temp = str(Path(dir_temp) / 'data_valerio.zip')\n",
    "\n",
    "## Download zip file\n",
    "roicat.helpers.download_file(\n",
    "    url='https://osf.io/ru4x5/download',\n",
    "    path_save=path_test_temp,\n",
    ")\n",
    "## Extract zip file\n",
    "paths_extracted = roicat.helpers.extract_zip(\n",
    "    path_zip=path_test_temp,\n",
    "    path_extract=None,\n",
    ")\n",
    "dir_test_data = paths_extracted[0]\n",
    "display(f'Downloaded and extracted folder containing test data to: {dir_test_data}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "370ff912",
   "metadata": {},
   "source": [
    "*Initialize class*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4602c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make paired lists of all the stat.npy and ops.npy files\n",
    "paths_stat = roicat.helpers.find_paths(\n",
    "    dir_outer=dir_test_data,\n",
    "    reMatch='stat.npy',\n",
    "    depth=4,\n",
    ")\n",
    "paths_ops = [str(Path(p).parent / 'ops.npy') for p in paths_stat]\n",
    "\n",
    "## Initialize the class\n",
    "data_roicat_multi_suite2p = roicat.data_importing.Data_suite2p(\n",
    "    paths_statFiles=paths_stat,\n",
    "    paths_opsFiles=paths_ops,\n",
    ")\n",
    "\n",
    "display(data_roicat_multi_suite2p)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db33e81e",
   "metadata": {},
   "source": [
    "And that's it, you now know how to use data from almost any segmentation pipeline to make a data object that can be used for any of the 3 pipelines in ROICaT. Let's finish by looking at some of the properties of these objects."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62f25d31",
   "metadata": {},
   "source": [
    "# Section 2\n",
    "## Understanding the `Data_roicat` class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8583c058",
   "metadata": {},
   "source": [
    "All raw data is ingested and stored through a custom python superclass called `Data_roicat` which standardizes data that comes from different sources. The main types of data it ingests are:\n",
    "1. `spatialFootprints`: The images of individual ROIs within the field of view\n",
    "2. `FOV_images`: The image of the field of view itself (e.g. the mean fluorescence image of the raw movie)\n",
    "3. `ROI_images`: Small images of individual ROIs\n",
    "4. `class_labels`: The labels associated with each ROI\n",
    "5. `um_per_pixel`: The resolution of the imaging field of view\n",
    "\n",
    "Let's demonstrate on **Suite2p** multisession test data from Valerio."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e1807813",
   "metadata": {},
   "source": [
    "#### `ROI_images`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc06ec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "roicat.visualization.display_toggle_image_stack(data_roicat_multi_suite2p.ROI_images[0], image_size=(200,200))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "373b7963",
   "metadata": {},
   "source": [
    "#### `FOV_images`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1ad92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "roicat.visualization.display_toggle_image_stack(data_roicat_multi_suite2p.FOV_images, image_size=(400,400))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1cd543aa",
   "metadata": {},
   "source": [
    "#### `spatialFootprints`\n",
    "ROIs from each session are stored as a scipy sparse array. Each sparse array is of shape: (`n_ROIs`, `height * width`). Notice that height and width dimension have been flattened into one dimension. We can reconstruct what a max intensity projection of ROIs looks like with the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e709c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data_roicat_multi_suite2p.spatialFootprints)\n",
    "\n",
    "height_width = (data_roicat_multi_suite2p.FOV_height, data_roicat_multi_suite2p.FOV_width)\n",
    "\n",
    "FOVs_MIP_ROIs = [sf.max(0).toarray().reshape(height_width[0], height_width[1]) for sf in data_roicat_multi_suite2p.spatialFootprints]\n",
    "\n",
    "roicat.visualization.display_toggle_image_stack(FOVs_MIP_ROIs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f8100f8e",
   "metadata": {},
   "source": [
    "##### Check completeness of object\n",
    "\n",
    "Lastyl, there are 3 things a data object can be used for in ROICaT: **tracking**, **classification training**, and **classification inference**. Let's check to see what we can do with the data object we just made:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7835ce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_roicat_multi_suite2p.check_completeness()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "781e0a44",
   "metadata": {},
   "source": [
    "Looks like we can do **tracking** and **classification-inference**, but not **classification-training** because we don't have class labels for each ROI. This makes sense because this is a raw dataset and labeling wasn't performed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c1aa44f",
   "metadata": {},
   "source": [
    "# Section 3\n",
    "## Custom data class\n",
    "\n",
    "We can also make a `Data_roicat` object from scratch by populating the required data for what we want to do. Let's start with an empty object and call the `.check_completeness()` to see what it can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59c8914",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_custom = roicat.data_importing.Data_roicat()\n",
    "\n",
    "display(data_custom.check_completeness())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cebaad71",
   "metadata": {},
   "source": [
    "As mentioned before, there are 5 key types of data that can be stored in a `Data_roicat` object:\n",
    "1. `spatialFootprints`: The images of individual ROIs within the field of view\n",
    "2. `FOV_images`: The image of the field of view itself (e.g. the mean fluorescence image of the raw movie)\n",
    "3. `ROI_images`: Small images of individual ROIs\n",
    "4. `class_labels`: The labels associated with each ROI\n",
    "5. `um_per_pixel`: The resolution of the imaging field of view\n",
    "\n",
    "Different combinations are needed for each of the 3 pipelines, which can be viewed in the above print statement from `.check_completeness()`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ed85f4b",
   "metadata": {},
   "source": [
    "### Prepare data for *Classification-inference*\n",
    "\n",
    "Let's add the necessary data to do **'Classification-Inference'**: `'ROI_images'`, `'um_per_pixel'`. \n",
    "\n",
    "Let's just make up some fake data with the correct properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5836fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper function for making fake ROI_images data\n",
    "def make_ROIs(\n",
    "    n_sessions=10,\n",
    "    max_rois_per_session=100,\n",
    "    size_im=(36,36)\n",
    "):\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    import torchvision\n",
    "\n",
    "    roi_prototype = torch.zeros(size_im, dtype=torch.uint8)\n",
    "    roi_prototype[*torch.meshgrid(torch.arange(size_im[0]//2-8, size_im[0]//2+8), torch.arange(size_im[1]//2-8, size_im[1]//2+8), indexing='xy')] = 255\n",
    "    transforms = torch.nn.Sequential(*[\n",
    "        torchvision.transforms.RandomPerspective(distortion_scale=0.9, p=1.0),\n",
    "        torchvision.transforms.RandomAffine(0, scale=(2.0, 2.0))\n",
    "    ])\n",
    "    ROIs = [[transforms(torch.as_tensor(roi_prototype[None,:,:]))[0].numpy() for i_roi in range(max_rois_per_session)] for i_sesh in range(n_sessions)]\n",
    "    ROIs = [np.stack([roi for roi in ROIs_sesh if roi.sum() > 0], axis=0) for ROIs_sesh in ROIs]\n",
    "\n",
    "    return ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9086648",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI_images = make_ROIs(\n",
    "    n_sessions=10,\n",
    "    max_rois_per_session=100,\n",
    "    size_im=(36,36),\n",
    ")\n",
    "\n",
    "print(f'Number of sessions: {len(ROI_images)}')\n",
    "print(f'Number of ROIs per session: {[rois.shape[0] for rois in ROI_images]}')\n",
    "print(f'Shape of each ROI image: {ROI_images[0][0].shape}')\n",
    "\n",
    "roicat.visualization.display_toggle_image_stack(ROI_images[0], image_size=(200,200))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2dd7377",
   "metadata": {},
   "source": [
    "We've made `ROI_images`, which is a list of lists of 3D numpy arrays:\n",
    "\n",
    "Now let's add the ROIs_images to the data object. We will also add a `um_per_pixel` value, which is necessary for classification-inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7046dc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_custom.set_ROI_images(ROI_images, um_per_pixel=1.5)\n",
    "\n",
    "data_custom.check_completeness()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a90fcd5d",
   "metadata": {},
   "source": [
    "Notice that `'classification_inference': True'`, so we can use this data object for the **classification_inference** and **classification_by_Drawing** notebooks/pipelines."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "01845c51",
   "metadata": {},
   "source": [
    "### Prepare data for *Tracking*\n",
    "\n",
    "For tracking we need: `spatialFootprints`, `FOV_images`, `ROI_images`, and `um_per_pixel`.\n",
    "\n",
    "What is `spatialFootprints`? It is an array containing the spatial mask of each ROI within the full field of view (FOV). We use a compressed datatype called a ***sparse matrix*** which dramatically speeds up handling this kind of data. The `Data_roicat` object can ingest two kinds of input for spatial footprints:\n",
    "1. A list of normal numpy arrays of shape **(n_roi, FOV_height, FOV_width)**\n",
    "2. A list of our natively used datatype: `scipy.sparse.csr_matrix` arrays of shape **(n_roi, FOV_height * FOV_width)**\n",
    "\n",
    "Again, let's just make up some fake data with the correct properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bcac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sessions = 5\n",
    "size_im = (300,400)\n",
    "max_rois_per_session = 50\n",
    "\n",
    "spatialFootprints = make_ROIs(\n",
    "    n_sessions=n_sessions,\n",
    "    max_rois_per_session=max_rois_per_session,\n",
    "    size_im=size_im,\n",
    ")\n",
    "\n",
    "print(f'Number of sessions: {len(spatialFootprints)}')\n",
    "print(f'Number of ROIs per session: {[sf.shape[0] for sf in spatialFootprints]}')\n",
    "print(f'Shape of each spatialFootprints image: {spatialFootprints[0][0].shape}')\n",
    "\n",
    "roicat.visualization.display_toggle_image_stack(spatialFootprints[0], image_size=size_im)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c4a470a",
   "metadata": {},
   "source": [
    "Now let's make a new `Data_roicat` and populate it with `spatialFootprints`. Again we need to specify a `um_per_pixel` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e500836",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_custom = roicat.data_importing.Data_roicat()\n",
    "\n",
    "data_custom.set_spatialFootprints(\n",
    "    spatialFootprints=spatialFootprints,\n",
    "    um_per_pixel=2.0,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "317d8308",
   "metadata": {},
   "source": [
    "We could have also converted our input `spatialFootprints` into sparse arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30afd3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "\n",
    "spatialFootprints_sparse = [scipy.sparse.csr_matrix(sf.reshape(sf.shape[0], -1)) for sf in spatialFootprints]\n",
    "\n",
    "data_custom.set_spatialFootprints(\n",
    "    spatialFootprints=spatialFootprints_sparse,\n",
    "    um_per_pixel=2.0,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "635a4e21",
   "metadata": {},
   "source": [
    "We also need `FOV_images` for tracking, so lets make some fake mean FOV images **with the same shape and number of sessions as spatial footprints**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd56fafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_custom.set_FOV_images([np.random.rand(*size_im) for ii in range(n_sessions)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42707317",
   "metadata": {},
   "source": [
    "Finally, we can convert the `spatialFootprints` into ROI_images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce6c84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_custom._transform_spatialFootprints_to_ROIImages(out_height_width=(36, 36));"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b83ba28",
   "metadata": {},
   "source": [
    "Let's look at `.check_completeness()` again to see what we can do with this data object now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5913f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_custom.check_completeness()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e23e52ee",
   "metadata": {},
   "source": [
    "We can do **tracking** and **classification-inference** now!\n",
    "\n",
    "Let's finish the exercise by adding `class_labels` so that we can use this data object for **classification-training** as well.\n",
    "\n",
    "`class_labels` should be a list of lists of integers. The outer list of should be of length `n_sessions` and the inner lists should be of length `n_rois` for that session. Each element should be an integer, and the set of integers should be consecutive and non-negative (ie: 0,1,2,3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc22eea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_labels = np.array(['n', 'd', 'j'])  ## 'neuron', 'dendrite', 'junk'\n",
    "class_labels = [possible_labels[np.random.randint(0,3, size=n)] for n in data_custom.n_roi]  ## List of arrays of str\n",
    "\n",
    "data_custom.set_class_labels(labels=class_labels, n_classes=len(possible_labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24773706",
   "metadata": {},
   "source": [
    "You can also import `class_labels` from a file. Each file should correspond to one session. The files can either all be .npy files containing a 1D numpy array of length `n_roi` for that session, or a .npy / .pkl file containing dictionaries with the field `'labels'` that has the value of a 1D numpy array of length `n_roi`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd25534",
   "metadata": {},
   "outputs": [],
   "source": [
    "## From .npy files containing 1D arrays\n",
    "paths_temp_classLabels = [str(Path(tempfile.gettempdir()) / f'test_classLabels_{ii}.npy') for ii in range(n_sessions)]\n",
    "[np.save(p, l) for p, l in zip(paths_temp_classLabels, class_labels)]\n",
    "\n",
    "data_custom.set_class_labels(path_labels=paths_temp_classLabels, n_classes=len(possible_labels))\n",
    "\n",
    "## From .pkl files containing dictionaries with 'labels' field with values of 1D arrays\n",
    "paths_temp_classLabels = [str(Path(tempfile.gettempdir()) / f'test_classLabels_{ii}.pkl') for ii in range(n_sessions)]\n",
    "[roicat.helpers.pickle_save({'labels': l}, p) for p, l in zip(paths_temp_classLabels, class_labels)]\n",
    "\n",
    "data_custom.set_class_labels(path_labels=paths_temp_classLabels, n_classes=len(possible_labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e9eda11",
   "metadata": {},
   "source": [
    "Let's look at `.check_completeness()` again to see what we can do with this data object now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c2934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_custom.check_completeness()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "12875c3a",
   "metadata": {},
   "source": [
    "We can do everything now!\n",
    "\n",
    "To review we used all the following methods:\n",
    "```\n",
    "data_custom = roicat.data_importing.Data_roicat()\n",
    "data_custom.set_spatialFootprints(list of spatialFootprints, um_per_pixel)\n",
    "data_custom.set_FOV_images(list of images)\n",
    "data_custom._transform_spatialFootprints_to_ROIImages(height_width)\n",
    "data_custom.set_class_labels(class_labels, n_classes)\n",
    "data_custom.check_completeness()\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3abc80a1",
   "metadata": {},
   "source": [
    "### Thank you!\n",
    "\n",
    "Please let us know if you had any issues with this notebook in the github issues tab."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

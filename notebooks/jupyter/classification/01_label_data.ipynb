{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from bnpm import file_helpers, optimization\n",
    "import sklearn.utils.class_weight\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "import sklearn.linear_model\n",
    "import multiprocessing as mp\n",
    "\n",
    "import roicat.classification.classifier_util as cu\n",
    "import scipy.sparse\n",
    "import roicat\n",
    "import bnpm.h5_handling\n",
    "from pathlib import Path\n",
    "<<<<<<< local\n",
    "=======\n",
    "import sys\n",
    "from pathlib import Path\n",
    ">>>>>>> remote\n",
    "import shutil\n",
    "import warnings\n",
    "import umap\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.offsetbox\n",
    "<<<<<<< local\n",
    "import json\n",
    "import os\n",
    "import natsort\n",
    "from roicat import helpers\n",
    "# from kymatio.torch import Scattering2D\n",
    "import gc\n",
    "import functools\n",
    "=======\n",
    "import json\n",
    ">>>>>>> remote"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify Initial Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_params = None # Path(r\"\")\n",
    "<<<<<<< local\n",
    "directory_data = r'/Users/josh/analysis/outputs/ROICaT/classification/00_data_ingestion'\n",
    "=======\n",
    ">>>>>>> remote\n",
    "directory_save = r'/Users/josh/analysis/outputs/ROICaT/classification/01_labels'\n",
    "testing = True\n",
    "save_ROIs = True\n",
    "save_latents = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_save = Path(directory_save)\n",
    "directory_save.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "labelingRun_interim = {}\n",
    "\n",
    "if path_params is not None:\n",
    "    try:\n",
    "        Path(str((directory_save).resolve())).mkdir(exist_ok=True, parents=True)\n",
    "        shutil.copy2(path_params, str(Path(directory_save) / Path(path_params).name));\n",
    "    except Exception as e:\n",
    "        print(f'JZ: Error copying params to {directory_save}')\n",
    "        print(e)\n",
    "tic = time.time()\n",
    "tictoc = {}\n",
    "tictoc['start'] = time.time() - tic\n",
    "\n",
    "params = file_helpers.json_load(str(Path(path_params).resolve())) if path_params is not None else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95a4480",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**<<<<<<< local**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/josh/analysis/data/ROICaT/classification/stat_s2p/stat.npy']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['/Users/josh/analysis/data/ROICaT/classification/stat_s2p/ops.npy']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josh/analysis/github_repos/ROICaT/roicat/util.py:191: UserWarning: RH WARNING: unable to get cpu info. Got error: No module named 'cpuinfo'\n",
      "  warnings.warn(f'RH WARNING: unable to get cpu info. Got error: {e}')\n",
      "/Users/josh/analysis/github_repos/ROICaT/roicat/util.py:210: UserWarning: RH WARNING: unable to get gpu info. Got error: No module named 'GPUtil'\n",
      "  warnings.warn(f'RH WARNING: unable to get gpu info. Got error: {e}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: Importing FOV images from ops files\n",
      "Completed: Set FOV_height and FOV_width successfully.\n",
      "Completed: Imported 1 FOV images.\n",
      "Completed: Set FOV_images for 1 sessions successfully.\n",
      "Importing spatial footprints from stat files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported 1 sessions of spatial footprints into sparse arrays.\n",
      "Completed: Set spatialFootprints for 1 sessions successfully.\n",
      "Completed: Created session_bool.\n",
      "Completed: Created centroids.\n",
      "Staring: Creating centered ROI images from spatial footprints...\n",
      "Completed: Created ROI images.\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib notebook\n",
    "# dir_allOuterFolders = str(Path('/Users/josh/analysis/data/ROICaT/classification/raw_images').resolve())\n",
    "dir_allOuterFolders = str(Path('/Users/josh/analysis/data/ROICaT/classification/stat_s2p').resolve())\n",
    "\n",
    "pathSuffixToStat = 'stat.npy'\n",
    "pathSuffixToOps = 'ops.npy'\n",
    "\n",
    "paths_allStat = test = helpers.find_paths(\n",
    "    dir_outer=dir_allOuterFolders,\n",
    "    reMatch=pathSuffixToStat,\n",
    "    depth=4,\n",
    ")\n",
    "paths_allOps = test = helpers.find_paths(\n",
    "    dir_outer=dir_allOuterFolders,\n",
    "    reMatch=pathSuffixToOps,\n",
    "    depth=4,\n",
    ")\n",
    "\n",
    "display(paths_allStat)\n",
    "display(paths_allOps)\n",
    "\n",
    "#Import data\n",
    "data = roicat.data_importing.Data_suite2p(\n",
    "    paths_statFiles=paths_allStat,\n",
    "    paths_opsFiles=paths_allOps,\n",
    "    um_per_pixel=2.0,\n",
    "    new_or_old_suite2p='new',\n",
    "    out_height_width=[36, 36],\n",
    "    type_meanImg='meanImgE',\n",
    "    verbose=True,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josh/analysis/github_repos/ROICaT/roicat/util.py:191: UserWarning: RH WARNING: unable to get cpu info. Got error: No module named 'cpuinfo'\n",
      "  warnings.warn(f'RH WARNING: unable to get cpu info. Got error: {e}')\n",
      "/Users/josh/analysis/github_repos/ROICaT/roicat/util.py:210: UserWarning: RH WARNING: unable to get gpu info. Got error: No module named 'GPUtil'\n",
      "  warnings.warn(f'RH WARNING: unable to get gpu info. Got error: {e}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists locally: /Users/josh/analysis/models/ROInet.zip\n",
      "Hash of local file matches provided hash_hex.\n",
      "Extracting /Users/josh/analysis/models/ROInet.zip to /Users/josh/analysis/models.\n",
      "Completed zip extraction.\n",
      "['/Users/josh/analysis/models/ROInet_classification_20220902', '/Users/josh/analysis/models/ROInet_classification_20220902/ConvNext_tiny__1_0_best__simCLR_wPCA.pth', '/Users/josh/analysis/models/ROInet_classification_20220902/model.py', '/Users/josh/analysis/models/ROInet_classification_20220902/classifier.pkl', '/Users/josh/analysis/models/ROInet_classification_20220902/params.json', '/Users/josh/analysis/models/ROInet_classification_20220902/__pycache__', '/Users/josh/analysis/models/ROInet_classification_20220902/__pycache__/model.cpython-39.pyc']\n",
      "Imported model from /Users/josh/analysis/models/ROInet_classification_20220902/model.py\n",
      "Loaded params_model from /Users/josh/analysis/models/ROInet_classification_20220902/params.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josh/opt/anaconda3/envs/ROICaT/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/josh/opt/anaconda3/envs/ROICaT/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ConvNeXt_Tiny_Weights.IMAGENET1K_V1`. You can also use `weights=ConvNeXt_Tiny_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated network using params_model\n",
      "Loaded state_dict into network from /Users/josh/analysis/models/ROInet_classification_20220902/ConvNext_tiny__1_0_best__simCLR_wPCA.pth\n",
      "Loaded network onto device cpu\n",
      "Starting: resizing ROIs\n",
      "Completed: resizing ROIs\n",
      "Defined image transformations: Sequential(\n",
      "  (0): ScaleDynamicRange(scaler_bounds=(0, 1))\n",
      "  (1): Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "  (2): TileChannels(dim=0)\n",
      ")\n",
      "Defined dataset\n",
      "Defined dataloader\n",
      "starting: running data through network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 613/613 [09:41<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed: running data through network\n"
     ]
    }
   ],
   "source": [
    "# Neural network embedding distances\n",
    "roinet = roicat.ROInet.ROInet_embedder(\n",
    "    device=roicat.util.helpers.set_device('cuda:0'),\n",
    "    dir_networkFiles=r\"/Users/josh/analysis/models\",\n",
    "    download_method=\"check_local_first\",\n",
    "    download_url=\"https://osf.io/xwzhp/download\",\n",
    "    download_hash=\"134b170242141c26b0adbd9e0fd80d0e\",\n",
    "    forward_pass_version=\"head\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "roinet.generate_dataloader(\n",
    "    ROI_images=data.ROI_images,\n",
    "    um_per_pixel=data.um_per_pixel,\n",
    "    pref_plot=False,\n",
    "    batchSize_dataloader=8,\n",
    "    pinMemory_dataloader=True,\n",
    "    numWorkers_dataloader=mp.cpu_count(),\n",
    "    persistentWorkers_dataloader=True,\n",
    "    prefetchFactor_dataloader=2,    \n",
    ");\n",
    "\n",
    "# roicat.visualization.display_toggle_image_stack(roinet.ROI_images_rs)\n",
    "\n",
    "roinet.generate_latents();\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec09b37",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**=======**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params is None:\n",
    "    params = {\n",
    "        \"method\": \"simclr\",\n",
    "        \"device\": \"cuda:0\",\n",
    "        \"datatype\": \"raw_images\",\n",
    "        \"hyperparameters_data\": {\n",
    "            \"new_or_old_suite2p\": \"new\",\n",
    "            \"out_height_width\": [\n",
    "                36,\n",
    "                36\n",
    "            ],\n",
    "            \"type_meanImg\": \"meanImgE\",\n",
    "            \"FOV_images\": None,\n",
    "            \"verbose\": True,\n",
    "            \"um_per_pixel\": 2.0\n",
    "        },\n",
    "        \"hyperparameters_split\": {\n",
    "            \"n_train\": 50000,\n",
    "            \"test_size\": 0.3\n",
    "        },\n",
    "        \"paths\": {\n",
    "            \"directory_github\": \"/Users/josh/analysis/github_repos/\",\n",
    "            \"directory_data\": \"/Users/josh/analysis/data/ROICaT/classification/raw_images\",\n",
    "            \"filename_rawImages\": \"sf_concat_rs_sparse.npz\",\n",
    "            \"filename_labels\": \"labels.npy\",\n",
    "            \"directory_simclrModel\": \"/Users/josh/analysis//models\",\n",
    "            \"filepath_umapModel\": None,\n",
    "        },\n",
    "        \"hyperparameters_training_simclr\": {\n",
    "            \"num_transform_copies\": 80,\n",
    "            \"solver\": \"lbfgs\",\n",
    "            \"fit_intercept\": True,\n",
    "            \"max_iter\": 20000,\n",
    "            \"C\": 0.01,\n",
    "            \"tol\": 0.001,\n",
    "            \"simclrModel_download_url\": \"https://osf.io/xwzhp/download\",\n",
    "            \"simclrModel_download_hash\": \"134b170242141c26b0adbd9e0fd80d0e\"\n",
    "        },\n",
    "        \"hyperparameters_augmentations_val\": {\n",
    "            \"Scale_image_sum\": {\n",
    "                \"sum_val\": 1,\n",
    "                \"epsilon\": 1e-09,\n",
    "                \"min_sub\": True\n",
    "            },\n",
    "            \"ScaleDynamicRange\": {\n",
    "                \"scaler_bounds\": [\n",
    "                    0,\n",
    "                    1\n",
    "                ],\n",
    "                \"epsilon\": 1e-09\n",
    "            },\n",
    "            \"WarpPoints\": {\n",
    "                \"r\": [\n",
    "                    0.1,\n",
    "                    0.2\n",
    "                ],\n",
    "                \"cx\": [\n",
    "                    -0.3,\n",
    "                    0.3\n",
    "                ],\n",
    "                \"cy\": [\n",
    "                    -0.3,\n",
    "                    0.3\n",
    "                ],\n",
    "                \"dx\": [\n",
    "                    -0.1,\n",
    "                    0.1\n",
    "                ],\n",
    "                \"dy\": [\n",
    "                    -0.1,\n",
    "                    0.1\n",
    "                ],\n",
    "                \"n_warps\": 1,\n",
    "                \"prob\": 0.0,\n",
    "                \"img_size_in\": [\n",
    "                    36,\n",
    "                    36\n",
    "                ],\n",
    "                \"img_size_out\": [\n",
    "                    224,\n",
    "                    224\n",
    "                ]\n",
    "            },\n",
    "            \"TileChannels\": {\n",
    "                \"dim\": -3,\n",
    "                \"n_channels\": 3\n",
    "            }\n",
    "        },\n",
    "        \"run_umap\": True,\n",
    "    }\n",
    "\n",
    "if not torch.cuda.is_available() and params['device'] != 'cpu':\n",
    "    warnings.warn('CUDA not available, using CPU')\n",
    "    params['device'] = torch.device('cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: Importing ROI images\n",
      "Completed: Imported 1 sessions. Each session has [68382] ROIs. Total number of ROIs is 68382. The um_per_pixel is 2.0 um per pixel.\n",
      "Starting: Importing class labels\n",
      "Labels and ROI Images match in shapes: Class labels and ROI images have the same number of sessions and the same number of ROIs in each session.\n",
      "Completed: Imported labels for 1 sessions. Each session has [68382] class labels. Total number of class labels is 68382.\n"
     ]
    }
   ],
   "source": [
    "directory_model = str(Path(params['paths']['directory_model']).resolve()) if 'directory_model' in params['paths'] else None\n",
    "filepath_data_labels = str((Path(params['paths']['directory_data']) / params['paths']['filename_labels']).resolve())\n",
    "\n",
    "if params['datatype'] == \"stat_s2p\":\n",
    "    assert 'filename_stat' in params['paths'] and 'filename_ops' in params['paths'], 'JZ: The suite2p params.json file must include paths.filename_stat and paths.filename_ops for stat_s2p datatype'\n",
    "    filepath_data_stat = str((Path(params['paths']['directory_data']) / params['paths']['filename_stat']).resolve())\n",
    "    filepath_data_ops = str((Path(params['paths']['directory_data']) / params['paths']['filename_ops']).resolve())\n",
    "\n",
    "    # Create data importing object to import suite2p data\n",
    "    data = roicat.data_importing.Data_suite2p(\n",
    "        paths_statFiles=[filepath_data_stat],\n",
    "        paths_opsFiles=[filepath_data_ops],\n",
    "        class_labels=[filepath_data_labels],\n",
    "        um_per_pixel=params['hyperparameters_data']['um_per_pixel'],\n",
    "        new_or_old_suite2p=params['hyperparameters_data']['new_or_old_suite2p'],\n",
    "        out_height_width=params['hyperparameters_data']['out_height_width'],\n",
    "        type_meanImg=params['hyperparameters_data']['type_meanImg'],\n",
    "        FOV_images=params['hyperparameters_data']['FOV_images'],\n",
    "        verbose=params['hyperparameters_data']['verbose'],\n",
    "    )\n",
    "elif params['datatype'] == \"raw_images\":\n",
    "    assert 'filename_rawImages' in params['paths'], 'JZ: The suite2p params.json file must include paths.filename_rawImages for raw_images datatype'\n",
    "    filepath_data_rawImages = str((Path(params['paths']['directory_data']) / params['paths']['filename_rawImages']).resolve())\n",
    "\n",
    "    sf = scipy.sparse.load_npz(filepath_data_rawImages)\n",
    "    labels = np.load(filepath_data_labels)\n",
    "\n",
    "    data = roicat.data_importing.Data_roicat(verbose=True)\n",
    "    data.set_ROI_images(ROI_images=[sf.A.reshape(sf.shape[0], 36, 36)], um_per_pixel=params['hyperparameters_data']['um_per_pixel'])\n",
    "    data.set_class_labels(class_labels=[labels.astype(int)])\n",
    "else:\n",
    "    raise ValueError(f\"Invalid datatype for simclr: {params['datatype']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of idx_violations:  2  out of  68382  total ROIs.\n",
      "Located at:  [41927 62784]\n",
      "Discarding these ROIs...\n",
      "Shape of ROI_images_filt: (100, 36, 36), shape of labels_remapped: (100,)\n"
     ]
    }
   ],
   "source": [
    "tictoc['imported_data'] = time.time() - tic\n",
    "\n",
    "ROI_images_rescaled = [roicat.ROInet.ROInet_embedder.resize_ROIs(rois, params['hyperparameters_data']['um_per_pixel']) for rois in data.ROI_images]\n",
    "\n",
    "# Initialize concatendated data\n",
    "ROI_images_init = np.concatenate(data.ROI_images, axis=0).astype(np.float32)\n",
    "ROI_images_init_rescaled = np.concatenate(ROI_images_rescaled, axis=0).astype(np.float32)\n",
    "_labels_init = np.concatenate(data.class_labels, axis=0).astype(int).copy()\n",
    "\n",
    "inx_kept = np.arange(ROI_images_init_rescaled.shape[0])\n",
    "\n",
    "# Perform data cleaning\n",
    "idx_violations = (np.isnan(ROI_images_init_rescaled.sum(axis=(1,2)))*1 + (np.sum(ROI_images_init_rescaled, axis=(1,2))==0)*1 + np.isnan(_labels_init)) != 0\n",
    "print('Number of idx_violations: ', idx_violations.sum(), ' out of ', len(idx_violations), ' total ROIs.')\n",
    "print('Located at: ', np.where(idx_violations)[0])\n",
    "print('Discarding these ROIs...')\n",
    "\n",
    "inx_kept = inx_kept[~idx_violations]\n",
    "ROI_images_filt = ROI_images_init_rescaled[~idx_violations]\n",
    "_labels_filt = _labels_init[~idx_violations]\n",
    "\n",
    "if testing:\n",
    "    inx_kept = inx_kept[:100]\n",
    "    ROI_images_filt = ROI_images_filt[:100]\n",
    "    _labels_filt = _labels_filt[:100]\n",
    "\n",
    "labelingRun_interim['inx_kept'] = inx_kept\n",
    "labelingRun_interim['ROI_images_filt'] = ROI_images_filt\n",
    "\n",
    "## No remapping for generate preproc\n",
    "# labels_remapped = cu.remap_labels(labels_filt, params['label_remapping'])\n",
    "\n",
    "tictoc['cleaned_data'] = time.time() - tic\n",
    "\n",
    "print(f'Shape of ROI_images_filt: {ROI_images_filt.shape}, shape of labels_remapped: {_labels_filt.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pass Data Through Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_final_val = cu.get_transforms(params['hyperparameters_augmentations_val'], scripted=True)\n",
    "dataset_val = roicat.ROInet.dataset_simCLR(\n",
    "        X=torch.as_tensor(ROI_images_filt, device='cpu', dtype=torch.float32),\n",
    "        y=torch.as_tensor(np.zeros((ROI_images_filt.shape[0])), device='cpu', dtype=torch.float32),\n",
    "        n_transforms=1,\n",
    "        class_weights=np.array([1]),\n",
    "        transform=transforms_final_val, # *Use WarpPoints\n",
    "        DEVICE='cpu',\n",
    "        dtype_X=torch.float32,\n",
    "    )\n",
    "dataloader_val = torch.utils.data.DataLoader( \n",
    "        dataset_val,\n",
    "        batch_size=64,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        pin_memory=False,\n",
    "        num_workers=0,#mp.cpu_count(),\n",
    "        persistent_workers=False,\n",
    "        prefetch_factor=2,\n",
    ")\n",
    "\n",
    "roinet = roicat.ROInet.ROInet_embedder(\n",
    "    device=params['device'],\n",
    "    dir_networkFiles=params['paths']['directory_simclrModel'],\n",
    "    download_method='check_local_first',\n",
    "    forward_pass_version='head',\n",
    "    download_url=params['hyperparameters_training_simclr']['simclrModel_download_url'],\n",
    "    download_hash=params['hyperparameters_training_simclr']['simclrModel_download_hash'],\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(f'Extracting transformed images from dataloaders, passing through roinet model, and saving to {directory_save}...')\n",
    "\n",
    "features_val, _labels_val, _idx_val, _sample_val = cu.extract_with_dataloader(\n",
    "    dataloader_val,\n",
    "    model=roinet.net,\n",
    "    num_copies=1,\n",
    "    device=params['device'],\n",
    ")\n",
    "\n",
    "labelingRun_interim['features_val'] = features_val\n",
    "print(f'Unaugmented run completed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09def6ec",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**>>>>>>> remote**</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run 2D UMap OR Project onto Previousy Fit UMap for Hand Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params['run_umap']:\n",
    "    umap_params = dict(\n",
    "        n_neighbors=30,\n",
    "        n_components=2,\n",
    "        metric='euclidean',\n",
    "        metric_kwds=None,\n",
    "        output_metric='euclidean',\n",
    "        output_metric_kwds=None,\n",
    "        n_epochs=None,\n",
    "        learning_rate=1.0,\n",
    "        init='spectral',\n",
    "        min_dist=0.1,\n",
    "        spread=1.0,\n",
    "        low_memory=True,\n",
    "        n_jobs=-1,\n",
    "        set_op_mix_ratio=1.0,\n",
    "        local_connectivity=1.0,\n",
    "        repulsion_strength=1.0,\n",
    "        negative_sample_rate=5,\n",
    "        transform_queue_size=4.0,\n",
    "        a=None,\n",
    "        b=None,\n",
    "        random_state=None,\n",
    "        angular_rp_forest=False,\n",
    "        target_n_neighbors=-1,\n",
    "        target_metric='categorical',\n",
    "        target_metric_kwds=None,\n",
    "        target_weight=0.5,\n",
    "        transform_seed=42,\n",
    "        transform_mode='embedding',\n",
    "        force_approximation_algorithm=False,\n",
    "        verbose=False,\n",
    "        tqdm_kwds=None,\n",
    "        unique=False,\n",
    "        densmap=False,\n",
    "        dens_lambda=2.0,\n",
    "        dens_frac=0.3,\n",
    "        dens_var_shift=0.1,\n",
    "        output_dens=False,\n",
    "        disconnection_distance=None,\n",
    "        precomputed_knn=(None, None, None),\n",
    "    )\n",
    "\n",
    "<<<<<<< local\n",
    "    umap_model = umap.UMAP(**umap_params)\n",
    "    print('Fitting UMAP...')\n",
    "    umap_model.fit(roinet.latents)\n",
    "=======\n",
    "    umap = umap.UMAP(**umap_params)\n",
    "    print('Fitting UMAP...')\n",
    "    umap.fit(features_val)\n",
    ">>>>>>> remote\n",
    "\n",
    "    if params['paths']['filepath_umapModel']:\n",
    "        raise NotImplementedError('Saving UMAP to file not yet implemented.') # TODO: JZ, Implement saving UMAP to file\n",
    "        # print(f'Saving UMAP to {params[\"paths\"][\"filepath_umapModel\"]}...')\n",
    "        # joblib.dump(umap, params['paths']['filepath_umapModel'])\n",
    "    else:\n",
    "        print('Unspecified filepath_umapModel in params... not saving UMAP to file.')\n",
    "elif params['paths']['filepath_umapModel']:\n",
    "    raise NotImplementedError('Loading UMAP from file not yet implemented.') # TODO: JZ, Implement loading UMAP from file\n",
    "    # print(f'Loading UMAP from {params[\"paths\"][\"filepath_umapModel\"]}...')\n",
    "    # umap = joblib.load(params['paths']['filepath_umapModel'])\n",
    "else:\n",
    "    raise ValueError(f'run_umap must be True or filepath_umapModel must be specified in params.')\n",
    "\n",
    "print('Generating Embeddings...')\n",
    "<<<<<<< local\n",
    "embeddings = umap_model.transform(roinet.latents)\n",
    "labelingRun_interim['embeddings'] = embeddings\n",
    "print('Embeddings Generated...')\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "ax.scatter(embeddings[:,0], embeddings[:,1], s=5, cmap='gist_rainbow')\n",
    "\n",
    "inx_lst = np.arange(np.concatenate(data.ROI_images).shape[0])\n",
    "inx_lst = np.random.choice(inx_lst, 100, replace=False)\n",
    "img_lst = np.concatenate(data.ROI_images)[inx_lst]\n",
    "=======\n",
    "embeddings = umap.transform(features_val)\n",
    "labelingRun_interim['embeddings'] = embeddings\n",
    "print('Embeddings Generated...')\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "ax.scatter(embeddings[:,0], embeddings[:,1], s=5, cmap='gist_rainbow')\n",
    "\n",
    "# inx_lst = list(range(100))\n",
    "inx_lst = np.arange(ROI_images_filt.shape[0])\n",
    "img_lst = ROI_images_filt[inx_lst]\n",
    ">>>>>>> remote\n",
    "x = embeddings[inx_lst, 0]\n",
    "y = embeddings[inx_lst, 1]\n",
    "\n",
    "for x0, y0, ROI_single in zip(x, y, img_lst):\n",
    "    offsetImage = matplotlib.offsetbox.OffsetImage(ROI_single, cmap='gray', zoom=0.5) # initialize offset image to contain ROI visualization\n",
    "    ab = matplotlib.offsetbox.AnnotationBbox(offsetImage, (x0, y0), frameon=False)\n",
    "    ax.add_artist(ab)\n",
    "\n",
    "# TODO: JZ, Add Circling Code for Labeling\n",
    "if testing:\n",
    "<<<<<<< local\n",
    "    num_zeroLabels = np.concatenate(data.ROI_images).shape[0]//2\n",
    "    num_onesLabels = np.concatenate(data.ROI_images).shape[0] - np.concatenate(data.ROI_images).shape[0]//2\n",
    "=======\n",
    "    num_zeroLabels = ROI_images_filt.shape[0]//2\n",
    "    num_onesLabels = ROI_images_filt.shape[0] - ROI_images_filt.shape[0]//2\n",
    ">>>>>>> remote\n",
    "    arr_labels = np.concatenate([np.zeros(num_zeroLabels), np.ones(num_onesLabels)])\n",
    "else:\n",
    "    raise NotImplementedError('Saving UMAP to file not yet implemented.') # TODO: JZ, Implement saving UMAP to file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23099cbc",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**<<<<<<< local**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving files completed.\n"
     ]
    }
   ],
   "source": [
    "with open(str((Path(directory_save) / 'feature_label_combo.npy').resolve()), 'wb') as f:\n",
    "    np.save(\n",
    "        file=f,\n",
    "        arr={\n",
    "            'rois': data.ROI_images,\n",
    "            'latents': roinet.latents,\n",
    "            'embeddings': embeddings,\n",
    "            'labels': arr_labels,\n",
    "        },\n",
    "        allow_pickle=True,\n",
    "    )\n",
    "with open(str((Path(directory_save) / 'pkl_labelingRunInterim.npy').resolve()), 'wb') as f:\n",
    "    np.save(\n",
    "        file=f,\n",
    "        arr=labelingRun_interim,\n",
    "        allow_pickle=True\n",
    "    )\n",
    "\n",
    "print(f'Saving files completed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79776b24",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**=======**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving files completed.\n"
     ]
    }
   ],
   "source": [
    "with open(str((Path(directory_save) / 'arr_labels.npy').resolve()), 'wb') as f:\n",
    "    np.save(\n",
    "        file=f,\n",
    "        arr=arr_labels,\n",
    "    )\n",
    "\n",
    "if save_ROIs:\n",
    "    with open(str((Path(directory_save) / 'arr_ROIs.npy').resolve()), 'wb') as f:\n",
    "        np.save(\n",
    "            file=f,\n",
    "            arr=features_val,\n",
    "        )\n",
    "\n",
    "if save_latents:\n",
    "    with open(str((Path(directory_save) / 'arr_latents.npy').resolve()), 'wb') as f:\n",
    "        np.save(\n",
    "            file=f,\n",
    "            arr=features_val,\n",
    "        )\n",
    "\n",
    "labelingRun_interim['params_prespecified'] = params\n",
    "with open(str((Path(directory_save) / 'pkl_labelingRunInterim.npy').resolve()), 'wb') as f:\n",
    "    np.save(\n",
    "        file=f,\n",
    "        arr=labelingRun_interim,\n",
    "        allow_pickle=True\n",
    "    )\n",
    "\n",
    "print(f'Saving files completed.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23d5386",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**>>>>>>> remote**</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ROICaT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

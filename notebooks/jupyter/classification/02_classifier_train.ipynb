{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from bnpm import file_helpers, optimization\n",
    "import sklearn.utils.class_weight\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "import sklearn.linear_model\n",
    "import multiprocessing as mp\n",
    "\n",
    "import roicat.classification.classifier_util as cu\n",
    "import scipy.sparse\n",
    "import roicat\n",
    "import bnpm.h5_handling\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import warnings\n",
    "import umap\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.offsetbox\n",
    "import json\n",
    "import os\n",
    "import natsort\n",
    "from roicat import helpers\n",
    "# from kymatio.torch import Scattering2D\n",
    "import gc\n",
    "import functools"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify Initial Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_params = None # Path(r\"\")\n",
    "# directory_data = r'/Users/josh/analysis/outputs/ROICaT/classification/00_data_ingestion'\n",
    "directory_data = r'/Users/josh/analysis/outputs/ROICaT/classification/labeling_interactive/feature_label_combo.npy'\n",
    "directory_save = r'/Users/josh/analysis/outputs/ROICaT/classification/02_classifier_train'\n",
    "testing = True\n",
    "save_ROIs = True\n",
    "save_latents = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_save = Path(directory_save)\n",
    "directory_save.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "params = file_helpers.json_load(str(Path(path_params).resolve())) if path_params is not None else None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Importing — Suite2p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/josh/analysis/data/ROICaT/classification/stat_s2p/stat.npy']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['/Users/josh/analysis/data/ROICaT/classification/stat_s2p/ops.npy']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josh/analysis/github_repos/ROICaT/roicat/util.py:191: UserWarning: RH WARNING: unable to get cpu info. Got error: No module named 'cpuinfo'\n",
      "  warnings.warn(f'RH WARNING: unable to get cpu info. Got error: {e}')\n",
      "/Users/josh/analysis/github_repos/ROICaT/roicat/util.py:210: UserWarning: RH WARNING: unable to get gpu info. Got error: No module named 'GPUtil'\n",
      "  warnings.warn(f'RH WARNING: unable to get gpu info. Got error: {e}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: Importing FOV images from ops files\n",
      "Completed: Set FOV_height and FOV_width successfully.\n",
      "Completed: Imported 1 FOV images.\n",
      "Completed: Set FOV_images for 1 sessions successfully.\n",
      "Importing spatial footprints from stat files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported 1 sessions of spatial footprints into sparse arrays.\n",
      "Completed: Set spatialFootprints for 1 sessions successfully.\n",
      "Completed: Created session_bool.\n",
      "Completed: Created centroids.\n",
      "Staring: Creating centered ROI images from spatial footprints...\n",
      "Completed: Created ROI images.\n",
      "Starting: Importing class labels\n",
      "RH WARNING: class_labels is a list of strings. Assuming each string is a path to a .npy file containing the class labels as a 1D integer array.\n",
      "Labels and ROI Images match in shapes: Class labels and ROI images have the same number of sessions and the same number of ROIs in each session.\n",
      "Completed: Imported labels for 1 sessions. Each session has [4898] class labels. Total number of class labels is 4898.\n"
     ]
    }
   ],
   "source": [
    "dir_allOuterFolders = str(Path('/Users/josh/analysis/data/ROICaT/classification/stat_s2p').resolve())\n",
    "\n",
    "pathSuffixToStat = 'stat.npy'\n",
    "pathSuffixToOps = 'ops.npy'\n",
    "pathSuffixToLabels = 'labels_round2_sesh2.npy'\n",
    "\n",
    "paths_allStat = helpers.find_paths(\n",
    "    dir_outer=dir_allOuterFolders,\n",
    "    reMatch=pathSuffixToStat,\n",
    "    depth=4,\n",
    ")\n",
    "paths_allOps = helpers.find_paths(\n",
    "    dir_outer=dir_allOuterFolders,\n",
    "    reMatch=pathSuffixToOps,\n",
    "    depth=4,\n",
    ")\n",
    "paths_allLabels = helpers.find_paths(\n",
    "    dir_outer=dir_allOuterFolders,\n",
    "    reMatch=pathSuffixToLabels,\n",
    "    depth=4,\n",
    ")\n",
    "\n",
    "display(paths_allStat)\n",
    "display(paths_allOps)\n",
    "\n",
    "#Import data\n",
    "data = roicat.data_importing.Data_suite2p(\n",
    "    paths_statFiles=paths_allStat,\n",
    "    paths_opsFiles=paths_allOps,\n",
    "    class_labels=paths_allLabels,\n",
    "    um_per_pixel=2.0,\n",
    "    new_or_old_suite2p='new',\n",
    "    out_height_width=[36, 36],\n",
    "    type_meanImg='meanImgE',\n",
    "    verbose=True,\n",
    ");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Importing — Hand Labeled Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_labellingInteractive = str(Path('/Users/josh/analysis/outputs/ROICaT/classification/labeling_interactive/test.ROICaT.labeling.results.pkl').resolve())\n",
    "labelingInteractive = roicat.helpers.pickle_load(filepath_labellingInteractive)\n",
    "category_mappings, codes_categories = np.unique(labelingInteractive['labels']['label'], return_inverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RH WARNING: No um_per_pixel provided. We recommend making an educated guess. Assuming 1.0 um per pixel. This will affect the embedding results.\n",
      "Starting: Importing ROI images\n",
      "Completed: Imported 1 sessions. Each session has [41] ROIs. Total number of ROIs is 41. The um_per_pixel is 1.0 um per pixel.\n",
      "Starting: Importing class labels\n",
      "Labels and ROI Images match in shapes: Class labels and ROI images have the same number of sessions and the same number of ROIs in each session.\n",
      "Completed: Imported labels for 1 sessions. Each session has [41] class labels. Total number of class labels is 41.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josh/analysis/github_repos/ROICaT/roicat/util.py:191: UserWarning: RH WARNING: unable to get cpu info. Got error: No module named 'cpuinfo'\n",
      "  warnings.warn(f'RH WARNING: unable to get cpu info. Got error: {e}')\n",
      "/Users/josh/analysis/github_repos/ROICaT/roicat/util.py:210: UserWarning: RH WARNING: unable to get gpu info. Got error: No module named 'GPUtil'\n",
      "  warnings.warn(f'RH WARNING: unable to get gpu info. Got error: {e}')\n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "data = roicat.data_importing.Data_roicat();\n",
    "data.set_ROI_images([labelingInteractive['images'][labelingInteractive['labels']['index']]]);\n",
    "data.set_class_labels([codes_categories]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "<<<<<<< REMOTE CELL DELETED >>>>>>>\n",
    "<<<<<<< LOCAL CELL DELETED >>>>>>>\n",
    "path_params = None # Path(r\"\")\n",
    "# directory_data = r'/Users/josh/analysis/outputs/ROICaT/classification/00_data_ingestion'\n",
    "directory_data = r'/Users/josh/analysis/outputs/ROICaT/classification/01_labels/feature_label_combo.npy'\n",
    "directory_save = r'/Users/josh/analysis/outputs/ROICaT/classification/02_classifier_train'\n",
    "testing = True\n",
    "save_ROIs = True\n",
    "save_latents = True\n",
    "\n",
    "\n",
    "# path_params = None # Path(r\"\")\n",
    "# # filepath_ROIs = r'/Users/josh/analysis/outputs/ROICaT/classification/01_labels/arr_ROIs.npy'\n",
    "# filepath_ROIs = None\n",
    "# filepath_latents = r'/Users/josh/analysis/outputs/ROICaT/classification/01_labels/arr_latents.npy'\n",
    "# filepath_labels = r'/Users/josh/analysis/outputs/ROICaT/classification/01_labels/arr_labels.npy'\n",
    "# testing = True\n",
    "# assert (filepath_ROIs is None) != (filepath_latents is None), 'Exactly one of filepath_ROIs or filepath_latents should be set'\n",
    "# assert Path(filepath_labels).exists(), 'File located at filepath_labels does not exist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "<<<<<<< REMOTE CELL DELETED >>>>>>>\n",
    "<<<<<<< LOCAL CELL DELETED >>>>>>>\n",
    "directory_save = Path(directory_save)\n",
    "directory_save.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "labelingRun_interim = {}\n",
    "\n",
    "if path_params is not None:\n",
    "    try:\n",
    "        Path(str((directory_save).resolve())).mkdir(exist_ok=True, parents=True)\n",
    "        shutil.copy2(path_params, str(Path(directory_save) / Path(path_params).name));\n",
    "    except Exception as e:\n",
    "        print(f'JZ: Error copying params to {directory_save}')\n",
    "        print(e)\n",
    "tic = time.time()\n",
    "tictoc = {}\n",
    "tictoc['start'] = time.time() - tic\n",
    "\n",
    "params = file_helpers.json_load(str(Path(path_params).resolve())) if path_params is not None else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47c6516",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**<<<<<<< local**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_params = None # Path(r\"\")\n",
    "# directory_data = r'/Users/josh/analysis/outputs/ROICaT/classification/00_data_ingestion'\n",
    "directory_data = r'/Users/josh/analysis/outputs/ROICaT/classification/labeling_interactive/feature_label_combo.npy'\n",
    "directory_save = r'/Users/josh/analysis/outputs/ROICaT/classification/02_classifier_train'\n",
    "testing = True\n",
    "save_ROIs = True\n",
    "save_latents = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_allOuterFolders = str(Path('/Users/josh/analysis/data/ROICaT/classification/stat_s2p').resolve())\n",
    "\n",
    "pathSuffixToStat = 'stat.npy'\n",
    "pathSuffixToOps = 'ops.npy'\n",
    "pathSuffixToLabels = 'labels_round2_sesh2.npy'\n",
    "\n",
    "paths_allStat = helpers.find_paths(\n",
    "    dir_outer=dir_allOuterFolders,\n",
    "    reMatch=pathSuffixToStat,\n",
    "    depth=4,\n",
    ")\n",
    "paths_allOps = helpers.find_paths(\n",
    "    dir_outer=dir_allOuterFolders,\n",
    "    reMatch=pathSuffixToOps,\n",
    "    depth=4,\n",
    ")\n",
    "paths_allLabels = helpers.find_paths(\n",
    "    dir_outer=dir_allOuterFolders,\n",
    "    reMatch=pathSuffixToLabels,\n",
    "    depth=4,\n",
    ")\n",
    "\n",
    "display(paths_allStat)\n",
    "display(paths_allOps)\n",
    "\n",
    "#Import data\n",
    "data = roicat.data_importing.Data_suite2p(\n",
    "    paths_statFiles=paths_allStat,\n",
    "    paths_opsFiles=paths_allOps,\n",
    "    class_labels=paths_allLabels,\n",
    "    um_per_pixel=2.0,\n",
    "    new_or_old_suite2p='new',\n",
    "    out_height_width=[36, 36],\n",
    "    type_meanImg='meanImgE',\n",
    "    verbose=True,\n",
    ");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Importing — Hand Labeled Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_labellingInteractive = str(Path('/Users/josh/analysis/outputs/ROICaT/classification/labeling_interactive/test.ROICaT.labeling.results.pkl').resolve())\n",
    "labelingInteractive = roicat.helpers.pickle_load(filepath_labellingInteractive)\n",
    "category_mappings, codes_categories = np.unique(labelingInteractive['labels']['label'], return_inverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "data = roicat.data_importing.Data_roicat();\n",
    "data.set_ROI_images([labelingInteractive['images'][labelingInteractive['labels']['index']]]);\n",
    "data.set_class_labels([codes_categories]);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pass Through Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9a999f",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**<<<<<<< local**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ad4a58",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**<<<<<<< local**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network embedding distances\n",
    "roinet = roicat.ROInet.ROInet_embedder(\n",
    "    device=roicat.util.helpers.set_device('cuda:0'),\n",
    "    dir_networkFiles=r\"/Users/josh/analysis/models\",\n",
    "    download_method=\"check_local_first\",\n",
    "    download_url=\"https://osf.io/xwzhp/download\",\n",
    "    download_hash=\"134b170242141c26b0adbd9e0fd80d0e\",\n",
    "    forward_pass_version=\"head\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "roinet.generate_dataloader(\n",
    "    ROI_images=data.ROI_images,\n",
    "    um_per_pixel=data.um_per_pixel,\n",
    "    pref_plot=False,\n",
    "    batchSize_dataloader=8,\n",
    "    pinMemory_dataloader=True,\n",
    "    numWorkers_dataloader=mp.cpu_count(),\n",
    "    persistentWorkers_dataloader=True,\n",
    "    prefetchFactor_dataloader=2,    \n",
    ");\n",
    "\n",
    "# roicat.visualization.display_toggle_image_stack(roinet.ROI_images_rs)\n",
    "\n",
    "roinet.generate_latents();\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c981f54a",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**=======**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_params = None # Path(r\"\")\n",
    "# filepath_ROIs = r'/Users/josh/analysis/outputs/ROICaT/classification/01_labels/arr_ROIs.npy'\n",
    "filepath_ROIs = None\n",
    "filepath_latents = r'/Users/josh/analysis/outputs/ROICaT/classification/01_labels/arr_latents.npy'\n",
    "filepath_labels = r'/Users/josh/analysis/outputs/ROICaT/classification/01_labels/arr_labels.npy'\n",
    "directory_save = '/Users/josh/analysis/outputs/ROICaT/classification/02_classifier_train'\n",
    "testing = True\n",
    "\n",
    "assert (filepath_ROIs is None) != (filepath_latents is None), 'Exactly one of filepath_ROIs or filepath_latents should be set'\n",
    "assert Path(filepath_labels).exists(), 'File located at filepath_labels does not exist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_ROIs = Path(filepath_ROIs) if filepath_ROIs else None\n",
    "filepath_latents = Path(filepath_latents) if filepath_latents else None\n",
    "filepath_labels = Path(filepath_labels)\n",
    "directory_save = Path(directory_save)\n",
    "directory_save.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "classifierTrainingRun_interim = {}\n",
    "\n",
    "if path_params is not None:\n",
    "    try:\n",
    "        Path(str((directory_save).resolve())).mkdir(exist_ok=True, parents=True)\n",
    "        shutil.copy2(path_params, str(Path(directory_save) / Path(path_params).name));\n",
    "    except Exception as e:\n",
    "        print(f'JZ: Error copying params to {directory_save}')\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params is None:\n",
    "    params = {\n",
    "        \"method\": \"simclr\",\n",
    "        \"device\": \"cuda:0\",\n",
    "        \"datatype\": \"raw_images\",\n",
    "        \"hyperparameters_data\": {\n",
    "            \"new_or_old_suite2p\": \"new\",\n",
    "            \"out_height_width\": [\n",
    "                36,\n",
    "                36\n",
    "            ],\n",
    "            \"type_meanImg\": \"meanImgE\",\n",
    "            \"FOV_images\": None,\n",
    "            \"verbose\": True,\n",
    "            \"um_per_pixel\": 2.0\n",
    "        },\n",
    "        \"hyperparameters_split\": {\n",
    "            \"n_train\": 50000,\n",
    "            \"val_size\": 0.2,\n",
    "            \"test_size\": 0.2,\n",
    "        },\n",
    "        \"paths\": { # TODO: Remove Irrelevant Paths\n",
    "            \"directory_github\": \"/Users/josh/analysis/github_repos/\",\n",
    "            \"directory_data\": \"/Users/josh/analysis/data/ROICaT/classification/raw_images\",\n",
    "            \"filename_rawImages\": \"sf_concat_rs_sparse.npz\",\n",
    "            \"filename_labels\": \"labels.npy\",\n",
    "            \"directory_simclrModel\": \"/Users/josh/analysis//models\",\n",
    "            \"filepath_umapModel\": None,\n",
    "        },\n",
    "        \"hyperparameters_training_simclr\": {\n",
    "            \"num_transform_copies\": 80,\n",
    "            \"solver\": \"lbfgs\",\n",
    "            \"fit_intercept\": True,\n",
    "            \"max_iter\": 20000,\n",
    "            \"C\": 0.01,\n",
    "            \"tol\": 0.001,\n",
    "            \"simclrModel_download_url\": \"https://osf.io/xwzhp/download\",\n",
    "            \"simclrModel_download_hash\": \"134b170242141c26b0adbd9e0fd80d0e\"\n",
    "        },\n",
    "        \"hyperparameters_augmentations_all\": {\n",
    "            \"Scale_image_sum\": {\n",
    "                \"sum_all\": 1,\n",
    "                \"epsilon\": 1e-09,\n",
    "                \"min_sub\": True\n",
    "            },\n",
    "            \"ScaleDynamicRange\": {\n",
    "                \"scaler_bounds\": [\n",
    "                    0,\n",
    "                    1\n",
    "                ],\n",
    "                \"epsilon\": 1e-09\n",
    "            },\n",
    "            \"WarpPoints\": {\n",
    "                \"r\": [\n",
    "                    0.1,\n",
    "                    0.2\n",
    "                ],\n",
    "                \"cx\": [\n",
    "                    -0.3,\n",
    "                    0.3\n",
    "                ],\n",
    "                \"cy\": [\n",
    "                    -0.3,\n",
    "                    0.3\n",
    "                ],\n",
    "                \"dx\": [\n",
    "                    -0.1,\n",
    "                    0.1\n",
    "                ],\n",
    "                \"dy\": [\n",
    "                    -0.1,\n",
    "                    0.1\n",
    "                ],\n",
    "                \"n_warps\": 1,\n",
    "                \"prob\": 0.0,\n",
    "                \"img_size_in\": [\n",
    "                    36,\n",
    "                    36\n",
    "                ],\n",
    "                \"img_size_out\": [\n",
    "                    224,\n",
    "                    224\n",
    "                ]\n",
    "            },\n",
    "            \"TileChannels\": {\n",
    "                \"dim\": -3,\n",
    "                \"n_channels\": 3\n",
    "            }\n",
    "        },\n",
    "        \"run_umap\": True,\n",
    "    }\n",
    "\n",
    "if not torch.cuda.is_available() and params['device'] != 'cpu':\n",
    "    warnings.warn('CUDA not available, using CPU')\n",
    "    params['device'] = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2414b4e4",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**>>>>>>> remote**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a14888",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**=======**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac50b171",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**=======**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "devices available: []\n",
      "no GPU available. Using CPU.\n",
      "File already exists locally: /Users/josh/analysis/models/ROInet.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josh/analysis/github_repos/ROICaT/roicat/util.py:191: UserWarning: RH WARNING: unable to get cpu info. Got error: No module named 'cpuinfo'\n",
      "  warnings.warn(f'RH WARNING: unable to get cpu info. Got error: {e}')\n",
      "/Users/josh/analysis/github_repos/ROICaT/roicat/util.py:210: UserWarning: RH WARNING: unable to get gpu info. Got error: No module named 'GPUtil'\n",
      "  warnings.warn(f'RH WARNING: unable to get gpu info. Got error: {e}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hash of local file matches provided hash_hex.\n",
      "Extracting /Users/josh/analysis/models/ROInet.zip to /Users/josh/analysis/models.\n",
      "Completed zip extraction.\n",
      "['/Users/josh/analysis/models/ROInet_classification_20220902', '/Users/josh/analysis/models/ROInet_classification_20220902/ConvNext_tiny__1_0_best__simCLR_wPCA.pth', '/Users/josh/analysis/models/ROInet_classification_20220902/model.py', '/Users/josh/analysis/models/ROInet_classification_20220902/classifier.pkl', '/Users/josh/analysis/models/ROInet_classification_20220902/params.json', '/Users/josh/analysis/models/ROInet_classification_20220902/__pycache__', '/Users/josh/analysis/models/ROInet_classification_20220902/__pycache__/model.cpython-39.pyc']\n",
      "Imported model from /Users/josh/analysis/models/ROInet_classification_20220902/model.py\n",
      "Loaded params_model from /Users/josh/analysis/models/ROInet_classification_20220902/params.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josh/opt/anaconda3/envs/ROICaT/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/josh/opt/anaconda3/envs/ROICaT/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ConvNeXt_Tiny_Weights.IMAGENET1K_V1`. You can also use `weights=ConvNeXt_Tiny_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated network using params_model\n",
      "Loaded state_dict into network from /Users/josh/analysis/models/ROInet_classification_20220902/ConvNext_tiny__1_0_best__simCLR_wPCA.pth\n",
      "Loaded network onto device cpu\n",
      "Starting: resizing ROIs\n",
      "Completed: resizing ROIs\n",
      "Defined image transformations: Sequential(\n",
      "  (0): ScaleDynamicRange(scaler_bounds=(0, 1))\n",
      "  (1): Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "  (2): TileChannels(dim=0)\n",
      ")\n",
      "Defined dataset\n",
      "Defined dataloader\n",
      "starting: running data through network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:13<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed: running data through network\n"
     ]
    }
   ],
   "source": [
    "# Neural network embedding distances\n",
    "roinet = roicat.ROInet.ROInet_embedder(\n",
    "    device=roicat.util.helpers.set_device('cuda:0'),\n",
    "    dir_networkFiles=r\"/Users/josh/analysis/models\",\n",
    "    download_method=\"check_local_first\",\n",
    "    download_url=\"https://osf.io/xwzhp/download\",\n",
    "    download_hash=\"134b170242141c26b0adbd9e0fd80d0e\",\n",
    "    forward_pass_version=\"head\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "roinet.generate_dataloader(\n",
    "    ROI_images=data.ROI_images,\n",
    "    um_per_pixel=data.um_per_pixel,\n",
    "    pref_plot=False,\n",
    "    batchSize_dataloader=8,\n",
    "    pinMemory_dataloader=True,\n",
    "    numWorkers_dataloader=mp.cpu_count(),\n",
    "    persistentWorkers_dataloader=True,\n",
    "    prefetchFactor_dataloader=2,    \n",
    ");\n",
    "\n",
    "# roicat.visualization.display_toggle_image_stack(roinet.ROI_images_rs)\n",
    "\n",
    "roinet.generate_latents();\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_label_combo = np.load(directory_data, allow_pickle=True)[()]\n",
    "# TODO: Add alternative data importing method for raw data when feature_label_combo does not exist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01c2423",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**>>>>>>> remote**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03472a4",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**>>>>>>> remote**</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train / Validation / Test Split Data, Hyperparameter Tune on Validation Set, and Fit Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46b4451",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**<<<<<<< local**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data...\n",
      "Creating X and y matrices for training data...\n",
      "Calculating class weights...\n",
      "Fitting model to data of dimensions: X: (60, 100), y: (60,)...\n",
      "Calculating tracker outputs and saving to /Users/josh/analysis/outputs/ROICaT/classification/02_classifier_train...\n",
      "Saving results:  /Users/josh/analysis/outputs/ROICaT/classification/02_classifier_train/results_training.csv /Users/josh/analysis/outputs/ROICaT/classification/02_classifier_train/results_timing.json\n",
      "self.tictoc={'start': 4.887580871582031e-05, 'loaded_data': 0.6734569072723389, 'splitted_data': 0.6762540340423584, 'completed_training_in_0': 0.7153449058532715}\n",
      "self.model={'coef': array([[-5.85583578e-03, -2.56761415e-03, -2.85717620e-04,\n",
      "         1.39980724e-03, -4.69398613e-03,  1.39073784e-03,\n",
      "        -4.09502665e-03, -6.19066812e-03, -2.53216414e-03,\n",
      "        -5.05807930e-04, -9.05063450e-04,  1.13785403e-03,\n",
      "        -7.10335497e-03, -3.48018141e-04, -4.56430364e-03,\n",
      "        -4.09421531e-03, -9.48537968e-04,  2.06175686e-03,\n",
      "        -5.21379017e-03,  1.25833581e-03,  1.00143141e-03,\n",
      "         5.54587913e-03, -4.96087667e-03,  5.78523710e-04,\n",
      "        -2.34480058e-03, -4.24748542e-04,  2.29494253e-04,\n",
      "        -1.95344170e-03, -2.15311061e-03,  1.17647903e-03,\n",
      "        -7.43009012e-03, -2.72018406e-03,  2.06751230e-03,\n",
      "         4.34910114e-03, -1.84695689e-03,  6.20641329e-04,\n",
      "        -2.26511555e-03, -5.72219438e-03, -2.95777379e-03,\n",
      "         2.30480869e-03,  6.18240543e-04, -7.78772098e-03,\n",
      "         4.99702222e-03,  3.95970383e-03,  4.49043241e-03,\n",
      "        -3.76699151e-03,  1.74704964e-03,  2.68536073e-03,\n",
      "         4.44230205e-03,  4.98784235e-04, -3.42783663e-03,\n",
      "         9.73880422e-03,  3.97129779e-03, -2.24050885e-03,\n",
      "        -3.39635350e-04,  2.04323403e-03,  3.68731617e-03,\n",
      "        -8.53799074e-03,  1.06806558e-03, -1.05251449e-03,\n",
      "         5.76199794e-03,  1.89358886e-03,  3.45303107e-03,\n",
      "         3.05432607e-03,  1.50207173e-03, -4.02562024e-03,\n",
      "         8.62522584e-03, -3.08412291e-03, -1.95202312e-04,\n",
      "        -1.38560091e-03, -2.03389717e-03, -5.15984809e-03,\n",
      "         1.92877265e-03,  7.87358120e-05, -1.44222194e-03,\n",
      "        -6.35793776e-03, -1.91664995e-04, -4.03905507e-03,\n",
      "        -2.16867961e-03,  2.10616194e-03, -2.90092518e-03,\n",
      "        -1.18269316e-03,  2.65287176e-03, -2.44745773e-03,\n",
      "        -7.52382359e-04,  3.12937887e-03,  1.48916540e-03,\n",
      "         9.53780097e-04,  2.20466497e-03,  1.38746250e-03,\n",
      "         5.01350070e-03,  1.84507331e-03,  2.26887527e-04,\n",
      "        -8.73770725e-04, -4.99331646e-03,  9.28965364e-03,\n",
      "        -2.42515383e-03,  6.63220517e-03,  3.15830167e-03,\n",
      "        -4.06672459e-04]]), 'intercept': array([6.47217386e-06])}\n",
      "   accuracy_training  confusionMatrix_training  accuracy_val  \\\n",
      "0                1.0  [[1.0, 0.0], [0.0, 1.0]]           0.5   \n",
      "\n",
      "        confusionMatrix_val  \n",
      "0  [[0.4, 0.4], [0.6, 0.6]]  \n"
     ]
    }
   ],
   "source": [
    "INTEGER_MAX = np.iinfo(np.int64(0).dtype).max\n",
    "\n",
    "# TODO: JZ, IMPLEMENT AS LOOP FOR OPTUNA FOR HYPERPARAMETER TUNING\n",
    "print('Splitting data...')\n",
    "# Create data splitting object for stratified sampling into train and test sets (as well as downsampling)\n",
    "data_splitter = cu.Datasplit(\n",
    "    features=roinet.latents,\n",
    "    labels=data.class_labels,\n",
    "    n_train=INTEGER_MAX,\n",
    "    val_size=0.2,\n",
    "    test_size=0.2,\n",
    ")\n",
    "\n",
    "print('Calculating class weights...')\n",
    "num_classes = len(np.unique(data.class_labels))\n",
    "class_weights = sklearn.utils.class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(data.class_labels), y=data.class_labels)\n",
    "\n",
    "print(f'Fitting model to data of dimensions: X: {data_splitter.features_train}, y: {data_splitter.labels_train}...')\n",
    "# Create lenet model, associated optimizer, loss function, and training tracker\n",
    "model = sklearn.linear_model.LogisticRegression(\n",
    "   solver='lbfgs',\n",
    "   fit_intercept=True,\n",
    "   max_iter=10000,\n",
    "   C=1e5,\n",
    "   class_weight={iClassWeight:classWeight for iClassWeight, classWeight in enumerate(class_weights)},\n",
    "#    class_weight=class_weights,\n",
    ")\n",
    "model.fit(data_splitter.features_train, data_splitter.labels_train)\n",
    "\n",
    "print(f'Calculating tracker outputs and saving to {directory_save}...')\n",
    "training_tracker = cu.TrainingTracker(\n",
    "    directory_save=directory_save,\n",
    "    class_weights=class_weights, # Class Weights\n",
    "    n_train_actual=data_splitter.n_train_actual,\n",
    "    model=({'coef':model.coef_, 'intercept':model.intercept_})\n",
    ")\n",
    "\n",
    "y_train_preds = model.predict(data_splitter.features_train).astype(int)\n",
    "y_train_true = data_splitter.labels_train\n",
    "y_val_preds = model.predict(data_splitter.features_val).astype(int)\n",
    "y_val_true = data_splitter.labels_val\n",
    "\n",
    "# Save training loop results from current epoch for training set\n",
    "training_tracker.add_accuracy(0, 'accuracy_training', y_train_true, y_train_preds) # Generating training loss\n",
    "training_tracker.add_confusion_matrix(0, 'confusionMatrix_training', y_train_true, y_train_preds) # Generating confusion matrix\n",
    "\n",
    "# Save training loop results from current epoch for validation set\n",
    "training_tracker.add_accuracy(0, 'accuracy_val', y_val_true, y_val_preds) # Generating validation accuracy\n",
    "training_tracker.add_confusion_matrix(0, 'confusionMatrix_val', y_val_true, y_val_preds) # Generating validation confusion matrix\n",
    "\n",
    "training_tracker.save_results() # TODO: JZ, ADJUST RESULTS SAVING TO SAVE CONFUSION MATRICES AS NOT A DATAFRAME CSV\n",
    "training_tracker.print_results()\n",
    "\n",
    "model_save = {\n",
    "    'intercept_': model.intercept_,\n",
    "    'coef_': model.coef_,\n",
    "    'classes_': model.classes_,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b9ecbb",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**=======**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<<<<<<< local\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<<<<<<< local\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data...\n",
      "Creating X and y matrices for training data...\n",
      "Calculating class weights...\n",
      "Fitting model to data of dimensions: X: (60, 100), y: (60,)...\n",
      "Calculating tracker outputs and saving to /Users/josh/analysis/outputs/ROICaT/classification/02_classifier_train...\n",
      "Saving results:  /Users/josh/analysis/outputs/ROICaT/classification/02_classifier_train/results_training.csv /Users/josh/analysis/outputs/ROICaT/classification/02_classifier_train/results_timing.json\n",
      "self.tictoc={'start': 4.792213439941406e-05, 'loaded_data': 0.7132289409637451, 'splitted_data': 0.7159662246704102, 'completed_training_in_0': 0.7610359191894531}\n",
      "self.model={'coef': array([[-6.75415296e-03, -5.46746177e-03,  4.79354474e-04,\n",
      "         1.08285428e-03,  2.15115646e-04, -2.05471810e-03,\n",
      "        -4.84297000e-04, -5.62958992e-03,  8.15842745e-03,\n",
      "        -2.81363387e-03,  5.75704830e-04,  4.53531535e-03,\n",
      "        -9.26651960e-03,  1.37357995e-03, -2.26479577e-03,\n",
      "        -9.89592445e-04, -1.85910939e-03,  2.91943812e-03,\n",
      "        -5.45014819e-03,  5.79063553e-03, -4.07646778e-03,\n",
      "         2.27442814e-03, -7.84319167e-03,  2.80346610e-03,\n",
      "         1.60115633e-03,  2.11675237e-03,  1.77431369e-03,\n",
      "        -1.34333236e-03, -4.21954957e-03, -1.09053422e-03,\n",
      "        -4.40235829e-03,  4.68881549e-03,  5.11666123e-03,\n",
      "        -1.24294291e-03,  1.62171963e-03,  5.89951999e-03,\n",
      "        -2.87793464e-03, -2.35118566e-03,  3.66440059e-03,\n",
      "        -8.45095768e-05,  2.76122390e-03, -4.16774446e-03,\n",
      "         4.75786767e-03,  2.04269952e-03,  8.87045814e-03,\n",
      "        -5.66791438e-03,  6.63302268e-03,  1.22562814e-03,\n",
      "        -1.71578090e-03, -8.73103621e-03, -5.68187307e-04,\n",
      "         9.97849338e-03,  7.75950343e-03, -1.37893098e-03,\n",
      "        -1.31490371e-03,  1.76823039e-03, -1.01056856e-03,\n",
      "         2.88215015e-03,  2.49978355e-03,  1.95999881e-03,\n",
      "         9.03014223e-03,  2.68188378e-03,  9.20052272e-04,\n",
      "         5.32373893e-03, -6.92563423e-03, -5.38095685e-03,\n",
      "         3.96933166e-03, -5.73797135e-03,  6.76160816e-04,\n",
      "         9.93315538e-04, -8.94776292e-03, -3.29803329e-03,\n",
      "        -4.36013102e-03, -2.32543655e-04, -2.62925196e-03,\n",
      "        -5.02763919e-03, -6.64378814e-03, -5.16250261e-03,\n",
      "        -3.37303449e-05,  2.94135023e-03, -2.70422309e-03,\n",
      "         3.86731698e-03, -6.74906539e-04,  4.05451773e-05,\n",
      "         3.99217675e-03,  2.76115172e-03,  4.11919419e-03,\n",
      "         5.04786849e-04,  3.44483110e-03, -4.25192739e-03,\n",
      "         6.74521837e-03, -2.97947833e-03, -1.11695073e-03,\n",
      "        -1.21291731e-03, -2.38639299e-03,  9.76137730e-03,\n",
      "        -1.79425892e-03,  7.20107500e-03,  1.47305420e-03,\n",
      "         2.02694247e-03]]), 'intercept': array([5.16358512e-06])}\n",
      "   accuracy_training  confusionMatrix_training  accuracy_val  \\\n",
      "0                1.0  [[1.0, 0.0], [0.0, 1.0]]          0.55   \n",
      "\n",
      "        confusionMatrix_val  \n",
      "0  [[0.6, 0.5], [0.4, 0.5]]  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>>>>>> remote\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<<<<<<< local <unchanged>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data...\n",
      "Creating X and y matrices for training data...\n",
      "Calculating class weights...\n",
      "Fitting model to data of dimensions: X: torch.Size([2938, 100]), y: (2938,)...\n",
      "Calculating tracker outputs and saving to /Users/josh/analysis/outputs/ROICaT/classification/02_classifier_train...\n",
      "Saving results:  /Users/josh/analysis/outputs/ROICaT/classification/02_classifier_train/results_training.csv /Users/josh/analysis/outputs/ROICaT/classification/02_classifier_train/results_timing.json\n",
      "self.tictoc={'start': 6.699562072753906e-05, 'loaded_data': 0.2793619632720947, 'splitted_data': 0.28069400787353516, 'completed_training_in_0': 1.374708890914917}\n",
      "self.model={'coef': array([[ 1.69406483e-04, -5.27381853e-04, -2.60215527e-04,\n",
      "        -2.68778208e-04,  3.91715543e-04, -4.79283612e-04,\n",
      "         2.32144896e-04,  2.07393075e-04,  6.25804876e-04,\n",
      "         3.00665636e-04,  6.02871984e-04,  6.75283610e-04,\n",
      "        -2.07972300e-04, -1.61987044e-04,  1.55279871e-04,\n",
      "         4.83258452e-04,  3.87508369e-04, -1.60286255e-04,\n",
      "        -4.55419072e-04, -1.80931402e-04,  2.65643425e-04,\n",
      "        -2.62778225e-04,  3.54850732e-04,  9.06564163e-05,\n",
      "         3.54075677e-04, -3.48639244e-04,  8.68352708e-05,\n",
      "        -4.30389357e-04,  2.52613707e-04,  3.95531238e-04,\n",
      "         2.11192826e-06, -1.27203346e-04,  4.72320977e-04,\n",
      "        -5.74709706e-05,  2.77168544e-05, -7.68446828e-05,\n",
      "         1.87244908e-04, -2.41463771e-04, -4.04520531e-04,\n",
      "         5.29887138e-04, -3.12835775e-04, -3.25953598e-04,\n",
      "        -2.38489443e-04, -3.14108323e-04, -2.54579428e-04,\n",
      "        -2.78188435e-05,  1.89950443e-04,  2.48901035e-04,\n",
      "        -1.73098825e-04, -3.40221098e-04,  1.58362627e-04,\n",
      "        -1.61701848e-05, -3.93274522e-04,  8.62018121e-05,\n",
      "         1.56552328e-04,  4.60834171e-04,  2.20095675e-04,\n",
      "         2.95665315e-04,  5.34930400e-04,  6.74323483e-04,\n",
      "         6.38126857e-06,  7.05828301e-04, -5.91669407e-04,\n",
      "         1.45064488e-03,  7.77978634e-05, -1.13906419e-03,\n",
      "         7.73276505e-05,  7.52688718e-04, -1.23491616e-04,\n",
      "        -4.23241409e-04,  8.04975431e-04, -6.00987096e-04,\n",
      "         4.58452020e-04, -4.11562033e-04,  2.43865695e-04,\n",
      "        -7.61506327e-04,  2.43831574e-03, -6.36662238e-04,\n",
      "        -1.72685781e-03, -1.69121416e-03, -1.22321761e-03,\n",
      "         2.65606257e-03,  2.24775597e-04, -4.43871627e-04,\n",
      "         1.15864969e-03, -2.13295759e-03, -2.43560586e-03,\n",
      "         3.37769506e-03, -3.35628935e-03,  1.25360841e-03,\n",
      "        -6.55160235e-03,  3.18922299e-05, -3.12618688e-04,\n",
      "        -1.81781953e-04, -5.39248924e-04, -3.35963068e-03,\n",
      "         9.07614188e-04,  3.17736526e-03,  1.96503407e-02,\n",
      "         2.94446480e-02]]), 'intercept': array([2.45939381])}\n",
      "   accuracy_training                           confusionMatrix_training  \\\n",
      "0           0.809735  [[0.8277739959155889, 0.20830496936691628], [0...   \n",
      "\n",
      "   accuracy_val                                confusionMatrix_val  \n",
      "0      0.793878  [[0.8142857142857143, 0.22653061224489796], [0...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>>>>>> remote <removed>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>>>>>> remote\n"
     ]
    }
   ],
   "source": [
    "INTEGER_MAX = np.iinfo(np.int64(0).dtype).max\n",
    "\n",
    "# TODO: JZ, IMPLEMENT AS LOOP FOR OPTUNA FOR HYPERPARAMETER TUNING\n",
    "print('Splitting data...')\n",
    "# Create data splitting object for stratified sampling into train and test sets (as well as downsampling)\n",
    "<<<<<<< local\n",
    "data_split_val = cu.Datasplit(\n",
    "<<<<<<< local\n",
    "    features=features_all,\n",
    "    labels=labels_all,\n",
    "    n_train=INTEGER_MAX,\n",
    "    test_size=params['hyperparameters_split']['val_size'],\n",
    "=======\n",
    "    features=feature_label_combo['latents'],\n",
    "    labels=feature_label_combo['labels'],\n",
    "=======\n",
    "data_splitter = cu.Datasplit(\n",
    "    features=roinet.latents,\n",
    "    labels=data.class_labels,\n",
    ">>>>>>> remote\n",
    "    n_train=INTEGER_MAX,\n",
    "    val_size=0.2,\n",
    "    test_size=0.2,\n",
    ">>>>>>> remote\n",
    ")\n",
    "<<<<<<< local\n",
    "data_split_test = cu.Datasplit(\n",
    "    features=data_split_val.features_train,\n",
    "    labels=data_split_val.labels_train,\n",
    "    n_train=INTEGER_MAX,\n",
    "<<<<<<< local\n",
    "    test_size = params['hyperparameters_split']['test_size']/(1 - params['hyperparameters_split']['val_size']),\n",
    "=======\n",
    "    test_size = 0.2/(1 - 0.2),\n",
    ">>>>>>> remote\n",
    ")\n",
    "\n",
    "print('Creating X and y matrices for training data...')\n",
    "X_train = data_split_test.features_train\n",
    "y_train = data_split_test.labels_train\n",
    "\n",
    "X_val = data_split_val.features_val\n",
    "y_val = data_split_val.labels_val\n",
    "\n",
    "X_test = data_split_val.features_val\n",
    "y_test = data_split_val.labels_val\n",
    "\n",
    "y_train = y_train.astype(int)\n",
    "y_val = y_val.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "=======\n",
    ">>>>>>> remote\n",
    "\n",
    "print('Calculating class weights...')\n",
    "<<<<<<< local\n",
    "<<<<<<< local\n",
    "num_classes = len(np.unique(labels))\n",
    "class_weights = sklearn.utils.class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(labels_all), y=labels_all)\n",
    "=======\n",
    "num_classes = len(np.unique(feature_label_combo['labels']))\n",
    "class_weights = sklearn.utils.class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(feature_label_combo['labels']), y=feature_label_combo['labels'])\n",
    ">>>>>>> remote\n",
    "=======\n",
    "num_classes = len(np.unique(data.class_labels))\n",
    "class_weights = sklearn.utils.class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(data.class_labels), y=data.class_labels)\n",
    ">>>>>>> remote\n",
    "\n",
    "print(f'Fitting model to data of dimensions: X: {data_splitter.features_train}, y: {data_splitter.labels_train}...')\n",
    "# Create lenet model, associated optimizer, loss function, and training tracker\n",
    "model = sklearn.linear_model.LogisticRegression(\n",
    "<<<<<<< local\n",
    "   solver=params['hyperparameters_training_simclr']['solver'],\n",
    "   fit_intercept=params['hyperparameters_training_simclr']['fit_intercept'],\n",
    "   max_iter=params['hyperparameters_training_simclr']['max_iter'],\n",
    "   C=params['hyperparameters_training_simclr']['C'],\n",
    "=======\n",
    "   solver='lbfgs',\n",
    "   fit_intercept=True,\n",
    "   max_iter=10000,\n",
    "   C=1e5,\n",
    ">>>>>>> remote\n",
    "   class_weight={iClassWeight:classWeight for iClassWeight, classWeight in enumerate(class_weights)},\n",
    "#    class_weight=class_weights,\n",
    ")\n",
    "model.fit(data_splitter.features_train, data_splitter.labels_train)\n",
    "\n",
    "print(f'Calculating tracker outputs and saving to {directory_save}...')\n",
    "training_tracker = cu.TrainingTracker(\n",
    "    directory_save=directory_save,\n",
    "    class_weights=class_weights, # Class Weights\n",
    "    n_train_actual=data_splitter.n_train_actual,\n",
    "    model=({'coef':model.coef_, 'intercept':model.intercept_})\n",
    ")\n",
    "\n",
    "y_train_preds = model.predict(data_splitter.features_train).astype(int)\n",
    "y_train_true = data_splitter.labels_train\n",
    "y_val_preds = model.predict(data_splitter.features_val).astype(int)\n",
    "y_val_true = data_splitter.labels_val\n",
    "\n",
    "# Save training loop results from current epoch for training set\n",
    "training_tracker.add_accuracy(0, 'accuracy_training', y_train_true, y_train_preds) # Generating training loss\n",
    "training_tracker.add_confusion_matrix(0, 'confusionMatrix_training', y_train_true, y_train_preds) # Generating confusion matrix\n",
    "\n",
    "# Save training loop results from current epoch for validation set\n",
    "training_tracker.add_accuracy(0, 'accuracy_val', y_val_true, y_val_preds) # Generating validation accuracy\n",
    "training_tracker.add_confusion_matrix(0, 'confusionMatrix_val', y_val_true, y_val_preds) # Generating validation confusion matrix\n",
    "\n",
    "training_tracker.save_results() # TODO: JZ, ADJUST RESULTS SAVING TO SAVE CONFUSION MATRICES AS NOT A DATAFRAME CSV\n",
    "training_tracker.print_results()\n",
    "\n",
    "model_save = {\n",
    "<<<<<<< local\n",
    "    'intercept': model.intercept_,\n",
    "    'coefs': model.coef_,\n",
    "=======\n",
    "    'intercept_': model.intercept_,\n",
    "    'coef_': model.coef_,\n",
    "    'classes_': model.classes_,\n",
    ">>>>>>> remote\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ea5935",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**>>>>>>> remote**</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(str((Path(directory_save) / 'model.npy').resolve()), model_save, allow_pickle=True)\n",
    "<<<<<<< local\n",
    "<<<<<<< local\n",
    "# with open(str((Path(directory_save) / 'classifierTrainingRun_interim.pkl').resolve()), 'wb') as f:\n",
    "#     np.save(\n",
    "#         file=f,\n",
    "#         arr=classifierTrainingRun_interim,\n",
    "#         allow_pickle=True\n",
    "#     )\n",
    "=======\n",
    "\n",
    "classifierTrainingRun_interim['params_prespecified'] = params\n",
    "=======\n",
    ">>>>>>> remote\n",
    "with open(str((Path(directory_save) / 'classifierTrainingRun_interim.pkl').resolve()), 'wb') as f:\n",
    "    np.save(\n",
    "        file=f,\n",
    "        arr=classifierTrainingRun_interim,\n",
    "        allow_pickle=True\n",
    "    )\n",
    ">>>>>>> remote\n",
    "\n",
    "print(f'Saved model fit results.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<<<<<<< LOCAL CELL DELETED >>>>>>>\n",
    "np.save(str((Path(directory_save) / 'model.npy').resolve()), model_save, allow_pickle=True)\n",
    "# with open(str((Path(directory_save) / 'classifierTrainingRun_interim.pkl').resolve()), 'wb') as f:\n",
    "#     np.save(\n",
    "#         file=f,\n",
    "#         arr=classifierTrainingRun_interim,\n",
    "#         allow_pickle=True\n",
    "#     )\n",
    "\n",
    "print(f'Saved model fit results.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ROICaT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

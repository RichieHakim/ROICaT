{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7866666",
   "metadata": {},
   "source": [
    "TODO: \n",
    "\n",
    "add some plotting\n",
    "\n",
    "add way to determine clustering linkage distances\n",
    "\n",
    "clean up later modules\n",
    "\n",
    "put cluster selection into module\n",
    "\n",
    "make cluster selection work with sparse inputs\n",
    "\n",
    "chase down memory usage in cluster selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50622a4e",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92846ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conda Environment: rich_clust\n",
      "python version: 3.9.12\n"
     ]
    }
   ],
   "source": [
    "# widen jupyter notebook window\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:95% !important; }</style>\"))\n",
    "\n",
    "# check environment\n",
    "import os\n",
    "print(f'Conda Environment: ' + os.environ['CONDA_DEFAULT_ENV'])\n",
    "\n",
    "from platform import python_version\n",
    "print(f'python version: {python_version()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4eb1fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import natsort\n",
    "\n",
    "import torch\n",
    "# from kymatio.torch import Scattering2D\n",
    "\n",
    "import gc\n",
    "import time\n",
    "import functools\n",
    "import multiprocessing as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b7a5c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_save = '/home/rich/Desktop/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81f6ee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88b893e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0+cu113'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "964102c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a74c9f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.14.0.dev20220707'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchvision.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86b07945",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/site-packages/torchaudio/lib/libtorchaudio.so: undefined symbol: _ZN2at27getStepCallbacksUnlessEmptyENS_11RecordScopeE",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchaudio\u001b[39;00m\n",
      "File \u001b[0;32m/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/site-packages/torchaudio/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchaudio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m      2\u001b[0m     _extension,\n\u001b[1;32m      3\u001b[0m     compliance,\n\u001b[1;32m      4\u001b[0m     datasets,\n\u001b[1;32m      5\u001b[0m     functional,\n\u001b[1;32m      6\u001b[0m     io,\n\u001b[1;32m      7\u001b[0m     kaldi_io,\n\u001b[1;32m      8\u001b[0m     models,\n\u001b[1;32m      9\u001b[0m     pipelines,\n\u001b[1;32m     10\u001b[0m     sox_effects,\n\u001b[1;32m     11\u001b[0m     transforms,\n\u001b[1;32m     12\u001b[0m     utils,\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchaudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_audio_backend, list_audio_backends, set_audio_backend\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/site-packages/torchaudio/_extension.py:103\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m \u001b[43m_init_extension\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/site-packages/torchaudio/_extension.py:88\u001b[0m, in \u001b[0;36m_init_extension\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchaudio C++ extension is not available.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m \u001b[43m_load_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlibtorchaudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# This has to happen after the base library is loaded\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchaudio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _torchaudio  \u001b[38;5;66;03m# noqa\u001b[39;00m\n",
      "File \u001b[0;32m/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/site-packages/torchaudio/_extension.py:51\u001b[0m, in \u001b[0;36m_load_lib\u001b[0;34m(lib)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m torch\u001b[38;5;241m.\u001b[39mclasses\u001b[38;5;241m.\u001b[39mload_library(path)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/site-packages/torch/_ops.py:255\u001b[0m, in \u001b[0;36m_Ops.load_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    250\u001b[0m path \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils_internal\u001b[38;5;241m.\u001b[39mresolve_library_path(path)\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dl_open_guard():\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;66;03m# Import the shared library into the process, thus running its\u001b[39;00m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;66;03m# static (global) initialization code in order to register custom\u001b[39;00m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;66;03m# operators with the JIT.\u001b[39;00m\n\u001b[0;32m--> 255\u001b[0m     \u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_libraries\u001b[38;5;241m.\u001b[39madd(path)\n",
      "File \u001b[0;32m/media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/ctypes/__init__.py:382\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
      "\u001b[0;31mOSError\u001b[0m: /media/rich/OS/Users/Richard/Linux_stuff_on_OS/conda_envs/envs/rich_clust/lib/python3.9/site-packages/torchaudio/lib/libtorchaudio.so: undefined symbol: _ZN2at27getStepCallbacksUnlessEmptyENS_11RecordScopeE"
     ]
    }
   ],
   "source": [
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebd0569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'paths': {\n",
    "        'dir_github': r'/media/rich/Home_Linux_partition/github_repos/',  ## directory where ROICat is\n",
    "        'dir_allOuterFolders': r\"/media/rich/bigSSD/other lab data/Harnett_lab/ROI_Tracking/Vincent_Valerio/4th_email/AllStatFiles/rbp16\",  ## directory where directories containing below 'pathSuffixTo...' are\n",
    "        'pathSuffixToStat': 'plane0/stat.npy',  ## path suffix to where the stat.npy file is\n",
    "        'pathSuffixToOps': 'plane0/ops.npy',  ## path suffix to where the ops.npy file is\n",
    "    },\n",
    "    'importing': {\n",
    "        'data_verbose': True,  ## default: True. Whether to print out data importing information\n",
    "        'out_height_width': [36, 36],  ## default: [36,36]. Height and width of output images (note that this must agree with the input of the ROInet input)\n",
    "        'max_footprint_width': 1025,  ## default: 1025. Maximum length of a spatial footprint. If you get an error during importing, try increasing this value.\n",
    "        'type_meanImg': 'meanImgE',  ## default: 'meanImgE'. Type of mean image to use for normalization. This is just a field in the ops.npy file.\n",
    "        'images': None,  ## default: None. Set to None if you want to use the images extracted from Suite2p\n",
    "        'import_workers': -1, ## default: -1. Number of workers to use for importing. Set to -1 to use all available workers.\n",
    "    },\n",
    "    'alignment': {\n",
    "        'method': 'createOptFlow_DeepFlow',  ## default: 'createOptFlow_DeepFlow'. Method to use for creating optical flow.\n",
    "        'kwargs_method': None,  ## default: None. Keyword arguments to pass to the method.\n",
    "        'return_sparse': True,  ## default: True. Whether to return a sparse matrix or a dense matrix.\n",
    "        'normalize': True,  ## default: True. Whether to normalize the optical flow.\n",
    "    },\n",
    "    'blurring': {\n",
    "        'kernel_halfWidth': 2.0,  ## default: 2.0. Half-width of the Gaussian kernel used for blurring. Use smaller values for smaller ROIs (dendrites) and larger values for larger ROIs (somata).\n",
    "        'device': 'cpu',  ## default: 'cpu'. Device to use for blurring. Recommend using 'cpu' even if you have a GPU.\n",
    "        'plot_kernel': False,  ## default: False. Whether to plot the kernel used for blurring.\n",
    "        'batch_size': 2000,  ## default: 2000. Number of images to use for each batch.\n",
    "    },\n",
    "    'ROInet': {\n",
    "        'device': 'cuda:0',  ## default: 'cuda:0'. Device to use for ROInet. Recommend using a GPU.\n",
    "        'dir_networkFiles': '/home/rich/Downloads/ROInet',  ## local directory where network files are stored\n",
    "        'download_from_gDrive': 'check_local_first',  ## default: 'check_local_first'. Whether to download the network files from Google Drive or to use the local files.\n",
    "        'gDriveID': '1FCcPZUuOR7xG-hdO6Ei6mx8YnKysVsa8',  ## default: '1FCcPZUuOR7xG-hdO6Ei6mx8YnKysVsa8'. Google Drive ID of the network files.\n",
    "        'verbose': True,  ## default: True. Whether to print out ROInet information.\n",
    "        'goal_size': 250,  ## default: 250. Size of the ROI to use for ROInet.\n",
    "        'ptile_norm': 90,  ## default: 90. Percentile to use for normalizing the ROI.\n",
    "        'scale_norm': 0.6,  ## default: 0.6. Scale to use for normalizing the ROI.\n",
    "        'pref_plot': False,  ## default: False. Whether to plot the ROI and the normalized ROI.\n",
    "        'batchSize_dataloader': 8,  ## default: 8. Number of images to use for each batch.\n",
    "        'pinMemory_dataloader': True,  ## default: True. Whether to pin the memory of the dataloader.\n",
    "        'persistentWorkers_dataloader': True,  ## default: True. Whether to use persistent workers for the dataloader.\n",
    "        'prefetchFactor_dataloader': 2,  ## default: 2. Number of prefetch factors to use for the dataloader.\n",
    "    },\n",
    "    'SWT': {\n",
    "        'kwargs_Scattering2D': {'J': 2, 'L': 8},  ## default: {'J': 2, 'L': 8}. Keyword arguments to pass to the Scattering2D function.\n",
    "        'image_shape': (36, 36),  ## default: (36,36). Shape of the images.\n",
    "        'device': 'cuda:0',  ## default: 'cuda:0'. Device to use for SWT. Recommend using a GPU.\n",
    "    }, \n",
    "    'similarity': {\n",
    "        'device': 'cpu',  ## default: 'cpu'. Device to use for similarity. Recommend using 'cpu' even if you have a GPU.\n",
    "        'n_workers': -1,  ## default: -1. Number of workers to use for similarity. Set to -1 to use all available workers.\n",
    "        'spatialFootprint_maskPower': 0.8,  ## default: 0.8. Power to use for the spatial footprint.\n",
    "        'block_height': 50,  ## default: 50. Height of the block to use for similarity.\n",
    "        'block_width': 50,  ## default: 50. Width of the block to use for similarity.\n",
    "        'overlapping_width_Multiplier': 0.1,  ## default: 0.1. Multiplier to use for the overlapping width.\n",
    "        'algorithm_nearestNeigbors_spatialFootprints': 'brute',  ## default: 'brute'. Algorithm to use for nearest neighbors.\n",
    "        'n_neighbors_nearestNeighbors_spatialFootprints': 'full',  ## default: 'full'. Number of neighbors to use for nearest neighbors.\n",
    "        'locality': 1,  ## default: 1. Locality to use for nearest neighbors. Exponent applied to the similarity matrix input.\n",
    "        'verbose': True,  ## default: True. Whether to print out similarity information.\n",
    "    },\n",
    "    'similarity_compute': {\n",
    "        'linkage_methods': ['single', 'complete', 'ward', 'average'],  ## default: ['single', 'complete', 'ward', 'average']. Linkage methods to use for computing linkage distances and ultimately clusters.\n",
    "        'bounded_logspace_args': (0.05, 2, 50),  ## default: (0.05, 2, 50). Linkage distances to use to find clusters.\n",
    "        'min_cluster_size': 2,  ## default: 2. Minimum size of a cluster.\n",
    "        'max_cluster_size': None,  ## default: None. Maximum size of a cluster. If None, then set to n_sessions.\n",
    "        'batch_size_hashing': 100,  ## default: 100. Number of images to use for each batch.\n",
    "        'cluster_similarity_reduction_intra': 'mean',  ## default: 'mean'. Reduction method to use for intra-cluster similarity.\n",
    "        'cluster_similarity_reduction_inter': 'max',  ## default: 'max'. Reduction method to use for inter-cluster similarity.\n",
    "        'cluster_silhouette_reduction_intra': 'mean',  ## default: 'mean'. Reduction method to use for intra-cluster silhouette.\n",
    "        'cluster_silhouette_reduction_inter': 'max',  ## default: 'max'. Reduction method to use for inter-cluster silhouette.\n",
    "        'n_workers': 8,  ## default: 8. Number of workers to use for similarity. WARNING, using many workers requires large memory requirement. Set to -1 to use all available workers.\n",
    "        'power_clusterSize': 2,  ## default: 2. Used in calculating custom cluster score. This is the exponent applied to the number of ROIs in a cluster.\n",
    "        'power_clusterSilhouette': 1.5,  ## default: 1.5. Used in calculating custom cluster score. This is the exponent applied to the silhouette score of a cluster.\n",
    "    },\n",
    "    'clusterAssigner': {\n",
    "        'device': 'cuda:0',  ## default: 'cuda:0'. Device to use for clusterAssigner. Recommend using a GPU.\n",
    "        'optimizer_partial_lr': 1e-1,  ## default: 1e-1. Learning rate for the optimizer.\n",
    "        'optimizer_partial_betas': (0.9, 0.900),  ## default: (0.9, 0.900). Betas for the optimizer.\n",
    "        'scheduler_partial_base_lr': 1e-3,  ## default: 1e-3. Base learning rate for the scheduler.\n",
    "        'scheduler_partial_max_lr': 3e0,  ## default: 3e0. Maximum learning rate for the scheduler.\n",
    "        'scheduler_partial_step_size_up': 250,  ## default: 250. Step size for the scheduler.\n",
    "        'scheduler_partial_cycle_momentum': False,  ## default: False. Whether to cycle the momentum of the optimizer.\n",
    "        'scheduler_partial_verbose': False,  ## default: False. Whether to print out scheduler information.\n",
    "        'dmCEL_temp': 1,  ## default: 1. Temperature to use for the dmCEL loss.\n",
    "        'dmCEL_sigSlope': 2,  ## default: 2. Slope to use for the dmCEL loss.\n",
    "        'dmCEL_sigCenter': 0.5,  ## default: 0.5. Center to use for the dmCEL loss.\n",
    "        'dmCEL_penalty': 1e0,  ## default: 1e0. Penalty to use for the dmCEL loss.\n",
    "        'sampleWeight_softplusKwargs': {'beta': 150, 'threshold': 50},  ## default: {'beta': 150, 'threshold': 50}. Keyword arguments to pass to the softplus function.\n",
    "        'sampleWeight_penalty': 1e3,  ## default: 1e3. Penalty to use for when an ROI is assigned to multiple clusters.\n",
    "        'fracWeighted_goalFrac': 1.0,  ## default: 1.0. Goal fraction ROIs assigned to a cluster.\n",
    "        'fracWeighted_sigSlope': 2,  ## default: 2. Slope to use for the sigmoid activation for the fracWeighted loss.\n",
    "        'fracWeighted_sigCenter': 0.5,  ## default: 0.5. Center to use for the fracWeighted loss sigmoid.\n",
    "        'fracWeight_penalty': 1e2,  ## default: 1e2. Penalty to use for the fracWeighted loss.\n",
    "        'maskL1_penalty': 2e-4,  ## default: 2e-4. Penalty to use for the L1 loss applied to the number of non-zero clusters.\n",
    "        'tol_convergence': 1e-9,  ## default: 1e-9. Tolerance to use for convergence.\n",
    "        'window_convergence': 50,  ## default: 50. Number of past iterations to use in calculating a smooth value for the loss derivative for convergence.\n",
    "        'freqCheck_convergence': 50,  ## default: 50. Period between checking for convergence.\n",
    "        'verbose': True,  ## default: True. Whether to print out information about the initialization.\n",
    "    },\n",
    "    'clusterAssigner_fit': {\n",
    "        'min_iter': 1e3,  ## default: 1e3. Minimum number of iterations to run.\n",
    "        'max_iter': 5e3,  ## default: 5e3. Maximum number of iterations to run.\n",
    "        'verbose': True,  ## default: True. Whether to print out information about the optimization.\n",
    "        'verbose_interval': 100,  ## default: 100. Number of iterations between printing out information about the optimization.\n",
    "        'm_threshold': 0.8,  ## default: 0.8. Threshold for the activated mask vector to define as an included cluster when making predictions.\n",
    "    },\n",
    "    'visualization': {\n",
    "        'FOV_threshold_confidence': 0.5,  ## default: 0.5. Threshold for the confidence scores when displaying ROIs.\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d73ee86",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_github = Path(params['paths']['dir_github']).resolve()\n",
    "\n",
    "import sys\n",
    "sys.path.append(str(dir_github))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ROICaT.tracking import data_importing, visualization, alignment, blurring, helpers, ROInet, scatteringWaveletTransformer, similarity_graph, cluster_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5743ff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_all = [helpers.deep_update_dict(params, ['paths', 'dir_allOuterFolders'], val) for val in [\n",
    "#         r\"/media/rich/bigSSD/other lab data/Harnett_lab/ROI_Tracking/Vincent_Valerio/4th_email/AllStatFiles/rbp6_3\",\n",
    "#         r\"/media/rich/bigSSD/other lab data/Harnett_lab/ROI_Tracking/Vincent_Valerio/4th_email/AllStatFiles/rbp10\",\n",
    "#         r\"/media/rich/bigSSD/other lab data/Harnett_lab/ROI_Tracking/Vincent_Valerio/4th_email/AllStatFiles/rbp11\",\n",
    "#         r\"/media/rich/bigSSD/other lab data/Harnett_lab/ROI_Tracking/Vincent_Valerio/4th_email/AllStatFiles/rbp12\",\n",
    "#         r\"/media/rich/bigSSD/other lab data/Harnett_lab/ROI_Tracking/Vincent_Valerio/4th_email/AllStatFiles/rbp13\",\n",
    "#         r\"/media/rich/bigSSD/other lab data/Harnett_lab/ROI_Tracking/Vincent_Valerio/4th_email/AllStatFiles/rbp16\",\n",
    "# ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f44b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "\n",
    "\n",
    "# Import paths\n",
    "def print_list(l):\n",
    "    for item in l:\n",
    "        print(item)\n",
    "\n",
    "dir_allOuterFolders = Path(params['paths']['dir_allOuterFolders']).resolve()\n",
    "\n",
    "folders_allSessions = natsort.natsorted(helpers.get_dir_contents(dir_allOuterFolders)[0])\n",
    "\n",
    "folders_toUse = folders_allSessions\n",
    "# folders_toUse = list(map(folders_allSessions.__getitem__, [np.arange(1,9, dtype=np.int32)]))\n",
    "\n",
    "\n",
    "# dir_allS2pFolders = [dir_allOuterFolders / folder / 'exp' / 'suite2p' / 'plane0' for folder in folders_toUse]\n",
    "dir_allS2pFolders = [dir_allOuterFolders / folder for folder in folders_toUse]\n",
    "\n",
    "pathSuffixToStat = params['paths']['pathSuffixToStat']\n",
    "pathSuffixToOps = params['paths']['pathSuffixToOps']\n",
    "\n",
    "paths_allStat = np.array([path / pathSuffixToStat for path in dir_allS2pFolders])[:2]\n",
    "paths_allOps  = np.array([path / pathSuffixToOps for path in dir_allS2pFolders])[:2]\n",
    "\n",
    "print(folders_allSessions)\n",
    "print(folders_toUse)\n",
    "print_list(dir_allS2pFolders)\n",
    "print_list(paths_allStat)\n",
    "\n",
    "\n",
    "#Import data\n",
    "data = data_importing.Data_suite2p(\n",
    "    paths_statFiles=paths_allStat,\n",
    "    paths_opsFiles=paths_allOps,\n",
    "    verbose=params['importing']['data_verbose'],\n",
    ");\n",
    "\n",
    "data.import_statFiles();\n",
    "\n",
    "data.import_ROI_centeredImages(\n",
    "    out_height_width=params['importing']['out_height_width'],\n",
    "    max_footprint_width=params['importing']['max_footprint_width'],\n",
    ");\n",
    "\n",
    "data.import_FOV_images(\n",
    "    type_meanImg=params['importing']['type_meanImg'],\n",
    "    images=params['importing']['images'],\n",
    ");\n",
    "\n",
    "data.import_ROI_spatialFootprints(workers=params['importing']['import_workers']);\n",
    "\n",
    "# visualization.display_toggle_image_stack(data.FOV_images)\n",
    "\n",
    "\n",
    "# Alignment\n",
    "aligner = alignment.Alinger(\n",
    "    method=params['alignment']['method'],\n",
    "    kwargs_method=params['alignment']['kwargs_method'],\n",
    ")\n",
    "\n",
    "aligner.register_ROIs(\n",
    "    templateFOV=data.FOV_images[0],\n",
    "    FOVs=data.FOV_images,\n",
    "    ROIs=data.spatialFootprints,\n",
    "    return_sparse=params['alignment']['return_sparse'],\n",
    "    normalize=params['alignment']['normalize'],\n",
    ");\n",
    "\n",
    "# visualization.display_toggle_image_stack(aligner.FOVs_aligned)\n",
    "# visualization.display_toggle_image_stack(aligner.get_ROIsAligned_maxIntensityProjection())\n",
    "\n",
    "\n",
    "# Blur ROIs (optional)\n",
    "blurrer = blurring.ROI_Blurrer(\n",
    "    frame_shape=(data.FOV_height, data.FOV_width),\n",
    "    kernel_halfWidth=params['blurring']['kernel_halfWidth'],\n",
    "    device=params['blurring']['device'],\n",
    "    plot_kernel=params['blurring']['plot_kernel'],\n",
    ")\n",
    "\n",
    "blurrer.blur_ROIs(\n",
    "    spatialFootprints=aligner.ROIs_aligned,\n",
    "    batch_size=params['blurring']['batch_size'],\n",
    ");\n",
    "\n",
    "# visualization.display_toggle_image_stack(blurrer.get_ROIsBlurred_maxIntensityProjection())\n",
    "\n",
    "\n",
    "# Neural network embedding distances\n",
    "hash_dict_true = {\n",
    "    'params': ('params.json', '877e17df8fa511a03bc99cd507a54403'),\n",
    "    'model': ('model.py', '6ef5c29793ae16a64e43e8cab33d9ff4'),\n",
    "    'state_dict': ('ConvNext_tiny__1_0_unfrozen__simCLR.pth', 'a5fae4c9ea95f2c78b4690222b2928a5'),\n",
    "}\n",
    "\n",
    "roinet = ROInet.ROInet_embedder(\n",
    "    device=params['ROInet']['device'],\n",
    "    dir_networkFiles=params['ROInet']['dir_networkFiles'],\n",
    "    download_from_gDrive=params['ROInet']['download_from_gDrive'],\n",
    "    gDriveID=params['ROInet']['gDriveID'],\n",
    "    hash_dict_networkFiles=hash_dict_true,\n",
    "    verbose=params['ROInet']['verbose'],\n",
    ")\n",
    "\n",
    "roinet.generate_dataloader(\n",
    "    ROI_images=data.ROI_images,\n",
    "    goal_size=params['ROInet']['goal_size'],\n",
    "    ptile_norm=params['ROInet']['ptile_norm'],\n",
    "    scale_norm=params['ROInet']['scale_norm'],\n",
    "    pref_plot=params['ROInet']['pref_plot'],\n",
    "    batchSize_dataloader=params['ROInet']['batchSize_dataloader'],\n",
    "    pinMemory_dataloader=params['ROInet']['pinMemory_dataloader'],\n",
    "    numWorkers_dataloader=mp.cpu_count(),\n",
    "    persistentWorkers_dataloader=params['ROInet']['persistentWorkers_dataloader'],\n",
    "    prefetchFactor_dataloader=params['ROInet']['prefetchFactor_dataloader'],    \n",
    ")\n",
    "\n",
    "roinet.generate_latents();\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "# Scattering wavelet embedding distances\n",
    "swt = scatteringWaveletTransformer.SWT(\n",
    "    kwargs_Scattering2D=params['SWT']['kwargs_Scattering2D'], \n",
    "    image_shape=params['SWT']['image_shape'], \n",
    "    device=params['SWT']['device'],\n",
    ")\n",
    "\n",
    "swt.transform(ROI_images=np.concatenate(data.ROI_images, axis=0));\n",
    "\n",
    "# Compute similarities\n",
    "sim = similarity_graph.ROI_graph(\n",
    "    device=params['similarity']['device'],\n",
    "    n_workers=params['similarity']['n_workers'],\n",
    "    spatialFootprint_maskPower=params['similarity']['spatialFootprint_maskPower'],\n",
    "    frame_height=data.FOV_height,\n",
    "    frame_width=data.FOV_width,\n",
    "    block_height=params['similarity']['block_height'],\n",
    "    block_width=params['similarity']['block_width'],\n",
    "    overlapping_width_Multiplier=params['similarity']['overlapping_width_Multiplier'],\n",
    "    algorithm_nearestNeigbors_spatialFootprints=params['similarity']['algorithm_nearestNeigbors_spatialFootprints'],\n",
    "    n_neighbors_nearestNeighbors_spatialFootprints=params['similarity']['n_neighbors_nearestNeighbors_spatialFootprints'],\n",
    "    locality=params['similarity']['locality'],\n",
    "    verbose=params['similarity']['verbose'],\n",
    ")\n",
    "\n",
    "sim.visualize_blocks()\n",
    "\n",
    "sim.compute_similarity_blockwise(\n",
    "    spatialFootprints=blurrer.ROIs_blurred,\n",
    "    features_NN=roinet.latents,\n",
    "    features_SWT=swt.latents,\n",
    "    ROI_session_bool=data.sessionID_concat,\n",
    "    linkage_methods=params['similarity_compute']['linkage_methods'],\n",
    "    linkage_distances=helpers.bounded_logspace(*params['similarity_compute']['bounded_logspace_args']),\n",
    "    min_cluster_size=params['similarity_compute']['min_cluster_size'],\n",
    "    max_cluster_size=params['similarity_compute']['max_cluster_size'],\n",
    "    batch_size_hashing=params['similarity_compute']['batch_size_hashing'],\n",
    ");\n",
    "\n",
    "sim.compute_cluster_similarity_graph(\n",
    "        cluster_similarity_reduction_intra=params['similarity_compute']['cluster_similarity_reduction_intra'],\n",
    "        cluster_similarity_reduction_inter=params['similarity_compute']['cluster_similarity_reduction_inter'],\n",
    "        cluster_silhouette_reduction_intra=params['similarity_compute']['cluster_silhouette_reduction_intra'],\n",
    "        cluster_silhouette_reduction_inter=params['similarity_compute']['cluster_silhouette_reduction_inter'],\n",
    "        n_workers=params['similarity_compute']['n_workers'],\n",
    ");\n",
    "\n",
    "sim.compute_cluster_scores(\n",
    "    power_clusterSize=params['similarity_compute']['power_clusterSize'], \n",
    "    power_clusterSilhouette=params['similarity_compute']['power_clusterSilhouette'],\n",
    ");\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(10,5))\n",
    "axs[0].plot(sim.scores.cpu())\n",
    "# plt.ylim([0,1.1])\n",
    "axs[1].plot(sim.scores.cpu())\n",
    "axs[1].set_yscale('log')\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(sim.scores.cpu(), 500)\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter((np.array(sim.cluster_bool.sum(1)).squeeze()), sim.scores, alpha=0.01)\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "ca= cluster_assignment.Cluster_Assigner(\n",
    "    c=sim.c_sim,\n",
    "    h=sim.cluster_bool.T,\n",
    "    w=sim.scores,\n",
    "    device=params['clusterAssigner']['device'],\n",
    "    m_init=(torch.ones(sim.c_sim.shape[0])*-5 + torch.rand(sim.c_sim.shape[0])*1).type(torch.float32),\n",
    "    optimizer_partial=functools.partial(torch.optim.Adam, lr=params['clusterAssigner']['optimizer_partial_lr'], betas=params['clusterAssigner']['optimizer_partial_betas']),\n",
    "    scheduler_partial=functools.partial(torch.optim.lr_scheduler.CyclicLR, base_lr=params['clusterAssigner']['scheduler_partial_base_lr'], max_lr=params['clusterAssigner']['scheduler_partial_max_lr'], step_size_up=params['clusterAssigner']['scheduler_partial_step_size_up'], cycle_momentum=params['clusterAssigner']['scheduler_partial_cycle_momentum'], verbose=params['clusterAssigner']['scheduler_partial_verbose']),\n",
    "    dmCEL_temp=params['clusterAssigner']['dmCEL_temp'],\n",
    "    dmCEL_sigSlope=params['clusterAssigner']['dmCEL_sigSlope'],\n",
    "    dmCEL_sigCenter=params['clusterAssigner']['dmCEL_sigCenter'],\n",
    "    dmCEL_penalty=params['clusterAssigner']['dmCEL_penalty'],\n",
    "    sampleWeight_softplusKwargs=params['clusterAssigner']['sampleWeight_softplusKwargs'],\n",
    "    sampleWeight_penalty=params['clusterAssigner']['sampleWeight_penalty'],\n",
    "    fracWeighted_goalFrac=params['clusterAssigner']['fracWeighted_goalFrac'],\n",
    "    fracWeighted_sigSlope=params['clusterAssigner']['fracWeighted_sigSlope'],\n",
    "    fracWeighted_sigCenter=params['clusterAssigner']['fracWeighted_sigCenter'],\n",
    "    fracWeight_penalty=params['clusterAssigner']['fracWeight_penalty'],\n",
    "    maskL1_penalty=params['clusterAssigner']['maskL1_penalty'],\n",
    "    tol_convergence=params['clusterAssigner']['tol_convergence'],\n",
    "    window_convergence=params['clusterAssigner']['window_convergence'],\n",
    "    freqCheck_convergence=params['clusterAssigner']['freqCheck_convergence'],\n",
    "    verbose=params['clusterAssigner']['verbose'],\n",
    ")\n",
    "\n",
    "ca.fit(\n",
    "    min_iter=params['clusterAssigner_fit']['min_iter'],\n",
    "    max_iter=params['clusterAssigner_fit']['max_iter'],\n",
    "    verbose=params['clusterAssigner_fit']['verbose'], \n",
    "    verbose_interval=params['clusterAssigner_fit']['verbose_interval'],\n",
    ")\n",
    "\n",
    "ca.plot_loss()\n",
    "\n",
    "# del clusterAssigner\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# clusterAssigner.plot_c_masked_matrix()\n",
    "\n",
    "preds, confidence, scores_samples, m_bool = ca.predict(m_threshold=params['clusterAssigner_fit']['m_threshold'])\n",
    "# preds, confidence, scores_samples, m_bool = clusterAssigner.predict(m_threshold=0.99)\n",
    "\n",
    "ca.plot_clusterWeights()\n",
    "\n",
    "ca.plot_sampleWeights()\n",
    "\n",
    "ca.plot_clusterScores(bins=200)\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "\n",
    "fig, axs = ca.plot_labelCounts()\n",
    "axs[0].set_ylim([0,20]);\n",
    "\n",
    "print(f'Number of clusters: {m_bool.sum()}')\n",
    "\n",
    "\n",
    "\n",
    "# visualization\n",
    "FOV_clusters = visualization.compute_colored_FOV(\n",
    "    spatialFootprints=aligner.ROIs_aligned,\n",
    "    FOV_height=data.FOV_height,\n",
    "    FOV_width=data.FOV_width,\n",
    "    preds=ca.preds,\n",
    "    confidence=ca.confidence,\n",
    "    threshold_confidence = params['visualization']['FOV_threshold_confidence'],\n",
    "#     threshold_confidence = 0.99,\n",
    ")\n",
    "\n",
    "# %matplotlib notebook\n",
    "# visualization.display_toggle_image_stack(FOV_clusters)\n",
    "\n",
    "preds_by_session = [preds[idx].numpy() for idx in data.sessionID_concat.T]\n",
    "\n",
    "ROIs = {\n",
    "    \"ROIs_aligned\": aligner.ROIs_aligned,\n",
    "    \"ROIs_raw\": data.spatialFootprints,\n",
    "    \"frame_height\": data.FOV_height,\n",
    "    \"frame_width\": data.FOV_width,\n",
    "    \"idx_roi_session\": [np.where(idx)[0] for idx in data.sessionID_concat.T]\n",
    "}\n",
    "\n",
    "name_save = os.path.split(dir_allOuterFolders)[-1]\n",
    "helpers.simple_save(\n",
    "    {\n",
    "        \"UCIDs\": list(ca.preds.numpy().astype(np.int64)),\n",
    "        \"UCIDs_bySession\": preds_by_session,\n",
    "        \"ROIs\": ROIs,\n",
    "    },\n",
    "    filename=Path(dir_save) / (name_save + '.plane0.rClust' '.pkl'),\n",
    "#     filename='/media/rich/bigSSD/analysis_data/mouse 2_6/multiday_alignment/UCIDs.pkl'\n",
    ")\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915fd8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %matplotlib notebook\n",
    "# visualization.display_toggle_image_stack(FOV_clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0866e3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import scipy.sparse\n",
    "\n",
    "# import torch_sparse as ts\n",
    "\n",
    "# scipy.sparse.save_npz(\n",
    "#     file=r'/home/rich/Desktop/c_sim.npz',\n",
    "#     matrix=sim.c_sim.tocsr(),\n",
    "#     compressed=True\n",
    "# )\n",
    "# scipy.sparse.save_npz(\n",
    "#     file=r'/home/rich/Desktop/cluster_bool.npz',\n",
    "#     matrix=sim.cluster_bool.tocsr(),\n",
    "#     compressed=True\n",
    "# )\n",
    "# np.save(\n",
    "#     file=r'/home/rich/Desktop/scores.npy',\n",
    "#     arr=sim.scores.numpy(),\n",
    "# )\n",
    "\n",
    "# c_sim = scipy.sparse.load_npz(file=r'/home/rich/Desktop/c_sim.npz').tolil()\n",
    "# cluster_bool = scipy.sparse.load_npz(file=r'/home/rich/Desktop/cluster_bool.npz').tocsr()\n",
    "# scores = torch.as_tensor(np.load(file=r'/home/rich/Desktop/scores.npy'), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213d71ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fef490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c4d62a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60840e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d835dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe27215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c05f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0396ff0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a24ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377fa162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "2884eabb8096b1e7cd90110c1616d829c56882231962761420acd4f852f6003e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

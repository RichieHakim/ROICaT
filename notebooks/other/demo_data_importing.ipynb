{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7864836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# widen jupyter notebook window\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e7486e",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "#### Welcome to a demo notebook on different methods for ingesting diverse data into ROICaT. There are 3 sections:\n",
    "\n",
    "- [Section 1](#Section-1): Ingesting data from **different segmentation packages** (Suite2p, CaImAn, CNMF, NWB, etc.).\n",
    "- [Section 2](#Section-2): **Understanding** the `Data_roicat` class.\n",
    "- [Section 3](#Section-3): Ingesting **custom data**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e739fc0",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4b1f992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "from IPython.display import display\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c4421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import roicat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ce6ec6",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbfa33a",
   "metadata": {},
   "source": [
    "# Section 1\n",
    "## Ingesting different data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b33df0e",
   "metadata": {},
   "source": [
    "We've made a few subclasses that make ingesting this data from various sources easy. These sources include:\n",
    "```\n",
    "METHOD               ROICaT class type\n",
    "======               =================\n",
    "- Suite2p ------ via Data_suite2p or Data_roiextractors\n",
    "- CaImAn ------- via Data_caiman or Data_roiextractors\n",
    "- CNMF --------- via Data_roiextractors\n",
    "- NWB ---------- via Data_roiextractors\n",
    "- Sima --------- via Data_roiextractors\n",
    "- EXTRACT ------ via Data_roiextractors\n",
    "\n",
    "OTHER:\n",
    "- Raw data ----- via Data_roicat\n",
    "- ROICaT ------- via Data_roicat\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fd5791",
   "metadata": {},
   "source": [
    "##### Download data\n",
    "\n",
    "Let's first download a single dataset that has been processed by each segmentation method above. This data was curated by the good folks at [CatalystNeuro](https://www.catalystneuro.com/), which makes [roiextractors](https://github.com/catalystneuro/roiextractors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74614b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_download_temp = tempfile.gettempdir()\n",
    "path_download_temp = str(Path(dir_download_temp) / 'datasets_roiextractors.zip')\n",
    "\n",
    "roicat.helpers.download_file(\n",
    "    url='https://osf.io/db5h8/download',\n",
    "    path_save=path_download_temp,\n",
    ")\n",
    "paths_extracted = roicat.helpers.extract_zip(\n",
    "    path_zip=path_download_temp,\n",
    "    path_extract=None,\n",
    "    verbose=True,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd83a2be",
   "metadata": {},
   "source": [
    "### Make `Data_roiextractors` objects\n",
    "Let's make first `roiextractors` objects out of each of these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14479151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import roiextractors\n",
    "\n",
    "dir_segData = paths_extracted[0]\n",
    "\n",
    "re_caiman = roiextractors.CaimanSegmentationExtractor(file_path=str(Path(dir_segData) / 'caiman' / 'caiman_analysis.hdf5'))\n",
    "re_cnmfe = roiextractors.CnmfeSegmentationExtractor(file_path=str(Path(dir_segData) / 'cnmfe' / '2014_04_01_p203_m19_check01_cnmfeAnalysis.mat'))\n",
    "re_EXTRACT = roiextractors.ExtractSegmentationExtractor(file_path=str(Path(dir_segData) / 'extract' / 'extract_public_output.mat'), sampling_frequency=30)\n",
    "re_NWB = roiextractors.NwbSegmentationExtractor(file_path=str(Path(dir_segData) / 'nwb' / 'nwb_test.nwb'))\n",
    "re_s2p = roiextractors.Suite2pSegmentationExtractor(folder_path=str(Path(dir_segData) / 'suite2p'), plane_no=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f8c942",
   "metadata": {},
   "source": [
    "Next, let's convert the `roiextractors` object to `Data_roicat` objects by using the `Data_roiextractors` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e7009d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_re_caiman = roicat.data_importing.Data_roiextractors(re_caiman)\n",
    "display(data_re_caiman)\n",
    "data_re_cnmfe = roicat.data_importing.Data_roiextractors(re_cnmfe)\n",
    "display(data_re_cnmfe)\n",
    "data_re_EXTRACT = roicat.data_importing.Data_roiextractors(re_EXTRACT)\n",
    "display(data_re_EXTRACT)\n",
    "data_re_NWB = roicat.data_importing.Data_roiextractors(re_NWB)\n",
    "display(data_re_NWB)\n",
    "data_re_s2p = roicat.data_importing.Data_roiextractors(re_s2p)\n",
    "display(data_re_s2p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e41ec7",
   "metadata": {},
   "source": [
    "### Make `Data_suite2p` and `Data_caiman` objects\n",
    "\n",
    "For suite2p and CaImAn, we recommend using our built in data ingestion classes. These collect a little more information and can be faster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2c5851",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_roicat_s2p = roicat.data_importing.Data_suite2p(\n",
    "    paths_statFiles=str(Path(dir_segData) / 'suite2p' / 'plane0' / 'stat.npy'),\n",
    "    paths_opsFiles=str(Path(dir_segData) / 'suite2p' / 'plane0' / 'ops.npy'),\n",
    ")\n",
    "display(data_roicat_s2p)\n",
    "\n",
    "data_roicat_caiman = roicat.data_importing.Data_caiman(\n",
    "    paths_resultsFiles=str(Path(dir_segData) / 'caiman' / 'caiman_analysis.hdf5')\n",
    ")\n",
    "display(data_roicat_caiman)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89f871c",
   "metadata": {},
   "source": [
    "## Make multisession objects\n",
    "\n",
    "Normally we are using ROICaT with multiple sessions of data. To do this, just pass in a list of paths or roiextractors objects where each element is from one session."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1674d55f",
   "metadata": {},
   "source": [
    "#### Multisession `Data_roiextractors`\n",
    "\n",
    "We will simulate having multiple sessions of a dataset from the EXTRACT pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c505fe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_multi_EXTRACT = [roiextractors.ExtractSegmentationExtractor(file_path=path, sampling_frequency=30) for path in [str(Path(dir_segData) / 'extract' / 'extract_public_output.mat')]*10]\n",
    "\n",
    "print(f'Number of sessions: {len(re_multi_EXTRACT)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1001189",
   "metadata": {},
   "source": [
    "Now let's make a single `Data_roiextractors` object containing all these sessions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab1a690",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_roicat_multi_EXTRACT = roicat.data_importing.Data_roiextractors(segmentation_extractor_objects=re_multi_EXTRACT)\n",
    "display(data_roicat_multi_EXTRACT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025f0504",
   "metadata": {},
   "source": [
    "You'll see that this object now stores data from all 10 of these sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76db37c",
   "metadata": {},
   "source": [
    "#### Multisession `Data_suite2p`\n",
    "\n",
    "Now let's do it with the `Data_suite2p` class (recommended for suite2p data). This data was collected and provided by Valerio Francioni while in Mark Harnett's lab at MIT:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1575df",
   "metadata": {},
   "source": [
    "*Download*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490e8a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define temporary directory to save files to\n",
    "dir_temp = tempfile.gettempdir()\n",
    "path_test_temp = str(Path(dir_temp) / 'data_valerio.zip')\n",
    "\n",
    "## Download zip file\n",
    "roicat.helpers.download_file(\n",
    "    url='https://osf.io/ru4x5/download',\n",
    "    path_save=path_test_temp,\n",
    ")\n",
    "## Extract zip file\n",
    "paths_extracted = roicat.helpers.extract_zip(\n",
    "    path_zip=path_test_temp,\n",
    "    path_extract=None,\n",
    ")\n",
    "dir_test_data = paths_extracted[0]\n",
    "display(f'Downloaded and extracted folder containing test data to: {dir_test_data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370ff912",
   "metadata": {},
   "source": [
    "*Initialize class*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067dbe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make paired lists of all the stat.npy and ops.npy files\n",
    "paths_stat = roicat.helpers.find_paths(\n",
    "    dir_outer=dir_test_data,\n",
    "    reMatch='stat.npy',\n",
    "    depth=4,\n",
    ")\n",
    "paths_ops = [str(Path(p).parent / 'ops.npy') for p in paths_stat]\n",
    "\n",
    "## Initialize the class\n",
    "data_roicat_multi_suite2p = roicat.data_importing.Data_suite2p(\n",
    "    paths_statFiles=paths_stat,\n",
    "    paths_opsFiles=paths_ops,\n",
    ")\n",
    "\n",
    "display(data_roicat_multi_suite2p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db33e81e",
   "metadata": {},
   "source": [
    "And that's it, you now know how to use data from almost any segmentation pipeline to make a data object that can be used for any of the 3 pipelines in ROICaT. Let's finish by looking at some of the properties of these objects. If you look through the other notebooks, you'll see that the first steps of the pipelines just make this data object, so feel free to just plug in your data and go!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f25d31",
   "metadata": {},
   "source": [
    "# Section 2\n",
    "## Understanding the `Data_roicat` class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8583c058",
   "metadata": {},
   "source": [
    "All raw data is ingested and stored through a custom python superclass called `Data_roicat` which standardizes data that comes from different sources. The main types of data it ingests are:\n",
    "1. `spatialFootprints`: The images of individual ROIs within the field of view\n",
    "2. `FOV_images`: The image of the field of view itself (e.g. the mean fluorescence image of the raw movie)\n",
    "3. `ROI_images`: Small images of individual ROIs\n",
    "4. `class_labels`: The labels associated with each ROI\n",
    "5. `um_per_pixel`: The resolution of the imaging field of view\n",
    "\n",
    "Let's demonstrate on **Suite2p** multisession test data from Valerio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1807813",
   "metadata": {},
   "source": [
    "#### `ROI_images`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829de816",
   "metadata": {},
   "outputs": [],
   "source": [
    "roicat.visualization.display_toggle_image_stack(data_roicat_multi_suite2p.ROI_images[0], image_size=(200,200))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373b7963",
   "metadata": {},
   "source": [
    "#### `FOV_images`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5279122",
   "metadata": {},
   "outputs": [],
   "source": [
    "roicat.visualization.display_toggle_image_stack(data_roicat_multi_suite2p.FOV_images, image_size=(400,400))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd543aa",
   "metadata": {},
   "source": [
    "#### `spatialFootprints`\n",
    "ROIs from each session are stored as a scipy sparse array. Each sparse array is of shape: (`n_ROIs`, `height * width`). Notice that height and width dimension have been flattened into one dimension. We can reconstruct what a max intensity projection of ROIs looks like with the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b113173d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data_roicat_multi_suite2p.spatialFootprints)\n",
    "\n",
    "height_width = (data_roicat_multi_suite2p.FOV_height, data_roicat_multi_suite2p.FOV_width)\n",
    "\n",
    "FOVs_MIP_ROIs = [sf.max(0).toarray().reshape(height_width[0], height_width[1]) for sf in data_roicat_multi_suite2p.spatialFootprints]\n",
    "\n",
    "roicat.visualization.display_toggle_image_stack(FOVs_MIP_ROIs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8100f8e",
   "metadata": {},
   "source": [
    "##### Check completeness of object\n",
    "\n",
    "Lastly, there are 3 things a data object can be used for in ROICaT: **tracking**, **classification training**, and **classification inference**. Let's check to see what we can do with the data object we just made:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7db77ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_roicat_multi_suite2p.check_completeness()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781e0a44",
   "metadata": {},
   "source": [
    "Looks like we can do **tracking** and **classification-inference**, but not **classification-training** because we don't have class labels for each ROI. This makes sense because this is a raw dataset and labeling wasn't performed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8908ea8",
   "metadata": {},
   "source": [
    "### Save and load the object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367f40ba",
   "metadata": {},
   "source": [
    "##### Option 1: Save the data object using `RichFile`\n",
    "We use a custom library for saving and loading complex objects called `RichFile` ([repository](https://github.com/RichieHakim/richfile)). This library works by saving hierarchical / tree-structured python objects as directory structures with customized functions for saving and loading each leaf object type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf1a612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import roicat.data_importing\n",
    "\n",
    "\n",
    "path_save = str(Path(tempfile.gettempdir()) / 'data_roicat.richfile')\n",
    "\n",
    "## Simple saving\n",
    "### Save the data object as a dictionary\n",
    "roicat.util.RichFile_ROICaT(path=path_save).save(data_roicat_multi_suite2p.__dict__, overwrite=True)\n",
    "\n",
    "## Simple loading\n",
    "### Load the richfile dictionary and import it into a Data_roicat object\n",
    "data_dict = roicat.util.RichFile_ROICaT(path=path_save).load()\n",
    "data_new = roicat.data_importing.Data_roicat().import_from_dict(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d279d735",
   "metadata": {},
   "source": [
    "Look at what the `.richfile` directory structure looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa835391",
   "metadata": {},
   "outputs": [],
   "source": [
    "roicat.util.RichFile_ROICaT(path=path_save).view_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1aa44f",
   "metadata": {},
   "source": [
    "# Section 3\n",
    "## Custom data class\n",
    "\n",
    "We can also make a `Data_roicat` object from scratch by populating the required data for what we want to do. Let's start with an empty object and call the `.check_completeness()` to see what it can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028633c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_custom = roicat.data_importing.Data_roicat()\n",
    "\n",
    "display(data_custom.check_completeness())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebaad71",
   "metadata": {},
   "source": [
    "As mentioned before, there are 5 key types of data that can be stored in a `Data_roicat` object:\n",
    "1. `spatialFootprints`: The images of individual ROIs within the field of view\n",
    "2. `FOV_images`: The image of the field of view itself (e.g. the mean fluorescence image of the raw movie)\n",
    "3. `ROI_images`: Small images of individual ROIs\n",
    "4. `class_labels`: The labels associated with each ROI\n",
    "5. `um_per_pixel`: The resolution of the imaging field of view\n",
    "\n",
    "Different combinations are needed for each of the 3 pipelines, which can be viewed in the above print statement from `.check_completeness()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed85f4b",
   "metadata": {},
   "source": [
    "### Prepare data for *Classification-inference*\n",
    "\n",
    "Let's add the necessary data to do **'Classification-Inference'**: `'ROI_images'`, `'um_per_pixel'`. \n",
    "\n",
    "Let's just make up some fake data with the correct properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa5836fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper function for making fake ROI_images data\n",
    "def make_ROIs(\n",
    "    n_sessions=10,\n",
    "    max_rois_per_session=100,\n",
    "    size_im=(36,36)\n",
    "):\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    import torchvision\n",
    "\n",
    "    roi_prototype = torch.zeros(size_im, dtype=torch.uint8)\n",
    "    roi_prototype[*torch.meshgrid(torch.arange(size_im[0]//2-8, size_im[0]//2+8), torch.arange(size_im[1]//2-8, size_im[1]//2+8), indexing='xy')] = 255\n",
    "    transforms = torch.nn.Sequential(*[\n",
    "        torchvision.transforms.RandomPerspective(distortion_scale=0.9, p=1.0),\n",
    "        torchvision.transforms.RandomAffine(0, scale=(2.0, 2.0))\n",
    "    ])\n",
    "    ROIs = [[transforms(torch.as_tensor(roi_prototype[None,:,:]))[0].numpy() for i_roi in range(max_rois_per_session)] for i_sesh in range(n_sessions)]\n",
    "    ROIs = [np.stack([roi for roi in ROIs_sesh if roi.sum() > 0], axis=0) for ROIs_sesh in ROIs]\n",
    "\n",
    "    return ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c423c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI_images = make_ROIs(\n",
    "    n_sessions=10,\n",
    "    max_rois_per_session=100,\n",
    "    size_im=(36,36),\n",
    ")\n",
    "\n",
    "print(f'Number of sessions: {len(ROI_images)}')\n",
    "print(f'Number of ROIs per session: {[rois.shape[0] for rois in ROI_images]}')\n",
    "print(f'Shape of each ROI image: {ROI_images[0][0].shape}')\n",
    "\n",
    "roicat.visualization.display_toggle_image_stack(ROI_images[0], image_size=(200,200))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dd7377",
   "metadata": {},
   "source": [
    "We've made `ROI_images`, which is a list of lists of 3D numpy arrays:\n",
    "\n",
    "Now let's add the ROIs_images to the data object. We will also add a `um_per_pixel` value, which is necessary for classification-inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fd7377",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_custom.set_ROI_images(ROI_images, um_per_pixel=1.5)\n",
    "\n",
    "data_custom.check_completeness()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90fcd5d",
   "metadata": {},
   "source": [
    "Notice that `'classification_inference': True'`, so we can use this data object for the **classification_inference** and **classification_by_Drawing** notebooks/pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01845c51",
   "metadata": {},
   "source": [
    "### Prepare data for *Tracking*\n",
    "\n",
    "For tracking we need: `spatialFootprints`, `FOV_images`, `ROI_images`, and `um_per_pixel`.\n",
    "\n",
    "What is `spatialFootprints`? It is an array containing the spatial mask of each ROI within the full field of view (FOV). We use a compressed datatype called a ***sparse matrix*** which dramatically speeds up handling this kind of data. The `Data_roicat` object can ingest two kinds of input for spatial footprints:\n",
    "1. A list of normal numpy arrays of shape **(n_roi, FOV_height, FOV_width)**\n",
    "2. A list of our natively used datatype: `scipy.sparse.csr_matrix` arrays of shape **(n_roi, FOV_height * FOV_width)**\n",
    "\n",
    "Again, let's just make up some fake data with the correct properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6229d3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sessions = 5\n",
    "size_im = (300,400)\n",
    "max_rois_per_session = 50\n",
    "\n",
    "spatialFootprints = make_ROIs(\n",
    "    n_sessions=n_sessions,\n",
    "    max_rois_per_session=max_rois_per_session,\n",
    "    size_im=size_im,\n",
    ")\n",
    "\n",
    "print(f'Number of sessions: {len(spatialFootprints)}')\n",
    "print(f'Number of ROIs per session: {[sf.shape[0] for sf in spatialFootprints]}')\n",
    "print(f'Shape of each spatialFootprints image: {spatialFootprints[0][0].shape}')\n",
    "\n",
    "roicat.visualization.display_toggle_image_stack(spatialFootprints[0], image_size=size_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4a470a",
   "metadata": {},
   "source": [
    "Now let's make a new `Data_roicat` and populate it with `spatialFootprints`. Again we need to specify a `um_per_pixel` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e500836",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_custom = roicat.data_importing.Data_roicat()\n",
    "\n",
    "data_custom.set_spatialFootprints(\n",
    "    spatialFootprints=spatialFootprints,\n",
    "    um_per_pixel=2.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317d8308",
   "metadata": {},
   "source": [
    "We could have also converted our input `spatialFootprints` into sparse arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30afd3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "\n",
    "spatialFootprints_sparse = [scipy.sparse.csr_matrix(sf.reshape(sf.shape[0], -1)) for sf in spatialFootprints]\n",
    "\n",
    "data_custom.set_spatialFootprints(\n",
    "    spatialFootprints=spatialFootprints_sparse,\n",
    "    um_per_pixel=2.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635a4e21",
   "metadata": {},
   "source": [
    "We also need `FOV_images` for tracking, so lets make some fake mean FOV images **with the same shape and number of sessions as spatial footprints**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd56fafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_custom.set_FOV_images([np.random.rand(*size_im) for ii in range(n_sessions)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42707317",
   "metadata": {},
   "source": [
    "Finally, we can convert the `spatialFootprints` into ROI_images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce6c84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_custom.transform_spatialFootprints_to_ROIImages(out_height_width=(36, 36));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b83ba28",
   "metadata": {},
   "source": [
    "Let's look at `.check_completeness()` again to see what we can do with this data object now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5913f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_custom.check_completeness()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23e52ee",
   "metadata": {},
   "source": [
    "We can do **tracking** and **classification-inference** now!\n",
    "\n",
    "Let's finish the exercise by adding `class_labels` so that we can use this data object for **classification-training** as well.\n",
    "\n",
    "`class_labels` should be a list of lists of integers. The outer list of should be of length `n_sessions` and the inner lists should be of length `n_rois` for that session. Each element should be an integer, and the set of integers should be consecutive and non-negative (ie: 0,1,2,3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc22eea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_labels = np.array(['n', 'd', 'j'])  ## 'neuron', 'dendrite', 'junk'\n",
    "class_labels = [possible_labels[np.random.randint(0,3, size=n)] for n in data_custom.n_roi]  ## List of arrays of str\n",
    "\n",
    "data_custom.set_class_labels(labels=class_labels, n_classes=len(possible_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24773706",
   "metadata": {},
   "source": [
    "You can also import `class_labels` from a file. Each file should correspond to one session. The files should all be '.json' files containing a list of integers or strings of length `n_roi` for that session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd25534",
   "metadata": {},
   "outputs": [],
   "source": [
    "## From .json files containing class labels\n",
    "paths_temp_classLabels = [str(Path(tempfile.gettempdir()) / f'test_classLabels_{ii}.json') for ii in range(n_sessions)]\n",
    "[roicat.helpers.json_save(list(l), p) for p, l in zip(paths_temp_classLabels, class_labels)];\n",
    "\n",
    "data_custom.set_class_labels(path_labels=paths_temp_classLabels, n_classes=len(possible_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9eda11",
   "metadata": {},
   "source": [
    "Let's look at `.check_completeness()` again to see what we can do with this data object now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c2934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_custom.check_completeness()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12875c3a",
   "metadata": {},
   "source": [
    "We can do everything now!\n",
    "\n",
    "To review we used all the following methods:\n",
    "```\n",
    "data_custom = roicat.data_importing.Data_roicat()\n",
    "data_custom.set_spatialFootprints(list of spatialFootprints, um_per_pixel)\n",
    "data_custom.set_FOV_images(list of images)\n",
    "data_custom._transform_spatialFootprints_to_ROIImages(height_width)\n",
    "data_custom.set_class_labels(class_labels, n_classes)\n",
    "data_custom.check_completeness()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abc80a1",
   "metadata": {},
   "source": [
    "### Thank you!\n",
    "\n",
    "Please let us know if you had any issues with this notebook in the github issues tab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca2b0b7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
